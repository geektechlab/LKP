Theory0:
/* softirq doesn't run in hard irq context */

Theory1:
Important Points related to softirqs
-------------------------------------

1. Compile Time:
	Declared at compile time in an enumerator
	Not suitable for linux kernel modules

2. Execution:
	Executed as early as possible
		After return of a top handler and before return to a system call
	This is achieved by giving a high priority to the executed softirq handlers

3. Parallel:
	Softirqs can run in parallel
	Each processor has its own softirq bitmap
	One softirq cannot be scheduled twice on the same processor
	One softirq may run in parallel on other

4. Priority:
	Kernel iterates over the softirq bitmap, least significant bit (LSB) first, and execute the associated
	softirq handlers

Theory2:
ksoftirqd
============

Softirqs are executed as long as the processor-local softirq bitmap is set.

Since softirqs are bottom halves and thus remain interruptible during execution, 

the system can find itself in a state where it does nothing else than 
	serving interrupts and 
	softirqs

incoming interrupts may schedule softirqs what leads to another iteration over the bitmap.

Such processor-time monopolization by softirqs is acceptable under high workloads (e.g., high IO or network traffic), but it is generally undesirable for a longer period of time since (user) processes cannot be executed.

Solution to above problem by kernel
======================================

After the tenth iteration(MAX_SOFTIRQ_RESTART) over the softirq bitmap, the kernel schedules the so-called ksoftirqd kernel thread, which takes control over the execution of softirqs.

Each processor has its own kernel thread called ksoftirqd/n, where n is the number of the processor

This processor-local kernel thread then executes softirqs as long as any bit in the softirq bitmap is set.

The aforementioned processor-monopolization is thus avoided by deferring softirq execution into process context (i.e., kernel thread), so that the ksoftirqd can be preempted by any other (user) process.

 ps -ef | grep ksoftirqd/

The spawn_ksoftirqd function starts these threads.

It is called early in the boot process.

static __init int spawn_ksoftirqd(void)
{
        cpuhp_setup_state_nocalls(CPUHP_SOFTIRQ_DEAD, "softirq:dead", NULL,
                                  takeover_tasklets);
        BUG_ON(smpboot_register_percpu_thread(&softirq_threads));

        return 0;
}
early_initcall(spawn_ksoftirqd);

File: kernel/softirq.c

Each ksoftirqd/n kernel thread runs the run_ksoftirqd()

static void run_ksoftirqd(unsigned int cpu)
{
        local_irq_disable();
        if (local_softirq_pending()) {
                /*
                 * We can safely run softirq on inline stack, as we are not deep
                 * in the task stack here.
                 */
                __do_softirq();
                local_irq_enable();
                cond_resched();
                return;
        }
        local_irq_enable();
}

Theory3:
local_softirq_pending()
-----------------------

It is 32-bit mask of pending softirqs

Theory4:
When are pending softirqs run?
-------------------------------

Pending softirq handlers are checked and executed at various points in the kernel code.

	a) After the completion of hard interrupt handlers with IRQ Lines Enabled
		do_IRQ() function finishes handling an I/O interrupt and invokes the irq_exit()

	b) call to functions like local_bh_enable() or spin_unlock_bh()

	c) when one of the special ksoftirqd/n kernel threads is awakened

Theory5:
in_softirq
-----------------

You can tell you are in a softirq (or tasklet) using the in_softirq() macro

Theory6:
Disabling/Enabling Softirqs
==============================

If a softirq shares data with user context, you have two problems.

1) the current user context can be interrupted by a softirq

2) the critical region could be entered from another CPU

Solution to  first problem
---------------------------

void local_bh_disable() 	Disable softirq and tasklet processing on the local processor

void local_bh_enable()		Enable softirq and tasklet processing on the local processor

The calls can be nested only the final call to local_bh_enable() actually enables bottom halves.

Theory7:
Locking Between User Context and Softirqs
==========================================

spin_lock_bh()	Disables softirqs on the CPU and then grabs the lock

spin_unlock_bh() Release lock and enable softirqs
