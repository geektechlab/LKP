1)
	A device driver has three sides: one side talks to the rest of the kernel, one talks to the hardware and one talks to the user
		==================
		=                =
		=   User         =  ---------
		=                =          |
		==================          |
			|                       |
			|                       |
			|                       |
		==================          |
		=                =          |
		=   Kernel       =          |
		=                =          |  Via Device File
		==================          |
			|                       |
			|Device Driver 
			|                       |
		==================          |
		=                =          |
		=   Hardware     = ---------
		=                =
		==================
	Traditional way of adding code to the kernel was to recompile the kernel and reboot the system. Instead of that, Loadable Kernel Modules (LKM) are piece of code that can be loaded/inserted and unloaded/removed from the kernel as per the demand/need. In boot process, base kernel is loaded first and then after the kernel image is loaded successfully it has initialized all the hardware peripherals it will start mounting the root file system and then it will load the kernel modules which are present in lib modules. Modules can save you memory, because you have to have them loaded only when you're actually using them ( the base kernel will always be present in the ram in the memory, but with modules we add/remove the code from the base kernel ) As the kernel modules are loaded very late in the boot process, hence core functionality has to go in the base kernel (E.g. Memory Management) ( all the kernel code can not be added as a kernel module because the core functionality like memory management cannot be configured as kernel module because the kernel modules as we have discussed they will be loaded late in the boot ) ( once the kernel is completely initialized and it has mounted the root file system then only the kernel can load the kernel modules hence the core functionality cannot be part of the kernel module ). Whenever we load an out of tree module it taints the kernel.

	All modules are installed in the /lib/modules/<kernel version> directory of the rootfs by default. Find kernel modules count by: cd /lib/modules/`uname -r`/kernel/ | find . -name '*.ko' | wc -l

	To support modules, the kernel must have been built with the following option enabled: CONFIG_MODULES=y. We can check it at cat /boot/config-`uname -r` | grep CONFIG_MODULES

	1. In-Source Tree: Modules present in the Linux Kernel Source Code which are present in the linux kernel source code so we download the source code from kernel.org can be configured as kernel modules )
	2. Out-of-Tree: Modules not present in the Linux Kernel Source Code which are not part of the kernel source code and which are distributed separately which by the vendor. All modules start out as "out-of-tree" developments, that can be compiled using the context of a source-tree.

	1. List Modules: (lsmod) lsmod gets its information by reading the file /sys/modules. ( we can check it by "strace lsmod" ) ( also we can check by "ls /sys/modules" )
	2. Module Information: (modinfo) : prints the information of the module. ( it provides various info such as word magic value and then you have what all parameters which are which can be passed to this module so while loading the module )

	printk() writes to the kernel buffer which can be read by dmesg, whereas printf() writes on the standard output. printk(KERN_log_priority "hello world\n"); printf() is a function in the C Standard Library. printk() is a kernel level function. printk(KERN_log_priority "hello world\n"); Here, log_priority is one of the eight values (predefined in linux/kernel.h, similar to /usr/include/sys/syslog.h)
		EMERG,
		ALERT, 
		CRIT, 
		ERR, 
		WARNING, 
		NOTICE, 
		INFO, 
		DEBUG (in order of decreasing priority).

	To Build Modules ( we are using /lib/modules/`uname -r`/build/Makefile, but it looks for another makefile in current folder which tells which modules to build. We specify this other makefile through M=${PWD} ):
		make -C /lib/modules/`uname -r`/build M=${PWD} modules
	To clean:
		make -C /lib/modules/`uname -r`/build M=${PWD} clean
	Once built, check generated module by
		file ./hello.ko
		modinfo ./hello.ko
	Load it by
		sudo insmod ./hello.ko ( because only root user can load module )
	Check loading by
		lsmod
	We can remove module by
		sudo rmmod hello
	Verify removal by lsmod Or check by ls /sys/module/hello/
	We need to check print messages by printk by
		dmesg

	Kernel modules must have at least two functions: 
		a "start" (initialization) function : module_init(test_hello_init); which is called when the module is loaded into the kernel
		an "end" (cleanup) function called : module_exit(test_hello_exit); which is called just before it is removed

	When we do insmod on a module, it performs a series of steps:
	a) It calls init_module() to intimate the kernel that a module is attempted to be loaded and transfers the control to the kernel
	b) In kernel, sys_init_module() [ https://elixir.bootlin.com/linux/latest/source/include/linux/module.h#L76 ] is run. It does a sequence of operations as follows, we can check it by [ strace insmod ./hello.ko ]:
			--> Verifies if the user who attempts to load the module has the permission to do so or not
			-->	The load_module function assigns temporary memory and copies the elf module from user space to kernel memory using copy_from_user
			--> It then checks the sanity of the ELF file ( Verification if it is a proper ELF file )
			--> Then based on the ELF file interpretation, it generates offset in the temporary memory space allocated. This is called the convenience variables
			-->	User arguments to the module are also copied to the kernel memory
			-->	Symbol resolution is done
			-->	The load_module function returns a reference to the kernel module.
			-->	The reference to the module returned by load_module is added to a doubly linked list that has a list of all the modules loaded in the system
			-->	Then the module_init function in the module code is called

	dmesg: Kernel keeps all the logs in a ring buffer. This is done to avoid the boot logs being getting lost until the syslog daemon starts and collects them and stores them in /var/log/dmesg. We will loss the boot up logs if we don't store them in ring buffer. dmesg command is used to control or print kernel ring buffer. Default is to prints messages from the kernel ring buffer on to console. ( we can check by strace dmesg -> it will write to STDOUT )

	when the kernel boots, there is no root file system. This means it does not have capability to write to any file so that's the reason why dmesg stores contents in a ring buffer. Once the system is up, syslog daemon starts and it will collect contents of the ring buffer and store them in a file which is specific to the distribution. So, if you look into the process list we'll be seeing there's a syslog daemon running ( check by [ ps -ef | grep syslog ] ) so which is actually reading periodically reading the kernel buffer contents of kernel buffer and it's writing into some file in /var/log which depends on the distribution ( check by [ cat /var/log/kern.log ] ).

	whenever we load an out of tree module it taints the kernel. Module should specify which license you are using MODULE_LICENSE() macro:
		"GPL"				[GNU Public License v2 or later]
		"GPL v2"			[GNU Public License v2]
		"GPL and additional rights"	[GNU Public License v2 rights and more]
		"Dual BSD/GPL"			[GNU Public License v2 or BSD license choice]
		"Dual MIT/GPL"			[GNU Public License v2 or MIT license choice]
		"Dual MPL/GPL"			[GNU Public License v2 or Mozilla license choice]
		"Proprietary"			[Non free products]

	Every kernel module needs to include linux/module.h. for macro expansion of module_init and module_exit linux/kernel.h only for the macro expansion for the printk() log level.

2)
	kernel use kbuild system to build the kernel modules. kbuild system reads the assignment of "obj-m := modulename.o"  from the makefile. Now the kbuild system know that it has to build "modulename.ko" and will look for "modulename.c" for the source. In case these files are not present in the directory passed to "M" , the compiling will stop with an error. If the files are present the source file is compiled to a "modulname.o",  and "modulename.mod.c" is created which is compiled to "modulename.mod.o". The modulename.mod.c is a file that basically contains the information about the module (Version information etc). The modulename.o and the modulename.mod.o are linked together by modpost in the next stage to create the "modulename.ko".

	Other Files:
	- "module.symvers": This will contain any of external symbols that is defined in your module and hence not present in the module.symvers of the kernel .
	- "modules.order" : In case you are compiling multiple modules together, it will list out the order in which the compilation and creation of .ko takes 

	- insmod:		Loads the module given 'insmod /path/to/module.ko'. Dependencies if present are not loaded.
	- modprobe – Add or Remove modules from the kernel. Loads the module only in /lib/modules/$(uname -r) 'modprobe /home/test/hello.ko' will not work. modprobe calculates dependencies, loads the dependencies and then the main module. Modprobe depends on depmod tool to calculate dependencies. depmod calculates dependencies of all the  modules present in /lib/modules/$(uname -r) folder, and places the dependency information in /lib/modules/$(uname -r)/modules.dep file ( try to [ cat /lib/modules/$(uname -r)/modules.dep ] ). E.g. kernel/drivers/net/wireless/admtek/adm8211.ko: kernel/net/mac80211/mac80211.ko kernel/net/wireless/cfg80211.ko kernel/drivers/misc/eeprom/eeprom_93cx6.ko

	When you say modprobe adm8211.ko, eeprom_93cx6.ko, cfg80211.ko is loaded first and then adm8211.ko. Modules are loaded right to left and removed left to right. So while removing adm8211.ko is removed, then cfg80211.ko and finally eeprom_93cx6.ko. We can re-load the modules.dep file by running "depmod -a" command

	In insmod, the function passed in the module_init macro is called, and on rmmod, the argument passed in the module_exit is called.

	The command line parameters through argc/argv provides a single linux driver to do multiple things, for example instead of fixing to a single I/O address for read/write, it can provide that as command line argument and allow user to read/write any address, Enable/disable debug logs/printk, Allow user to set the mode if the driver supports multiple modes.

	We can add parameters using module_param macro. Declared in moduleparam.h file
	#define module_param(name, type, perm)              \
		module_param_named(name, name, type, perm)

	name: name of the variable
	type: Type of the Variable. Supported types are charp, bool, invbool, int, long, short, uint, ulong, ushort
	perm: Permissions for the sysfs entry.  
	E.g. S_IRUGO : Only read by all users
		   0 : No sysfs entry
	You can also use numeric values like 0644 for permission entry.

	we can check our module's argumnets at [ ls sys/module/<module_name>/parameters ]
	and module's argumnets' permissions at [ ls sys/module/<module_name>/parameters ]
	we can check assigned values to arguments via [ cat sys/module/<module_name>/parameters/<argument> ]
	How to pass parameters: sudo insmod ./argument.ko name="EMBED" loop_count=5
	How can we pass arguments which are called by modprobe? modprobe reads /etc/modprobe.conf file for parameters.

	How can we pass string in argument? If we run the following command: "insmod argument.ko name="Linux World". We get the error "Unknown parameter 'World' ignored" in dmesg. This happens because shell removes double quotes and pass it to insmod, to avoid this add a single quotes over the string. Run the following command: "insmod argument.ko name='"Linux World"' to pass the whole string

	To pass multiple parameters we need to pass parameter array. To pass array we need to use module_param_array() function instead of module_param() function: sudo insmod ./parameter_array.ko param_array=1,2,4

	A symbol is a name given to a space in the memory which stores:
	 - data (Variables, For reading and writing)
	 - instructions (Functions, for executing)
	So symbol in the programming language is either a variable or function.

	What is Symbol table? Data Structure created by compiler containing all the symbols used in the program. Every kernel image that you build has a symbol table with it. The Linux kernel symbol table contains names and addresses of all the kernel symbols. When you install the kernel it will be present in /boot/System.map-<linux_version>

	System.map-<linux_version> is generated while compiling kernel. When we install it, it resides in boot folder.

	How to Export your symbols? When you define a new function in your module, the default behavior of this function is local, only the module in which the function is defined can access it, cannot be accessed by other modules. To export this module we need to use EXPORT_SYMBOL or EXPORT_SYMBOL_GPL. Once you export them, they will be available to other modules to use.

	Difference between EXPORT_SYMBOL and EXPORT_SYMBOL_GPL
	EXPORT_SYMBOL: The exported symbol can be used by any kernel module
	EXPORT_SYMBOL_GPL: The exported symbol can be used by only GPL licensed code.

	What is the difference between System.map and /proc/kallsyms?
	/proc/kallsyms: Contains symbols of dynamically loaded modules as well as builtin modules
	System.map: Contains symbols of only builtin modules. Because System.map-<linux_version> is generated while compiling kernel. When we install it, it resides in boot folder.

	$cat /boot/System.map-* | grep ttyprintk_exit
	$cat /proc/kallsyms | grep ttyprintk_exit

	What is module stacking? New modules using the symbols exported by old modules. Examples of modules stacking in Linux Kernel:
	- Msdos filesystem relies on symbols exported by fat module
	- Parallel port printer driver (lp) relies on symbols exported by generic parallel port driver (parport)

	Vermagic is a magic string present in the Linux Kernel and added into the .modinfo section of the Linux Kernel Modules. This is used to verify whether the kernel module was compiled for the particular kernel version or not. ‘VERMAGIC_STRING’ is generated by the kernel configuration.
	#define VERMAGIC_STRING                         \
		UTS_RELEASE " "                         \
		MODULE_VERMAGIC_SMP MODULE_VERMAGIC_PREEMPT             \
		MODULE_VERMAGIC_MODULE_UNLOAD MODULE_VERMAGIC_MODVERSIONS   \
		MODULE_ARCH_VERMAGIC                        \
		MODULE_RANDSTRUCT_PLUGIN

	we can check Vermagic of module at
	- dmesg once module is loaded
	- modinfo ./vermagic.ko
	we can check Vermic of kernel at [ uname -a ]

3)
	tainting of kernel will be stored in dmesg only once. re-loading will not display that message. At runtime, you can query the tainted state by reading $cat /proc/sys/kernel/tainted. After [reboot], value of above file will be 0. The easiest way to decode that number is the script kernel-chktaint ://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/plain/tools/debugging/kernel-chktaint. Running above script will tell the reason of tainting. For raw taint value decoding from the message, check flags.txt in this directory.

	How to find the version of a compiled kernel module? modinfo can be used for this. [ modinfo <.ko file> ]. Module Metadata:
	- MODULE_DESCRIPTION can be a short synopsis of what your module is trying to accomplish
	- MODULE_AUTHOR declares the module’s author
	- MODULE_VERSION macro sets the version of the module

	When the kernel is tainted, it means that it is in a state that is not supported by the community. In addition, some debugging functionality and API calls may be disabled when the kernel is tainted. Reasons:
	- The use of a proprietary (or non-GPL-compatible) kernel module—this is the most common cause of tainted kernels and usually results from loading proprietary NVIDIA or AMD video drivers
	- The use of staging drivers, which are part of the kernel source code but are not fully tested
	- The use of out-of-tree modules that are not included with the Linux kernel source code
	- Certain critical error conditions, such as machine check exceptions and kernel oopses

	Understanding modinfo output:
	- vermagic: When loading a module, the strings in the vermagic value are checked if they match. If they don't match you will get an error and the kernel refuses to load the module. 
	- intree: All kernel modules start their developments as out-of-tree. Once a module gets accepted to be included, it becomes an in-tree module.
	- srcversion: is an MD4 hash of the source code used to compile the kernel module. It is calculated automatically at build time from modpost script. Can be used for checking if given .ko is loaded by user or he is using previous only when we distribute .ko to customer.
	- retpoline: "Retpoline" was introduced to be a solution to mitigate the risk of Spectre bug.

	An ELF object file consists of various named sections. Some of them are basic parts of an object file, for example the .text section contains executable code that a loader loads. To see all the sections: $ objdump --section-headers ./mod_info.ko
	To see the contents of the .modinfo section: $ objdump --section-headers --section=.modinfo --full-contents ./mod_info.ko

	Printk is implemented by using a ring buffer in the kernel with a size of __LOG_BUF_LEN bytes where __LOG_BUF_LEN equals (1 << CONFIG_LOG_BUF_SHIFT). Calling dump_stack() will cause a stack trace to be printed at that point.

	Kernel Panic is an error in the kernel code and will stop running immediately to avoid data loss or other damage. The reason to stop running is to protect your computer. reasons:
	- Hardware or Software Issue (e.g. unable to start init process) ( init process is first process )
	- Bug in the kernel driver ( e.g. NULL pointer dereference )
	- Defective or Incompatible RAM

	When kernel decides to Panic, it calls the panic() function which dumps some debug information and depending on the configuration reboots the system. By default, the kernel will not reboot on Kernel Panic. There are two ways by which you can instruct the kernel to reboot:
	- Kernel Command line: Add "panic=N" to the kernel command line, for the kernel to reboot after N seconds
	- Proc File system: echo N > /proc/sys/kernel/panic , for kernel to reboot after N seconds on reboot. Note this setting is not persistent on reboot.

	How to check kernel commandline to know to reason of boot/reboot:
	- dmesg initial log will have kernel command line printed
	- cat /proc/cmdline

	An OOPS is similar to segfault in user space. Kernel throws oops message when an exception such as accessing invalid memory location happens in the kernel code. Upon OOPS, the kernel performs the following operations:
	- Kills the offending process
	- Prints information which can help the developers to debug
	- Continues execution. Note: After oops, the system cannot be trusted further as the some of the locks or structures may not be cleaned up.

	An OOPS Message contains the following information:
	- Processor Status
	- Contents of the CPU Registers at the time of exception
	- Stack trace
	- Call Trace
	in case of OOPS, system execution continues unlike kernel panic. But system can't be trusted further because some of the locks or structures may not be cleaned up. System continues running further after adding logs to dmesg.

	BUG() macro. we can find many BUG calls in linux source code, [ cd linux-`uname -r` ] [ grep -nr 'BUG' . ]
	- Prints the contents of the registers
	- Prints Stack Trace
	- Current Process dies
	After loading this module using insmod, you cannot unload this. If you try to call rmmod, you will get "Module in use" error.

	WARN() macro:
	- Prints the contents of the registers
	- Prints Stack Trace.
	- But current process will not die unlike BUG()

	Sometimes, an external module uses exported symbols from another external module. kbuild needs to have full knowledge of all symbols to avoid spitting out warnings about undefined symbols. When an external module is built, a Module.symvers file is generated containing all exported symbols which are not defined in the kernel. Use KBUILD_EXTRA_SYMBOLS and provide it the path of the Module.symvers file if it is present in some other directory other than the module directory.

	can I load any file to kernel ? lets do, [ touch hello.ko ], then [ chmod +x hello.ko ], then [ insmod hello.ko ]. It's not possible.

	insmod is user space utility. What happens when we do insmod on a module ? What is a kernel module? Kernel module is a piece of kernel code which can be added to the running kernel when loaded and can be removed from the kernel when the functionality is removed.

4)
	For Linux, a console is a device to which you can write text data and read text data. By default, the console is the screen and keyboard. When one boots his PC, the kernel prints a lot of messages, like "initializing this...", "initializing that...". These all get printed via printk that sends the message to the console driver. In Linux, graphics mode is implemented not inside the kernel but in user space and thus it cannot print messages in graphics mode, but as a usermode process called X sends a message via IPC to the X server and says it how the X server should draw the window. This message passing is implemented in a shared library. To display all kernel messages, [ dmesg -n 5 ].

	[ cat /proc/sys/kernel/printk ] will display 4 numbers. They are associated with the following variables:
		- console_loglevel: level under which the messages are logged on the console device 
		- default_message_loglevel: priority level that is associated by default with messages for which no priority value is specified 
		- minimum_console_loglevel: minimum level to allow a message to be logged on the console device 
		- maximum_console_loglevel: maximum level 

	$echo 8 > /proc/sys/kernel/printk Will change the console_loglevel

	pr_error etc. message displays more info than printk().

	When a user-space process uses floating-point instructions, the kernel manages the transition from integer to floating point mode. Many programs don't use floating point or don't use it on any given time slice and saving the FPU registers and other FPU state takes time; therefore an OS kernel may simply turn the FPU off. Presto, no state to save and restore, and therefore faster context-switching. 

	If a program attempts an FPU op, the program will trap into the kernel and the kernel will turn the FPU on restore any saved state that may already exist, and then return to re-execute the FPU op. At context switch time, it knows to actually go through the state save logic. (And then it may turn the FPU off again.) The reason that the kernel doesn't particularly need FPU ops and also needs to run on architectures without an FPU at all.

	A function, printk_ratelimit is to restrict the logging using which we can set a limit on the number of prints that we want our program to do. The limit on the number of prints is set in the file /proc/sys/kernel/printk_ratelimit_burst
	$ cat /proc/sys/kernel/printk_ratelimit_burst 

5)
	num_online_cpus() gives online cpu.

	process is a program running in memory. Linux kernel internally refers processes as tasks. Kernel stores the list of processes in a circular doubly linked list called the task list. Each task/process is represented in kernel with struct task_struct (defined in <linux/sched.h>). This data structure (task_struct) is huge (1.7 Kilobytes) containing all the information about a specific process. Let's write a module/device driver which reads the circular linked list and prints the following information for us:
		- Process Name
		- Process ID
		- Process State

	Before that, we should know what are the different states a process can be:
		- TASK_RUNNING(R): Process is either currently running or on a run-queue waiting to run
		- TASK_INTERRUPTIBLE(S) sleep: Process is sleeping/blocked for some resource say I/O. Can be runnable/awaken by a signal
		- TASK_UNINTERRUPTIBLE(D) sleep: Similar to TASK_INTERRUPTIBLE, but does not wakeup on a signal. Used in cases where it is waiting for critical hardware ( e.g. I/O resource ) and can't be interrupted.
		- __TASK_STOPPED(T): Process execution has stopped. This happens when the task receives SIGSTOP, SIGTSTP, SIGTTIN or SIGTTOU signal or if it receives any signal while it is being debugged.
	You can find the states using ps -el command.

	While writing a module if we want to get information about the current process that is running in the kernel, we need to read the "task_struct" of the corresponding process. The kernel provides a easy way to do this by providing a macro by the name "current", which always returns a pointer to the "task_struct" of the current executing process. Some architectures stores this in a register some stores them in bottom of kernel stack of process.

	Process Memory Map: struct mm_struct - contains list of process VMAs, page tables, etc. All information related to the process address space is included in an object called the memory descriptor of type mm_struct accessible via current-> mm.
	struct mm_struct {
		/* Pointer to the head of the list of memory region objects */
		struct vm_area_struct * mmap;
		/* Pointer to the root of the red-black tree of memory region objects */
		struct rb_root mm_rb;
		/* Pointer to the last referenced memory region object */
		struct vm_area_struct * mmap_cache;
		....
	};

	Linux implements a memory region by means of an object of type vm_area_struct
	struct vm_area_struct {
		struct mm_struct * vm_mm;   /* Pointer to the memory descriptor that owns the region */
		unsigned long vm_start;   /* First linear address inside the region */
		unsigned long vm_end;   /* First linear address after the region */
		....
	};

	Each memory region descriptor identifies a linear address interval. ( vm_end - vm_start ) denotes the length of the memory region. All the regions owned by a process are linked in a simple list. Regions appear in the list in ascending order by memory address. The vm_next field of each vm_area_structelement points to the next element in the list.

	A Kernel Thread is a Linux Task running only in kernel mode. It is not created by running fork() or clone() system calls. run [ ps -ef ] and whatever threads are in [], those are kernel threads. Kernel Threads helps the kernel to perform operations in background. examples of Kernel Thread:
		- ksoftirqd is Per CPU kernel thread runs processing softirqd.
		- kworker is a kernel thread which processes work queues.

	differences between Kernel Thread and User Thread:
	Both Kernel Thread and User Thread are represented by task_struct. The main difference is that there is no address space in kernel threads. mm variable of task_struct is set to NULL ( https://github.com/firmianay/Life-long-Learner/blob/master/linux-kernel-development/chapter-15.md ). Because kernel threads do not have address space and do not have any pages in user-space, they do not have memory descriptor and page tables. ( Read Robert Love. )

	How to Create a Kernel Thread?
		#include <linux/kthread.h>
		struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char name[], ...)
			Parameters:
			threadfn -> the function which thread should run
			data -> Argument for thread function
			name -> Printf style format for the name of kernel thread.
			Return Value: Pointer to struct  task_struct
		Note: kthread_create only creates the thread but doesn't run the thread, we need to call wake_up_process() with the return value of kthread_create as an argument to the wake_up_process for the thread function to run.

	kthread_create() only creates thread but pthread_create() creates thread and starts as well. Note: If you don't stop the kernel thread in your module_exit function and kernel thread is running, you will get oops message. kthread_stop is a blocking call, it waits until the function executed by thread exits. kthread_stop() flag sets a variable in the task_struct variable which the function running in while(1) should check in each of its loop.
		int threadfunc(void *data)
		{
			 while(!kthread_should_stop())
			 {
						//perform operations here
			  }
			return 0;
		}

	we can have same name of threads. When you have multiple processors present in the system, and want to find out on which the processor your driver code is running, use smp_processor_id().

6)
	In Linux everything is considered to be a file so devices are also considered to be a file. In UNIX, hardware devices are accessed by the user through special device files. These files are grouped into the /dev directory, and system calls open, read, write, close, lseek, mmap etc. are redirected by the operating system to the device driver associated with the physical device. In the UNIX world there are two categories of device files and thus device drivers: character and block. This division is done:
	- by the speed,
	- volume and
	- way of organizing the data to be transferred from the device to the system and vice versa.

	In the first category, there are slow devices, which manage a small amount of data, and access to data does not require frequent seek queries. Examples are devices such as keyboard, mouse, serial ports, sound card, joystick. In general, operations with these devices (read, write) are performed sequentially byte by byte.

	The second category includes devices where data volume is large, data is organized on blocks, and search is common. Examples of devices that fall into this category are hard drives, cdroms, ram disks, magnetic tape drives. For these devices, reading and writing is done at the data block level. For the two types of device drivers, the Linux kernel offers different APIs. If for character devices system calls go directly to device drivers, in case of block devices, the drivers do not work directly with system calls. In the case of block devices, communication between the user-space and the block device driver is mediated by the file management subsystem and the block device subsystem.

	ll /dev
	if c at start, it is character device
	if d at start, it is directory
	if b at start, it is block device

	Character Device Driver: A character device typically transfers data to and from a user application — they behave like pipes or serial ports, instantly reading or writing the byte data in a character-by-character stream.

	Command to list all the character device driver: $ls -l /dev/ | grep "^c"

	Command to list all the block device driver: $ls -l /dev/ | grep "^b"

	all ttys are serial ports. sda are block devices.

	Steps in creating a character driver:
	1. Allocate a device number dynamically or statically (dev_t)
	2. Initializing the character device with its file operations (struct cdev, struct file_operations)
	3. Registering the character device with Linux Kernel (cdev_add)

	Connection between the application and the device file is based on the name of the device file. However the connection between the device file and the device driver is based on the number of the device file, not the name. A device ID/number consists of two parts:
	- Major Number : identifies the device type (IDE disk, SCSI disk, serial port, etc.)
	- Minor Number : identifies the device (first disk, second serial port, etc.)

	Most times, the major identifies the driver, while the minor identifies each physical device served by the driver. Certain major identifiers are statically assigned to devices (in the Documentation/admin-guide/devices.txt file from the kernel sources).

	ls -l /dev/ttyS*
	crw-rw---- 1 root dialout 4, 64 Apr 12 23:18 /dev/ttyS0
	crw-rw---- 1 root dialout 4, 65 Apr 12 23:18 /dev/ttyS1
	crw-rw---- 1 root dialout 4, 74 Apr 12 23:18 /dev/ttyS10
	crw-rw---- 1 root dialout 4, 75 Apr 12 23:18 /dev/ttyS11
	crw-rw---- 1 root dialout 4, 76 Apr 12 23:18 /dev/ttyS12
	crw-rw---- 1 root dialout 4, 77 Apr 12 23:18 /dev/ttyS13
	crw-rw---- 1 root dialout 4, 78 Apr 12 23:18 /dev/ttyS14
	In columns 5 and 6 of the result you can see the major, respectively the minor for each device.

	When choosing the identifier for a new device, you can use two methods:
		static (choose a number that does not seem to be used already)
		dynamic (kernel will give you a device number)

	Data Type: A device ID/number is represented using the type dev_t. 12 bit major number + 20 bit Minor number =32 bit dev_t.

	Header File: linux/kdev_t.h
	To obtain the major or minor parts of a dev_t, use: MAJOR(dev_t dev); MINOR(dev_t dev);
	To create a device number from major and minor number: MKDEV(int major, int minor);

	/proc/devices:
	This file displays the various character and block devices currently configured. The output from /proc/devices includes the major number and name of the device. Output is broken into two major sections:
	- Character devices and 
	- Block devices.

	Difference between static and dynamic method of major and minor number allocation: Static method is only really useful if you know in advance which major number you want to start with. With Static method, you tell the kernel what device numbers you want (the start major/minor number and count) and it either gives them to you or not (depending on availability).

	With Dynamic method, you tell the kernel how many device numbers you need (the starting minor number and count) and it will find a starting major number for you, if one is available, of course. Partially to avoid conflict with other device drivers, it’s considered preferable to use the Dynamic method function, which will dynamically allocate the device numbers for you.

	Dynamic Allocation will allocate the major number dynamically to your driver which is available. It is advantageous over static method because conflict will not happen and kernel will allocate available number automatically. Minor number is still at our wish.

	Header File: <linux/fs.h>

	we can't use same major number and minor number combination which already has been used. But character and block device can have same major and minr number combination because noth device types are different. Try passing same major number which is already used by finding it from [ cat /proc/devices ]. however, we can use same device name.

	CHRDEV_MAJOR_MAX is an artificial limit foe maximum major number (chosen to be 511).

	Suppose if we create duplicate copy of .ko then even we will not be able to load same module again because, name of module will remain same. check it by [ modinfo <name>.ko ].

	There are 2 segments for free char majors. First starting point can be any, we don't know but ends at 234. Second segment starts at 511 and grows reverse and ends at 384. Marks the top and bottom of the second segment of free char majors. After these two segments utilized, dynamic allocation will start failing. Those are defined here:
	/* fs/char_dev.c */
	#define CHRDEV_MAJOR_MAX 512

	We can check dynamic allocations live using [ dmesg ] by running as daemon [ & ]. also we can check later using [ cat /proc/devices/

	Device file is independent of device driver. We can create device file before creating device driver also. Device file can be created in two ways:
		1. Manual
		2. Automatic

	We can create the device file manually by using mknod. $ mknod -m <permissions> <name> <device type> <major> <minor>
	-m <permissions> – optional argument that sets the permission bits of the new device file to permissions
	<name> – your device file name that should have full path (/dev/name)
	<device type> – Put c or b
		c – Character Device
		b – Block Device
	<major> – major number of your device
	<minor> – minor number of your driver

	Eg. 
	$sudo mknod -m 0644 /dev/mydevice c 244 10

	Traditionally, device nodes were stored in the /dev directory on Linux systems. There was a node for every possible type of device, regardless of whether it actually existed in the system. The result was that this directory took up a lot of space.

	udev introduces a new way of creating device nodes. It compares the information made available by sysfs and creates nodes. udev can be further configured using its configuration files to tune the device file names, their permissions, their types, etc.

	/dev provides a way for user process to access device files to read, write, send IOCTL command etc. Whereas, /sys sysfs file system exposes detailed device information, atributes and kernel objects to user space for introspection and configuration which can be read/written for debugging and configuration.

	So, as far as driver is concerned, the appropriate /sys entries need to be populated using the Linux device model APIs declared in <linux/device.h> and the rest would be handled by udev.

	class_create — create a struct class structure
		struct class * class_create (struct module *owner,
						 const char *name);
		owner	-	pointer to the module that is to “own” this struct class
		name	-	pointer to a string for the name of this class.
		Header File: <linux/device.h>
	This is used to create a struct class pointer that can then be used in calls to class_device_create. class_destroy — destroys a struct class structure. void class_destroy (struct class *cls); Now, the name will appear in /sys/class/<name>.

	$ udevadm monitor
	With this command, you can tap into udev in real time and see what it sees when you plug in different devices. For better understanding of process, see example 7.

	Create a device and register it with sysfs ( creates devnode ). struct device * device_create(struct class *class, struct device *parent, dev_t devt, void *drv_data, const char *fmt, ...); This function can be used by char device classes. A struct device will be created in sysfs, registered to the specified class.
		class 	-->	pointer to the struct class that this device should be registered to (it returns a pointer )
		parent  -->	pointer to the parent struct device of this new device, if any
		devt    --> 	the dev_t for the char device to be added
		fmt	-->     string for the device's name
		...	-->	variable arguments

	If a pointer to a parent struct device is passed in, the newly created struct device will be a child of that device in sysfs. device_destroy() — removes a device that was created with device_create. void device_destroy (struct class *class, dev_t devt);

7)
	adding __init / __exit attribute to function creates an entry in sections in generated .ko file. It can be used to create init or exit code. struct file_operations:
		Purpose: Holds pointers to functions defined by the driver that performs various operations on the device.
		Defined in : linux/fs.h
		struct file_operations {
			struct module *owner;
			loff_t (*llseek) (struct file *, loff_t, int);
			ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);
			ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);
			[...]
			long (*unlocked_ioctl) (struct file *, unsigned int, unsigned long);
			[...]
			int (*open) (struct inode *, struct file *);
			int (*flush) (struct file *, fl_owner_t id);
			int (*release) (struct inode *, struct file *);
			[...]

		E.g. struct file_operations fops =
		{
		.read = device_read,
		.write = device_write,
		.open = device_open,
		.release = device_release
		};

	The above fops structure has defined four function pointers : For reading, writing, opening and closing the device file. It can be noticed that the signature of the function differs from the system call that the user uses. The operating system sits between the user and the device driver to simplify implementation in the device driver.

	for example, int (*open) (struct inode *, struct file *); has two arguments. Whereas, open system call has file path, permissions, and file flags. So parameters are different in user space and kernel space. Kernel will translate this parameter using VFS layer and then call kernel open where we register our own open call viz. device_open().

	open does not receive the parameter path or the various parameters that control the file opening mode. Similarly, read, write, release, ioctl, lseek do not receive as a parameter a file descriptor. Instead, these routines receive as parameters two structures: file and inode.

	struct cdev: In kernel, each character device is represented using this structure.
		Header File: linux/cdev.h
		struct cdev
		{
			/* module */
			struct kobject kobj;
			struct module *owner;
			const struct file_operations *ops;
			struct list_head list;
			dev_t dev;
			unsigned int count;
		} __randomize_layout;

		void cdev_init(struct cdev *, const struct file_operations *); --> initialize a cdev structure
		struct cdev *cdev_alloc(void); --> Allocates and returns a cdev structure
		int cdev_add(struct cdev *, dev_t, unsigned int minor_count); --> add a char device to the system
		void cdev_del(struct cdev *dev); --> remove a cdev from the system

	The owner field of the structure should be initialized to THIS_MODULE to protect against ill-advised module unloads while the device is active. Find cdev_alloc() vs cdev_init() difference.

	Pseudo-Devices: Devices in Linux (and other Unix clones) do not necessarily have to correspond to physical devices. These are known as pseudo-devices. For example,
		- /dev/urandom generates a stream of pseudo-random numbers (try running head /dev/urandom in a terminal)
		- /dev/null produces no output, but accepts and discards any input (if you wanted to test your download speed without writing any data to your disk, you could download a file to /dev/null by running, e.g., wget http://some.website/big.file > /dev/null).
			Read : Returns End of file (read returns 0)
			Write: Data written is discarded
		- /dev/zero: Used by developers to create a file with no meaningful data but a particular size
			Read: Returns endless bytes of zeroes (\0 characters)
			Write: Data written is discarded
	File: drivers/char/mem.c has the implementation for this devices

	go into linux source code and go into [ ls drivers/char/mem.c ] and chek it's called register_chrdev with MEM_MAJOR argument. check MEM_MAJOR using [ grep ] command and it comes out as 1. then [ cat /proc/devices ] and check [ ls -l /dev/zero ], [ ls -l /dev/null ], [ ls -l /dev/urandom ] and check all has major number 1 and only minor number differs. check chr_dev_init() internals and see how device number creation, assignment and registration etc. happens

8)
	How many times device driver open and release will be called in case of fork? The open and release function is only called once. When you do fork(), it will not create a new file structure and close() will call the release method of the driver only when the counter of the file structure becomes zero. Those called only once because open() and close() are related to device file which is related to hardware not related to number of process created.

	vi ~/linux-5.2.8/include/linux/fs.h check struct file -> count variable.

	struct file:
	Header File: <linux/fs.h>
	struct file is different when compared to FILE of user space program. A FILE is defined in the C library and never appears in kernel code. A struct file, on the other hand, is a kernel structure that never appears in user programs.

	The file structure represents an open file. (It is not specific to device drivers; every open file in the system has an associated struct file in kernel space.) Whenver you open a file, kernel creates a struct file in kernel space. It is created by the kernel on open and is passed to any function that operates on the file, until the last close. After all instances of the file are closed, the kernel releases the data structure. An open file is different from a disk file, represented by struct inode.

	Important Fields:
		struct file {
			//The file mode identifies the file as either readable or writable
			fmode_t                 f_mode;
			//The current reading or writing position. loff_t is a 64-bit value 
			loff_t f_pos;
			//These are the file flags, such as O_RDONLY, O_NONBLOCK, and O_SYNC. The file mode identifies the file is opened in either read or write mode ?
			unsigned int            f_flags;
			//The operations associated with the file.
			struct file_operations *f_op;
			//The open system call sets this pointer to NULL before calling the open method for the driver.
			//The driver can use the field to point to allocated data, but then must free memory in the release method before the file structure is destroyed by the kernel
			// private_data is a useful resource for preserving state information across system calls
			void *private_data;
		}; 

	struct inode: we can verify inode related information using stat command. [ stat hello.c ]
		Header File: <linux/fs.h>
	The inode structure is used by the kernel internally to represent files. An inode uniquely identifies a file in a file system. It represents a file on disk. struct inode is different from struct file. Whenever we open a file, struct file gets created. But when file gets created, struct inode gets created.
		struct inode {
			//mode
			umode_t                 i_mode;
			kuid_t                  i_uid;
			kgid_t                  i_gid;
			//inode number
			unsigned long           i_ino;
			//Contains the actual device number
			dev_t                   i_rdev;
			// Kernel representation of char device
			struct cdev *i_cdev
		};

	Kernel developers have added two macros that can be used to obtain the major and minor numbers from an inode.
	( MAJOR(inode->i_rdev), MINOR(inode->i_rdev) )
	unsigned int iminor(struct inode *inode);
	unsigned int imajor(struct inode *inode);
	Check example 4 for understanding inode better.

	difference between struct inode vs struct file: if we run userapp or kernel driver multiple times then file strucutre pointer will be different whereas inode will same because file structure will get created again but inode will remain same because it points to same file. Because multiple driver instance will have separate file descriptor but inode is associated with file itself.

	Accessing process address space can not be done directly (by de-referencing a user-space pointer). Because kernel driver can't/shouldn't access user space memory. If we try to do that, then page domain fault will happen and OOPs will happen. Maybe because when kernel tries to access user space space memory it might be used by another process or might be swapped out. Direct access of a user-space pointer can lead to 
		- incorrect behavior (depending on architecture, a user-space pointer may not be valid or mapped to kernel-space), ( in ARM architecture, EL0 address access might not be allowed from EL1 ? )
		- a kernel oops (the user-mode pointer can refer to a non-resident memory area) or 
		- security issues. 

	Proper access to user-space data is done by calling the macros / functions below: #include <linux/uaccess.h>
		put_user(type val, type *address);
		get_user(type val, type *address);
		unsigned long copy_to_user(void __user *to, const void *from, unsigned long n);
		unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)

	The copy_from_user function copies a block of data from user space into a kernel buffer. It accepts:
		destination buffer (in kernel space), 
		a source buffer (from user space), and 
		a length defined in bytes

	The copy_to_user function copies a block of data from the kernel into user space. This function accepts:
		pointer to a user space buffer, 
		a pointer to a kernel buffer, and 
		a length defined in bytes. 

	put_user function is used to write a simple variable from the kernel into user space. It supports simple types like char and int, but not larger data types like structures or arrays. get_user is used to read a simple variable from user space.

9)
	If we pass structure having a pointer member then copying functions will do shallow copy instead of deep copy. Because it will copy contents from user/kernel space to kernel/space of structure. Not the reference of memory pointed to user space. To avoid this issue, copy individual members.

	strlen can't work directly on user space memory. Proper way to do that it to copy in kernel space. strnlen_user gets the size of a NULL-terminated string in user space.
		long strnlen_user (const char __user *s, long  	n);
		s 	The string to measure.
		n	The maximum valid length

	The *offp should be updated after each data transfer to represent the current file position after successful completion of the system call (copy_to_user, copy_from_user etc. ). Othrwise it will take same one as previous call. That's why previous example was failing.

	If we create multiple device nodes then While allocating the device numbers, we need to specify the number of minor devices in the count argument.
		int alloc_chrdev_region (dev_t * dev, unsigned  baseminor, unsigned  count, const char * name);
		We need to create an array of struct cdev, and register each of the cdev with one minor number.
	check 5 device nodes created:
	ls /dev/msg*

	Compare 12 example with previous examples and check how it is different. Only alloc_chrdev_region() gets updated and all system calls and its argumnets remain unchanged. In our previous program, each one is operation on same user buffer. But if I want private user buffer for each, use this example.

		#define offsetof(TYPE, MEMBER)	((size_t) &((TYPE *)0)->MEMBER)
		#define container_of(ptr, type, member)	({	\
								const typeof ( ((type *)0)->member) *__mptr = (ptr); \
								(type *)( (char *)__mptr - offsetof(type, member));})

	What happens when a user-space application calls write on a device file, for example we wrote our own null device: [ /dev/my_null ]. So, we execute write using: [ echo "Hello" > /dev/my_null ]. Userspace internally calls GLibC write call which calls write System Call.
		Step1: Write system call in kernel is executed which is present in fs/read_write.c, which calls ksys_write
		Step2: The fd passed by user is an index in the file descriptor table present in the kernel, fdget_pos fetches the struct fd of the particular file
			struct fd {
				struct file *file;
				unsigned int flags;
			};
			static inline loff_t file_pos_read(struct file *file)
			{
				return file->f_pos;
			}
			This position extracts the offset within the file, and calls vfs_write, and then the return value of write call is updated with offset
		Step 3: In vfs_write,
			It checks whether the file was opened in read-only mode
			Checks whether this file has write method
			Whether the passed user buffer is a valid buffer for reading
			Verifies the area for writing is valid and for security permissions
			And calls __vfs_write 
		Step 4: Finally in __vfs_write, it calls our write function present in the fops (struct file_operations) present in the struct file. So, this is the way, even if we pass only three arguments from user space, kernel reads the offset from the file and pass it to our write function defined in our driver.
	go to ~/linux-5.2.8/fs and grep -nr 'vfs_write' .

10)
	IOCTL is referred as Input and Output Control. Device files are supposed to represent physical devices. Most physical devices are used for output as well as input. We have write and read system calls for input and output. This is not always enough. The major use of this is in case of handling some specific operations of a device for which the kernel does not have a system call by default. Examples:
		1. Ejecting the media from a “cd” drive,
		2. change the Baud Rate of Serial port
		3. Adjust the Volume
		4. Reading or Writing device registers

	The system call ioctl() is provided for device-specific custom commands (such as format, reset and shutdown) that are not provided by standard system calls such as read(), write().
		int ioctl(int fd, unsigned long request, ...);
		Every device can have its own ioctl commands, which can be
			--> read ioctl's (to send information from a process to the kernel)
			--> write ioctl's (to return information to a process)
			--> both or neither

	See ioctl_list(2) for a list of  many  of  the  known  ioctl() calls. [ man 2 ioctl_list ], important, open and check it. On Linux-based systems the size of a block special device can be obtained using the ioctl request BLKGETSIZE ( check in [ man 2 ioctl_list ] ). It returns the device size as a number of 512-byte blocks

	The ioctl driver method has a prototype that differs somewhat from the user space version. generally, IOCTL is used for custom commands implemented for a particular given device. unlocked_ioctl is custom command for a character driver, which we implemented. Se how it gets assigned in device_fops. See what values are received in kernel space.
		long (*unlocked_ioctl) (struct file *filp, unsigned int cmd, unsigned long arg);
	The filp pointer is the value corresponding to the file descriptor fd passed on by the application and is the same parameters to the open method. The cmd argument ( from user space ) is passed from the user unchanged, and the optional arg argument is passed in the form of an unsigned long

	Most ioctl implementations consist of a big switch statement that selects the correct behavior according to the cmd argument. Programmers much choose a number for the integer command representing each command implemented through ioctl. Normally many programmers choose a set of small numbers starting with 0 or 1 and go up from there. Picking arbitrary number is a bad idea, because:
	 - Two device nodes may have the same major number
	 - An application could open more than one device and mix up the file descriptors, thereby sending the right command to the wrong device.
	 - Sending wrong ioctl commands can have catastrophic consequences, including damage to hardware.

	Example: Program might find itself trying to change the baud rate of non-serial port input stream, such as FIFO or an audio device. also header files provide macros, but do not specify of which type those are. Whether those are char, int etc. To help programmers create unique ioctl command codes, ioctl codes have been divided into four bitfields.
	1. type/magic number:
		8 - bit Wide
		Choose one number after looking into  Documentation/ioctl-number.txt and use it throughout the driver
	2. number:
		8-bits wide
		sequential number you assign to your command
	3. direction:
		Direction of data transfer.
		Possible values:
			_IOC_NONE(NO Data Transfer)
			_IOC_READ 	--> Reading from the device, driver must write into userspace
			_IOC_WRITE
			_IOC_READ|_IOC_WRITE
	4. size:
		Size of the user data involved.
		Width depends on the architecture: usually 13 or 14 bits
		You can find its value for your specific architecture in the macro _IOC_SIZEBITS

	Header File: <linux/ioctl.h>. This above header file defines macro that help set up the command numbers as follows:
		_IO(type, nr) (for a command that has no argument)
		_IOR(type, nr, datatype) (for reading data from the driver)
		_IOW(type, nr, datatype) (for writing data to the driver)
		_IOWR(type, nr, datatype) (for bidirectional data transfer)
	Type and number fields are passed as arguments and size field is derived by applying sizeof to the datatype argument.

	Macros to decode information from the ioctl command
	_IOC_TYPE(cmd) /* gets the magic number of the device this command targets */
	_IOC_NR( cmd) /* gets the sequential number of the command within your device */
	_IOC_SIZE(cmd) /* gets the size of the data structure */
	_IOC_DIR( cmd) /* gets the direction of data transfer,
									can be one of the following:
									_IOC_NONE
									_IOC_READ
									_IOC_WRITE
									_IOC_READ | _IOC_WRITE
									*/
	As per the POSIX Standard, if an inappropriate ioctl command has been issued , then -ENOTTY should be returned.

	We need to take care of the arg parameter in the ioctl function, because it is a user space ( might be pointing to user space memory ). We can use copy_from_user/copy_to_user to safely copy data from user to kernel and vice versa. These functions are less efficient in case of copying small data items. You can use put_user/get_user for copying 1, 2, 4 or 8 bytes. If you only want to verify the address without transferring data, you can use access_ok.
		Header File: <asm/uaccess.h>
		int access_ok(int type, void *addr, unsigned long size);
		type -> VERIFY_READ/VERIFY_WRITE: depending on action: reading the user space memory or writing it
		addr -> user space address
		size -> Depends on the ioctl command.
			If you need to both read and write, use VERIFY_WRITE, it is a superset of VERIFY_READ. https://lkml.org/lkml/2019/1/4/418

	64 bit ioctl will fail for 32 will -ENOTTY. To use older 32 bit ioctl, we can use compact_ioctl instead of unlock_ioctl. compact_ioctl convert to unlock_ioctl arguments. For generating 32 bit applcation on 64 bit machine need to install when compiling for 32 bit in 64 bit machine.
	$ sudo apt-get install g++-multilib
	gcc userapp.c -o userapp -m32

	Sending a signal from module to process via IOCTL.
		int send_sig(int signal, struct task_struct *task, int priv);
		signal --> Signal to send
		task   --> Corresponds to task_struct corresponding to the process
		priv   --> 0 for user applications, 1 for kernel
	see how pid gets updated.

11)
	If you want to support multiple kernel versions, you'll find yourself having to code conditional compilation directives. The way to do this to compare the macro LINUX_VERSION_CODE to the macro KERNEL_VERSION. LINUX_VERSION_CODE:This macro expands to the binary representation of the  kernel version. One byte for each part of the version release number. Eg. 5.0.0 = 0x050000 = 327680
		Header File: <linux/version.h>
		From Kernel Top Level Makefile
		LINUX_VERSION_CODE = $(VERSION) * 65536 + $(PATCHLEVEL) * 256 + $(SUBLEVEL)
		Eg: 5.0.0 = 5*65536+0*256+0 = 327680

	If you want to stop compilation at preprocessing stage. Add this in your makefile EXTRA_CFLAGS=’-save-temps’. This will generate all the intermediate files in generating .ko. If you need only .i file. $ make -C /lib/modules/`uname -r`/build M=${PWD} hello.i

	KERNEL_VERSION macro is used to build an integer code from the individual numbers that build up a version number.
		#define KERNEL_VERSION(a,b,c) (((a) << 16) + ((b) << 8) + (c))
		Header File: <linux/version.h>

	UTS_RELEASE macro expands to a string describing the version of this kernel tree. Header File: #include <generated/utsrelease.h>

	If you find out how many times your driver code is used by application, we can maintain a static counter variable in open system call and later print it. Sometimes a device needs to be opened once at a time; More specifically, do not allow the second open before the release. To implement this restriction, you choose a way to handle an open call for an already open device: it can return an error (-EBUSY), block open calls until a release operation, or shut down the device before do the open.

	Logic: Initialize the atomic value with 1. In open function, decrement and check whether the value is zero, if zero then return success. If the value is not zero, then increment the value and return EBUSY. In release function, increment the value of atomic variable.

	To allow a single user to open a device in multiple processes but allow only one user to have the device open at a time. To achieve this, two items are needed:
		- an open count
		- uid of the owner of the device.
	The open call grants access on first open but remembers the owner of the device.

	Traditionally Linux/Unix only had two level of privileges:
		1. Root
		2. Non-Root

	No security checks where performed for processes running in root user, whereas processes running in non-root user were subjected to security checks. No intermediate solution was existing at that time. setuid was only the option for the non-root processes to get privileges. Giving all privileges when only few were required was not a good solution and is a target for attack. POSIX Capabilities is a concept which divides root privileges into a set of privileges. These privileges/values then can be independently assigned to the processes, by this way the process will only contain the require privileges and some level of security is achieved. File '/usr/include/linux/capability.h' contains list of capabilities available in Linux or [ man capabilities ].

	Command to find which capabilities are set for a particular file? [ getcap <filename> ]
	Command to set capabilities for a particular file? Each process has three sets of capabilities:
		1. Permitted: capabilities that this process can possibly have. Superset of effective
		2. Effective:  capabilities that this process actually has.
		3. Inheritable: capabilities that this process can pass to a child process

	Each capability is implemented as a bit in each of the bitmap, which can be set or unset. $ setcap cap_sys_boot+ep /path/to/executable. The above command sets 'CAP_SYS_BOOT' capabilities in both extended and permitted bitmap. Capabilities are implemented on Linux using extended attributes in the security namespace. All the major file systems such as ext2, ext3, ext4, JFS, XFS etc support extended attributes.

	When a process tries to perform a privileged operation, the kernel checks whether the particular capability for performing the operation is set in the effective capability bitmap, if yes then it allows, else throws 'permission denied' error.

	CAP_DAC_OVERRIDE: Allows a non-root user full file system access. Bypasses file read, write and execute permission check. DAC stands for "discretionary access control".
		$sudo setcap cap_dac_override+ep userapp
		$getcap userapp

	CAP_SYS_ADMIN is the ability to perform all the system administration operations. Almost near to root. Before performing a privileged operation, a device driver should check that the calling process has the appropriate capability or not. Capabilities checks are performed with the capable function.
		Header File: <linux/sched.h>
		int capable(int capability);

	As you know the open system call takes set of flags as second argument that control opening a file and mode as third argument that specifies permission the permissions of a file if it is created.
		int open(const char *pathname, int flags, mode_t mode);
	The do_sys_open function starts from the call of the build_open_flags function which does some checks that set of the given flags is valid and handles different conditions of flags and mode.
		File: fs/open.c
	Let's look at the implementation of the build_open_flags. This function is defined in the same kernel file and takes three arguments:
		flags - flags that control opening of a file;
		mode - permissions for newly created file;
		The last argument - op is represented with the open_flags structure:
			struct open_flags {
					int open_flag;
					umode_t mode;
					int acc_mode;
					int intent;
					int lookup_flags;
			};
	which is defined in the fs/internal.h header file and as we may see it holds information about flags and access mode for internal kernel purposes. Implementation of the build_open_flags function starts from the definition of local variables and one of them is:
		int acc_mode = ACC_MODE(flags);
	This local variable represents access mode and its initial value will be equal to the value of expanded ACC_MODE macro. 
		#define ACC_MODE(x) ("\004\002\006\006"[(x)&O_ACCMODE])
		#define O_ACCMODE   00000003
			The "\004\002\006\006" is an array of four chars:
				"\004\002\006\006" == {'\004', '\002', '\006', '\006'}
					So, the ACC_MODE macro just expands to the accession to this array by [(x) & O_ACCMODE] index. As we just saw, the O_ACCMODE is 00000003. By applying x & O_ACCMODE we will take the two least significant bits which are represents read, write or read/write access modes:
		#define O_RDONLY        00000000
		#define O_WRONLY        00000001
		#define O_RDWR          00000002

	When the process terminates, the release function will be called even if we don't call close() from user space.

	Misc drivers: In UNIX, Linux and similar operating systems, every device is identified by two numbers: a “major” number and a “minor” number. These numbers can be seen by invoking ls -l /dev. Every device driver registers its major number with the kernel and is completely responsible for managing its minor numbers. Every driver needs to register a major number, even if it only deals with a single device. Misc (or miscellaneous) drivers are simple char drivers that share certain common characteristics. The kernel abstracts these commonalities into an API (implemented in drivers/char/misc.c), and this simplifies the way these drivers are initialized. All misc drivers are assigned a major number of 10, but each can choose a single minor number. So, if you have a char driver needs to support multiple devices, it's not the candidate for being a misc driver.

	the sequence of initialization steps that a char driver performs:
		1. Allocates major/minor number using alloc_chrdev_region() and friends
		2. Creates /dev and /sys nodes using class_device_create() function
		3. Register itself as a char driver using cdev_init() and cdev_add()
			static struct miscdevice misc_dev ={
				.minor = 10,
				.name = MYDEV_NAME,
				.fops = &mycdrv_fops,
			};
		misc_register(&misc_dev);

	In the above example, I have statically assigned a minor number 10. You can also request for dynamic minor number assignment by specifying MISC_DYNAMIC_MINOR in the minor field. Each misc driver automatically appears under /sys/class/misc without explicit effort from the driver writer.

	The misc API seems to make your life easier when you're writing a small character driver and do not want to need to allocate a new major number only to use one minor number. It simplifies things, but all the file operations are still available using the fops member of struct miscdevice. The basic difference is you only get one minor number per misc device.

	Loading Modules on Demand: Linux offers support for automatic loading and unloading of modules. This feature avoid wasting kernel memory by keeping drivers in core memory when not in use. This ability to request additional modules when they are needed is particularly useful for drivers using module stacking. To request the loading of a module, call request_module:
		int request_module(const char *module_name);
	Note that request_module is synchronous -- it will sleep until the attempt to load the module has completed. This means, of course, that request_module cannot be called from interrupt context. The return value indicates that request_module was successful in running modprobe, but does not reflect the success status of modprobe itself. When the kernel code calls request_module, a new "kernel thread'' process is created, which runs modprobe in the user context. But we can't remove it dynamically through this.

12)
	Virtual File Systems: There are numerous ways for a device driver (or other kernel component) to provide information to the user or system administrator. One useful technique is the creation of virtual files, in debugfs, /proc or elsewhere. Virtual files can provide human-readable output that is easy to get at without any special utility programs.

	virtual file system reside in RAM memeory. They do not take any space in harddisk or any storage media. /proc/ /debugfs and /sys file systems are example of this. But SATA etc. take space in storage media.

	Proc File System: Proc is a pseudo file system for interfacing with the kernel internal data structures. As a user, you can use proc files for system diagnostics – CPU, memory, Interrupts and many more. You can also configure a lot of parameters like scheduler parameters, kernel objects, memory and more. The common interaction with proc is using cat and echo from the shell. For example:
		# cat /proc/cpuinfo
		# echo "50"> /proc/sys/kernel/sched_rr_timeslice_ms

	It has proc has may modules such as modules, cpuinfo, meminfo. procfs is for processes. sysfs is for kernel. But still some legacy are using procfs.
		cat /proc/cmdline
		cat /proc/<pid>
		cat /proc/misc
		cat /proc/devices
		cat /proc/memeinfo
		cat /proc/uptime

	Creating Directory in /proc:
		Header Files: <linux/proc_fs.h>
		struct proc dir entry* proc_mkdir(const char *name, struct proc dir entry * parent);
			name: The name of the folder that will be created under /proc.
			Parent: In case the folder needs to be created in a sub folder under /proc a pointer to the same is passed else it can be left as NULL

	Creating a proc file:
		Header File: <linux/proc_fs.h>
		static inline struct proc_dir_entry *proc_create(const char *name, 
								 umode_t mode,
								 struct proc_dir_entry *parent, 
								 const struct file_operations *proc_fops);
			name: The name of the proc entry
			mode: The access mode for proc entry
			parent: The name of the parent directory under /proc
			proc_fops: The structure in which the file operations for the proc entry will be created.

	Removing a proc entry: When a module is removed from the kernel, it should also remove any proc entries it created. The function that enables the removal of proc entry is "remove_proc_entry" which has the following prototype:
		void remove_proc_entry(const char *name, struct proc_dir_entry *parent);
			name: Name of the proc entry that has to be removed.
			parent: In case the proc entry lies in a subdirectory under the proc filesystem, we can pass the subdirectories here.

	Theory4,5,6,7: see example 4,5,6,7 to get complete picture.

	If you only need a single function entry (call) to produce all the desired proc-fs output, just use single_open() and single_release(). single_open() gets a parameter that is the "show" function for the data that is to be written to /proc.
		int single_open(struct file *file, int (*show)(struct seq_file *m, void *p), void *data);

	The "show" function does everything that is needed to write the data, all in one function call. The data value given to single_open() can be found in the private field of the seq_file structure. This is useful either for writing small amounts of data to /proc, for cases in which the output is not iterative, or for cases in which recursion is more appropriate, since the non-single methods don't fit well with recursive techniques. When using single_open(), the programmer should use single_release() instead of seq_release() in the file_operations structure to avoid a memory leak.
		struct proc_dir_entry *proc_create_data(const char *name, umode_t mode,struct proc_dir_entry *parent,
												const struct file_operations *proc_fops,void *data);
			name: The name of the proc entry 
			mode: The access mode for proc entry 
			parent: The name of the parent directory under /proc 
			proc_fops: The structure in which the file operations for the proc entry will be created. 
			data: If any data needs to be passed to the proc entry. 

	To access the data in the proc_dir_structure we need to make use of the function PDE_DATA to which we pass the file pointer. The function in turn returs a pointer to the data that was passed during the creation of the proc entry. See how proc_fs_mul prints 3 times in this example.

	SEQ_START_TOKEN is a special value which can be returned by the start() function. It can be used if you wish to instruct your show() function to print a header at the top of the output. SEQ_START_TOKEN should only be used if the offset is zero, however.

13)
	What is physical address space? The entire range of memory addresses accessible by processors is often referred to as physical address space. 32 Bit systems can have address space of 2^32 = 4 GB. This Physical address space is used by
		--->	RAM
		--->	BIOS
		--->	APIC
		--->	PCI
		--->	Other Memory Mapped I/O Devices
		+------------------+  <- 0xFFFFFFFF (4GB)
		|      32-bit      |
		|  memory mapped   |
		|     devices      |
		|                  |
		/\/\/\/\/\/\/\/\/\/\

		/\/\/\/\/\/\/\/\/\/\
		|                  |
		|      Unused      |
		|                  |
		+------------------+  <- depends on amount of RAM
		|                  |
		|                  |
		| Extended Memory  |
		|                  |
		|                  |
		+------------------+  <- 0x00100000 (1MB)
		|     BIOS ROM     |
		+------------------+  <- 0x000F0000 (960KB)
		|  16-bit devices, |
		|  expansion ROMs  |
		+------------------+  <- 0x000C0000 (768KB)
		|   VGA Display    |
		+------------------+  <- 0x000A0000 (640KB)
		|                  |
		|    Low Memory    |
		|                  |
		+------------------+  <- 0x00000000
	$ cat /proc/iomem. This file shows you the current map of the system's memory for each physical device.

	Virtual Address Space for 32-bit processors: On Linux, every memory address is virtual. They do not point to any address in the RAM directly. Whenever you access a memory location, a translation mechanism is performed in order to match the corresponding phyical memory. On Linux Systems, each process owns a virtual address space. Size of the virtual address space is 4GB on 32-bit systems (even on a system with physical memory less than 4 GB). Linux divides this virtual address space into:
		--->	an area for applications, called user space
		--->	an area for kernel, called kernel space/process space
	The split between the two is set by a kernel configuration parameter named PAGE_OFFSET. This is called 3G/1G Split.
		  .------------------------. 0xFFFFFFFF
		  |                        | (4 GB)
		  |    Kernel addresses    |
		  |                        |
		  |                        |
		  .------------------------.CONFIG_PAGE_OFFSET
		  |                        |(x86: 0xC0000000, ARM: 0x80000000)
		  |                        |
		  |                        |
		  |  User space addresses  |
		  |                        |
		  |                        |
		  |                        |
		  |                        |
		  '------------------------' 00000000
	IMP: User address space is allocated per process, so that each process runs in a sandbox, separated from others.
	IMP: The kernel address space is same for all process; there is only one kernel.

	Why kernel shares its address space with every process:
		--> Every single process uses system calls, which will involve the kernel
		--> Mapping the kernel's virtual memory address into each process virtual address space allows us to avoid the cost of switching out the memory address space on each entry to and exit from the kernel

	if one process updates golbal variable in kernel, then if second process comes and sees variable. Then it will see updated variable. 64- bit memory map:
		===========================================================================================
			Start addr    |   Offset   |     End addr     |  Size   | VM area description
		===========================================================================================
						  |            |                  |         |
		 0000000000000000 |    0       | 00007fffffffffff |  128 TB | user-space virtual memory
		__________________|____________|__________________|_________|______________________________
						  |            |                  |         |
		 0000800000000000 | +128    TB | ffff7fffffffffff | ~16M TB | non-canonical ( what is this ? )
		__________________|____________|__________________|_________|______________________________
						  |            |                  |         |
		 ffff800000000000 | -128    TB | ffffffffffffffff |  128 TB | kernel-space virtual memory
		__________________|____________|__________________|_________|______________________________

	Documentation/x86/x86_64/mm.txt. how much RAM installed in machine ? [ free -m ] or /proc/meminfo. [ make menuconfig ] gives kernel configurations in QEMU.

	Kinds of Memory: Kernel and user space work with virtual addresses. These virtual addresses are mapped to physical addresses by memory management hardware (MMU).
		Header File: #include <asm/io.h>
			phys_addr = virt_to_phys(virt_addr);
			virt_addr = phys_to_virt(phys_addr);
		[ uname -a ] shows 64-bit / 32-bit machine type. i686=32-bit, x86_64=64-bit. buildroot generates linux images for lightweight targets. Yocto is for heavy weight.

	Pages: Virtual address space (0x00000000 to 0xffffffff) is divided into pages of 4096 bytes. The page size may differ in other systems. But on ARM and x86 it is fixed. The size of a page is defined in the kernel through the PAGE_SIZE macro. Pages in the virtual address space are mapped to physical addresses by the Memory Management Unit(MMU), which uses page tables to perform the mapping.

	Memory Page/Virtual Page/Page:
		Refers to a fixed length contiguous block of virtual memory.
		Kernel data structure to represent a memory page is struct page.

	Frame/Page Frame:
		Refers to a fixed length contiguous block of physical memory on top of which the OS maps a memory page.
		Each page frame is given a page frame number (PFN).
		Given a page, you can easily get its PFN and vice versa, using page_to_pfn/pfn_to_page macros.

	Page Table:
		Kernel and architecture data structure used to store the mapping between virtual addresses and physical addresses.
		Each entry describes key pair page/frame.

	Command to find out page size: $ getconf PAGESIZE or $ getconf PAGE_SIZE

	Kernel represents every virtual page on the system with struct page structure.
		Header File: <linux/mmtypes.h>
		struct page {
				unsigned long flags;
			atomic_t      _count;
			void          *virtual;
			....
		};

	Flags: Status of the page: Dirty, locked in memory.
		Values: <linux/page-flags.h>
		_count : Usage count of the page. How many references are to this page. When page is free _count is negative one
		virtual: Page's virtual Address.

	with 4KB Page Size and 4GB of Physical Memory = 1048576 Pages
	Each page is taking 64 bytes = 1048576*64 = 64 MB is used to store all the physical pages

	Kernel memory is managed in a fairly straightforward way. It is not demand-paged, meaning that, for every allocation using kmalloc() or similar function, there is real physical memory. Kernel memory is never discarded or paged out. Linux employs a lazy allocation strategy for user space, only mapping physical pages of memory when the program accesses it. For example, allocating a buffer of 1 MiB using malloc(3) returns a pointer to a block of memory addresses but no actual physical memory. A flag is set in the page table entries such that any read or write access is trapped by the kernel. This is known as a page fault. Only at this point does the kernel attempt to find a page of physical memory and add it to the page table mapping for the process.

	See example 4 to check page fault.

	A page fault is generated when the kernel traps an access to a page that has not been mapped. In fact, there are two kinds of page fault: minor and major. With a minor fault, the kernel just has to find a page of physical memory and map it into the process address space. A major page fault occurs when the virtual memory is mapped to a file, for example using mmap(2). Major faults are much more expensive in time and system resources. Here, program pagefault diffrence is 256 for 1kb request and 1024 for 4kb.

	User space virtual address space:
			 address|-------------------| command-line arguments
					|-------------------| and environment variables
					|        stack      |
					|-------------------|
					|	                |
					|		            |
					|		            |
					|-------------------|
					|		heap        |
					|-------------------|
					|uninitialized data | initialized to
					|		        (bss| zero by exec
					|-------------------|
					| initialized data  | read from
					|-------------------| program file
					|		text        | by exec
		low address |-------------------|
				Typical memory arrangement

	we can check it using [ $ cat /proc/pid/maps ]. [ cat /proc/self/maps ] gives address space for current process bash.

	Low and High Memory: The Linux kernel has its own virtual address space, as every user mode process does. The kernel code and data structures must fit into that space, but the biggest consumer of kernel address space is virtual mappings for physical memory. The kernel to access physical memory should first map it into the kernel's virtual address space.

	Maximum amount of physical memory handled by the kernel = amount that could be mapped into the kernel's portion of virtual address space - Space used by kernel code.

	As, a result x86 based Linux systems could work with a maximum of a little under 1 GB of physical memory. The virtual address space of the kernel (1 GB sized in a 3G/1G split) is divided into two parts:
		-->	Low memory or LOWMEM, which is the first 896 MB
		-->	High memory or HIGHMEM, represented by the top 128 MB

											   Physical mem
		   Process address space    +------> +------------+
									|        |  3200 M    |
									|        |            |
		4 GB+---------------+ <-----+        |  HIGH MEM  |
			|     128 MB    |                |            |
			+---------------+ <---------+    |            |
			+---------------+ <------+  |    |            |
			|     896 MB    |        |  +--> +------------+
		3 GB+---------------+ <--+   +-----> +------------+
			|               |    |           |   896 MB   | LOW MEM
			|     /////     |    +---------> +------------+
			|               |
		0 GB +---------------+

	Low Mem: The first 896 MB of kernel address space constitutes the low memory region. Early in the boot, the kernel permanently maps this 896MB. Addresses that result from this mapping are called logical addresses. These are virtual addresses, but can be translated into physical addresses by subtracting a fixed offset, since the mapping is permanent and known in advance. You can convert a physical address into a logical address using the __pa(address) macro, and then revert it with the __va(address) macro. Low memory matches with the lower bound of physical addresses. In fact, to serve different purposes, kernel memory is divided into a zone. We can then identify three different memory zones in the kernel space:
		ZONE_DMA: This contains page frames of memory below 16 MB, reserved for Direct Memory Access (DMA). Useful for device that can't access other memory regions.
		ZONE_NORMAL: This contains page frames of memory above 16 MB and below 896 MB, for normal use
		ZONE_HIGHMEM: This contains page frames of memory at and above 896 MB
	On a 512 MB system, there will be no ZONE_HIGHMEM, 16 MB for ZONE_DMA, and 496 MB for ZONE_NORMAL. [ check it on QEMU, shown in video 43:00 ]

	High Memory: The top 128 MB of the kernel address space is called the high memory region. It is used by the kernel to temporarily map physical memory above 1 GB. When physical memory above 1GB (or more precisely 896MB) needs to be accessed, the kernel uses those 128MB to create a temporary mapping to its virtual address space, thus achieving the goal of being able to access all physical pages. The physical memory above 896 MB is mapped on demand to the 128 MB of the HIGHMEM region. Mapping to access high memory is created on the fly by the kernel, and destroyed when done. This makes high memory access slower. Concept of high memory does not exist on 64-bit systems, due to the huge address range (2^64), where the 3G/1G split does not make sense anymore. High memeory concep is required only because of 4GB restriction.

	Memory allocation mechanism:
		----------------------------------
		|   Kernel                       |
		|   Module                       |
		----------------------------------
			|           |   |       |
			v           |   |       v
		----------      |   |   -----------
		|         |     |   |   |         |
		|kmalloc  |     |   |   |vmalloc  |
		|allocator|     |   |   |allocator|
		----------      |   |   -----------
		   |            |   |
		   v            v   |
		-----------------   |
		| slab          |   |
		| allocator     |   |
		----------------    |
			|               |
			v               v
		------------------------------------------
		|   Page Allocator                       |
		|Allocate physical memory by chunk of 4k |
		------------------------------------------
				|
				|
				v
		---------------------------------------
		|   Main Memory                       |
		|                                     |
		---------------------------------------

	There is an allocation mechanism to satisfy any kind of memory request. Depending on what you need memory for, you can choose the one closest to your goal. The main allocator is the page allocator, which only works with pages (a page being the smallest memory unit it can deliver). Then comes the SLAB allocator which is built on top of the page allocator, getting pages from it and returning smaller memory entities (by mean of slabs and caches). This is the allocator on which the kmalloc allocator relies. [ cat /proc/slabinfo ] gives info about slab.

	kmalloc family allocation: kmalloc is a kernel memory allocation function, such as malloc() in user space. Memory returned by kmalloc is contiguous in physical memory and in virtual memory:

						virtual memory    physical memory
						----------        --------
				   - - -|        |------- |      |
		kmalloc   /     |        |        |      |
		---------/      |        |        |      |
		|       |       |        |        |      |
		|       |   --- |        |------- |      |
		|       |  /    |        |        |      |
		|       | /     |        |        |      |
		---------/      |        |        |      |
						|        |        |      |
						|        |        |      |
						|        |        |      |
						|        |        |      |
						|        |        |      |
						----------        --------

	kmalloc allocator is the general and higher-level memory allocator in the kernel, and relies on SLAB Allocator. Memory returned from kmalloc has a kernel logical address because it is allocated from the LOW_MEM region, unless HIGH_MEM is specified.
		Header File: #include <linux/slab.h>
		void *kmalloc(size_t size, int flags); 
			size: specifies the size of the memory to be allocated (in bytes).
			flags: determines how and where memory should be allocated. 
				Available flags are the same as the page allocator (GFP_KERNEL, GFP_ATOMIC, GFP_DMA, and so on)
			Return Value: On Success, returns the virtual address of the chunk allocated, which is guaranteed to be physically contiguous.  On error, it returns NULL
		Flags:
			GFP_KERNEL: This is the standard flag. We cannot use this flag in the interrupt handler because its code may sleep. It always returns memory from the LOM_MEM zone (hence a logical address).
			GFP_ATOMIC: This guarantees the atomicity of the allocation. The only flag to use when we are in the interrupt context.
			GFP_USER: This allocates memory to a user space process. Memory is then distinct and separated from that allocated to the kernel.
			GFP_HIGHUSER: This allocates memory from the HIGH_MEMORY zone.
			GFP_DMA: This allocates memory from DMA_ZONE.

	kfree:The kfree function is used to free the memory allocated by kmalloc.
		void kfree(const void *ptr) 
		Memory corruption can happen:
			--->    on a block of memory that already has been freed
			--->    on a pointer that is not an address returned from kmalloc()
	Always balance allocations and frees to ensure that kfree() is called exactly once on the correct pointer

14)
	zones: Linux kernel divides physical RAM into a number of different memory regions: zones. What memory regions(zones) there are depends on whether your machine is 32-bit or 64-bit and also how complicated it is. Zones:
		1. DMA: low 16 MBytes of memory. At this point it exists for historical reasons. There were hardware that could only do DMA into this area of physical memory.
		2. DMA32:	exists only in 64-bit Linux. It is the low 4 GBytes of memory, more or less. It exists because the transition to large memory 64-bit machines has created a class of hardware that can only do DMA to the low 4 GBytes of memory.
		3. Normal: It is different on 32-bit and 64-bit machines. On 64-bit machines, it is all RAM from 4GB or so on upwards. On 32-bit machines it is all RAM from 16 MB to 896 MB for complex and somewhat historical reasons. Note that this implies that machines with a 64-bit kernel can have very small amounts of Normal memory unless they have significantly more than 4GB of RAM. For example, a 2 GB machine running a 64-bit kernel will have no Normal memory at all while a 4 GB machine will have only a tiny amount of it. We will have only DMA zone.
		4. HighMem:	exists only on 32-bit Linux. It is all RAM above 896 MB, including RAM above 4 GB on sufficiently large machines.

	Within each zone, Linux uses a buddy-system allocator to allocate and free physical memory.
	Buddy Allocator: Memory is broken up into large blocks of pages where each block is a power of two number of pages (2^order). Starts from 4KB page. All free pages are split into 11 (MAX_ORDER) lists, each contains a list of 2^order pages. [ check all 11 columns in /proc/buddyinfo ] [ watch video 9:00-12:00 ].

	When an allocation request is made for a particular size, the buddy system looks into the appropriate list for a free block, and returns its address, if available. However, if it cannot find a free block, it moves to check in the next high-order list for a larger block, which if available it splits the higher-order block into equal parts called buddies, returns one for the allocator, and queues the second into a lower-order list. When both buddy blocks become free at some future time, they are coalesced to create a larger block. [ /proc/buddyinfo ] shows all zones present.

	Using the buddy algorithm, each column represents the number of pages of a certain order (a certain size) that are available at any given time. check available RAM using [ free -m ]

	# cat /proc/buddyinfo 
	Node 0, zone      DMA      1      1      0      1      2      1      1      0      1      1      3
	Node 0, zone   Normal      1      1      1      1      3      1      1      2      3      4    207
	Node 0, zone  HighMem     22      8      4      1      1      1      1      1      1      2     34

	highmem will not be present if it has only 512 MB memory. Verify by configuring QEMU and then running /proc/buddyinfo ( video 5:00 ). This means, zone DMA, there are 1 of 2^(0*PAGE_SIZE) free chunks of memory, 1 of 2^(1)*PAGE_SIZE, 0 of 2^(2)*PAGE_SIZE and so on upto 3*(2^10)*PAGE_SIZE = Nearly 16 MB

	virtual kernel memory layout:
	x86: You can see in dmesg | grep -A 10 'virtual kernel memory layout'
	x86_64: Documentation/x86/x86_64/mm.rst

	can I use virt_to_phys for user space memory in kernel module? Can I use virt_to_phys to get the physical address returned by malloc ?
		virt_to_phys: The returned physical address is the physical (CPU) mapping for the memory address given. It is only valid to use this function on addresses directly mapped or allocated via kmalloc. It means It is used by the kernel to translate kernel virtual address (not user virtual address) to physical address

	What is the maximum size allocatable using kmalloc? The upper limit (number of bytes that can be allocated in a single kmalloc request), is a function of:
		the processor – really, the page size – and the number of buddy system freelists (MAX_ORDER). ( check in include/linux/slab.h [ IMP: video 24:00 - 29:00 ] )

	On both x86 and ARM, with a standard page size of 4 Kb and MAX_ORDER of 11
		#define KMALLOC_SHIFT_MAX       (MAX_ORDER + PAGE_SHIFT - 1)
		MAX_ORDER = 11 , PAGE_SHIFT = 12 = 11 + 12 -1 = 22
		/* Maximum allocatable size */
		#define KMALLOC_MAX_SIZE        (1UL << KMALLOC_SHIFT_MAX) = 2^22 = 4*1024*1024 = 4MB

	What happens if we don't free the memory allocated by kmalloc? Kernel memory is never freed automatically, even after module removal. [ RAM size/available can be fetched [ cat /proc/meminfo ] ]. ( watch video 25:00 - 35:00 ). Unlike this, in user space, malloc allocated memory gets leaked but claimed back when process is removed.

	kmalloc may internally round up allocations and return more memory than requested. ksize() can be used to determine the actual amount of memory allocated. The caller may use this additional memory, even though a smaller amount of memory was initially specified with the kmalloc call. This function is not often needed; callers to kmalloc() usually know what they allocated. It can be useful, though, in situations where a function needs to know the size of an object and does not have that information handy.

	kzalloc works like kmalloc, but also zero the memory.
		void *kzalloc(size_t size, gfp_t flags);

	Memory allocated by kmalloc() can be resized by:
		void *krealloc(const void *p, size_t new_size, gfp_t flags);

	The kmalloc() function returns physically and virtually contiguous memory. Physically contiguous memory has two primary benefits.
			1.  many hardware devices cannot address virtual memory.
			2.  a physically contiguous block of memory can use a single large page mapping. This minimizes the translation lookaside buffer (TLB) overhead of addressing the memory
	Allocating physically contiguous memory has one downside: it is often hard to find physically contiguous blocks of memory, especially for large allocations.

	vmalloc: Memory returned by vmalloc is only contiguous in virtual memory and not in physical memory.
						virtual memory    physical memory
						----------        --------
				   - - -|        |--------|      |
		vmalloc   /     |        |        |      |
		---------/      |        |--------|      |
		|       |       |        |\       |      |
		|       |   --- |        | \      |      |
		|       |  /    |        |\ ----- |      |
		|       | /     |        | \      |      |
		---------/      |        |  ------|      |
						|        |        |      |
						|        |        |      |
						|        |        |      |
						|        |        |      |
						|        |        |      |
						----------        --------
	The returned memory always comes from HIGH_MEM zone. HIGH_MEM zone is in only 32-bit machines. 64-bit machines don't have it.

	What is the maximum size allocatable using vmalloc? Unlike kmalloc(), it will keep allocating till RAM size. Theoratically, /proc/meminfo -> vmalloctotal shows how much can we allocate.
		[ bc -q ] launches calculator ?
		[ /fs/proc/meminfo ] has vmalloc related proc calls.

	Can i use ksize with vmalloc? According to the documentation, "The caller must guarantee that objp points to a valid object previously allocated with either kmalloc() or kmem_cache_alloc()." 

	Maximum Amount of memory can be allocated using vmalloc: The vmalloc upper limit is, in theory, the amount of physical RAM on the system. Kernel reserves an architecture (cpu) specific “range” of virtual memory for the purpose of vmalloc: from VMALLOC_START to VMALLOC_END.
		Header file: <asm/pgtable.h>

	Differences between vmalloc and kmalloc:
		1. Physical Memory:
			kmalloc: Guarantees the pages are physically contiguous and virtually contiguous
			vmalloc: It allocates virtually contiguous but not necessarily physically contiguous
		2. Low Mem vs High Mem:
			kmalloc: Returns from Low Memory
			vmalloc: Returns from High Memory
		3. Usage:
			kmalloc: Memory returned Can be used by hardware devices(DMA, IMP: PCI ( https://stackoverflow.com/questions/116343/what-is-the-difference-between-vmalloc-and-kmalloc ))
			vmalloc: Memory returned Cannot be used by hardware devices
		4. Interrupt Context:
			kmalloc: can be used in interrupt context with 'GFP_ATOMIC'
			vmalloc: cannot be used in interrupt context
		5. Allocator:
			kmalloc: Uses slab allocator which in turn use Page Allocator
			vmalloc: Directly uses Page Allocator
		6. Overhead:
			kmalloc: less overhead
			vmalloc: more overhead, as each vmalloc requires page table changes and a translation look aside buffer invalidation.
		7. Size:
			kmalloc: Cannot give large memory
			vmalloc: Useful for allocating large memory and no requirement of physical contiguous

	kmalloc(0) returns a special ZERO_SIZE_PTR value. It is a non-NULL value which looks like a legitimate pointer, but which causes a fault on any attempt at dereferencing it. Any attempt to call kfree() with this special value will do the right thing, of course.

	Kernel Stack. In a Linux System, every process has 2 stacks:
		User stack
		Kernel stack ( when process run in kernel space for given space )

	User Stack in x86: Resides in user address space (0-3GB in 32-bit x86)
	Kernel Stack in x86: Resides in kernel address space(3GB-4GB in 32-bit x86)

	User space is afforded the luxury of a large, dynamically growing stack, whereas the kernel has no such luxury. The kernel's stack is small and fixed. Size of the per-process kernel stacks depends on both the architecture and a compile-time option. When the option is enabled, each process is given only a single page - 4KB on 32-bit architectures and 8KB on 64-bit architectures. Why only one page?
		1. Less memory consumption per process
		2. As uptime increases, it becomes increasingly hard to find two physically contiguous unallocated pages.

	Historically, interrupt handlers also used the kernel stack of the process they interrupted. As it placed tighter constraints on the already smaller kernel stack. Kernel developers implemented a new feature: interrupt stacks. Interrupts use their own stacks. It consumes only a single page per processor. Now, we have a kernel stack size of 16KB from Linux 3.15 in x86_64.

	CONFIG_FRAME_WARN: This kernel configuration option passes an option to the compiler to cause it to emit a warning when a static stack size for a routine is detected that is larger than the specified threshold. It requires gcc version 4.4 or later in order to work. The gcc option used is "-Wframe-larger-than=xxx". By default, CONFIG_FRAME_WARN has the value of 1024, but you can set it to any value from 0 to 8192. Linux kernel defines stack size 8192 bytes for each process. The sum of the stack frames of all active functions should not overflow 8192 bytes. This warning does not guarantee that you will overflow the stack space; it just shows that this function makes an overflow more likely (when used together with other big-frame functions, or with many smaller functions).

	There's a way to get a list of how much stack space each function in your program uses. checkstack.pl. It prints out a list of functions and their stack usage, biggest first.
		$ objdump -D hello.ko | perl ~/linux-5.2.8/scripts/checkstack.pl
	Note: it can't take into account recursive functions. It only performs static analysis

15)
	Linux Kernel Code provides several data structures: Linked lists, Queues, Maps, Binary trees. These generic data structures are provided to encourage code reuse.

	Linked list is the simplest and most common data structure in the Linux Kernel. Linked list allows to have variable number of elements called nodes of the list. Elements in Linked List are dynamically created at run time, and they do not necessarily occupy contiguous regions in memory. Therefore elements needs to be linked together. Each element in the list contains a pointer to the next element. As elements are added and removed from the list, the pointer to the next node is simply adjusted. Types:
		1. Singly Linked Lists
		2. Doubly Linked Lists
		3. Circular Linked Lists

	instead of referrig to this course, can we go through just: https://demystifyingme.wordpress.com/2017/06/10/kernel-data-structures-linkedlist/ ?

16)
		int *ptr = NULL;

		int* getmem(){
			if (!ptr) {
				ptr = kmalloc(sizeof(int), GFP_KERNEL);
				if (!ptr)
					return -ENOMEM;
			}
			return ptr;
		}

	concurreny issue: because ptr is global, two threads share this varibale and if one updates it, other thread will also get updated value and then concurreny issues may happen.

	concurrency: the ability to handle multiple outstanding tasks/process with the illusion or reality of simultaneity. Single Core Environment(fake parallelism): concurrency is achieved via a process called context-switching i.e., at a particular time period, only a single task gets executed. If we see multiple processes running on single processor, then only one is running and other are waiting. Because processor can run a single process at a time.

	Multi Core Environment(true parallelism): Multiple processes executing simultaneously on multiple processors/CPU's.

	How to find out how many cores you have? $ grep -c ^processor /proc/cpuinfo. $ nproc

	How to find the processor number in which process is running? $ ps -eaF. The PSR column shows which <process> is running on which processor <number>

	Multiprocessing systems:
	initial approach:
		Each CPU has its own OS. The simplest possible way to organize a multiprocessor operating system. statically divide memory into as many partitions as there are CPUs and give each CPU its own private memory and its own private copy of the operating system. One obvious optimization is to allow all the CPUs to share the operating system code and make private copies of only the data

			cpu1            cpu2            cpu3           cpu4         Memory               IO
			--------        ---------       ---------      ----------   -----------          ---------
			|Private|       |private|       |Private |     |Private |   |1   |2    |         |        |
			|OS     |       |OS     |       |OS      |     |OS      |   |Data|Data |         |        |
			--------        ---------       ---------       ----------  ---------- |         |        |
			  | |             | |             | |             | |       |3   |4    |         |        |
			  | |             | |             | |             | |       |Data|Data |         |        |
			  | |             | |             | |             | |       -----------|         ----------
			  | |             | |             | |             | |       |OS Code   |              | |
			  | |             | |             | |             | |       -----------               | |
			  | |             | |             | |             | |            | |                  | |
			  | |             | |             | |             | |            | |                  | |
			--  --------------  --------------   --------------  ------------  -------------------   -----
						BUS
			-----------------------------------------------------------------------------------------------

		Problems with this approach:
			1. When a process makes a system call, the system call is caught and handled on its own CPU using the data structures in the operating system's tables. So, one CPU can't handle other's system calls.
			2. since each operating system has its own tables, it also has its own set of processes that it schedules by itself. There is no sharing of processes. As a consequence, it can happen that CPU 1 is idle while CPU 2 is loaded with work.
			3. no sharing of pages. It can happen that CPU 1 has pages to spare while CPU 2 is paging continuously. There is no way for CPU 2 to borrow some pages from CPU 1 since the memory allocation is fixed.
			4. if the operating system maintains a buffer cache of recently used disk blocks, each operating system does this independently of the other ones. Thus it can happen that a certain disk block is present and dirty in multiple buffer caches at the same time, leading to inconsistent results.

	A master-slave multiprocessor model:
		One copy of OS and its tables are present on CPU1 and not on any of the others. All system calls are redirected to CPU 1 for processing there. CPU 1 may also run user processes if there is CPU time left over. This model is called master-slave since CPU 1 is the master and all the others are slaves.

			cpu1            cpu2/slave      cpu3/slave      cpu4/slave    Memory              IO
			--------        ---------       ---------       ----------    -----------         ---------
			|Master |       |user   |       |user    |      |user    |    |User      |        |        |
			|runs OS|       |process|       |process |      |process |    |Processes |        |        |
			--------        ---------       ---------       ----------    |          |        |        |
			  | |             | |             | |             | |         |          |        |        |
			  | |             | |             | |             | |         |          |        |        |
			  | |             | |             | |             | |         -----------|        ----------
			  | |             | |             | |             | |         |OS Code   |            | |
			  | |             | |             | |             | |         -----------             | |
			  | |             | |             | |             | |            | |                  | |
			  | |             | |             | |             | |            | |                  | |
			--  --------------  --------------   --------------  ------------  -------------------   -----
						BUS
			-----------------------------------------------------------------------------------------------

		The master-slave model solves most of the problems of the first model. 
			1. There is a single data structure (e.g., one list or a set of prioritized lists) that keeps track of ready processes.When a CPU goes idle, it asks the operating system for a process to run and it is assigned one.  Thus it can never happen that one CPU is idle while another is overloaded.
			2. Similarly, pages can be allocated among all the processes dynamically and there is only one buffer cache, so inconsistencies never occur.

		Problem:
			The problem with this model is that with many CPUs, the master will become a bottleneck. After all, it must handle all system calls from all CPUs. If, say, 10% of all time is spent handling system calls, then 10 CPUs will pretty much saturate the master, and with 20 CPUs it will be completely overloaded. Thus this model is simple and workable for small multiprocessors, but for large ones it fails.

	Symmetric Multiprocesors (SMP):
		One copy of the OS  is in memory, but any CPU can run it.

		UP: User Process
			cpu1            cpu2            cpu3           cpu4         Memory               IO
			--------        ---------       ---------      ----------   -----------          ---------
			|Shared |       |Shared |       |Shared  |     |Shared  |   |          |         |        |
			|OS/UP  |       |OS/UP  |       |OS/UP   |     |OS/UP   |   |          |         |        |
			--------        ---------       ---------      ----------   |          |         |        |
			  | |             | |             | |             | |       |          |         |        |
			  | |             | |             | |             | |       |          |         |        |
			  | |             | |             | |             | |       -----------|         ----------
			  | |             | |             | |             | |       |OS Code   |              | |
			  | |             | |             | |             | |       -----------               | |
			  | |             | |             | |             | |            | |                  | |
			  | |             | |             | |             | |            | |                  | |
			--  --------------  --------------   --------------  ------------  -------------------   -----
						BUS
			-----------------------------------------------------------------------------------------------

		Advantage: eliminates the master CPU bottleneck, since there is no master

		Problems:
		Imagine two CPUs simultaneously picking the same process to run or claiming the same free memory page. The simplest way around these problems is to associate a mutex (i.e., lock) with the operating system, making the whole system one big critical region. When a CPU wants to run operating system code, it must first acquire the mutex. If the mutex is locked, it just waits. In this way, any CPU can run the operating system, but only one at a time. It is called big kernel lock.

		With 20 CPUs, there will be long queues of CPUs waiting to get in. Fortunately, it is easy to improve. Many parts of the operating system are independent of one another. For example, there is no problem with one CPU running the scheduler while another CPU is handling a file system call and a third one is processing a page fault. This observation leads to splitting the operating system up into independent critical regions that do not interact with one another. Each critical region is protected by its own mutex, so only one CPU at a time can execute it.

	Preemption means forcefully taking away of the processor from one process and allocating it to another process. Switching. Whereas, Switching from one running task/process to another/process is known as context switch. In the Linux kernel, the scheduler is called after each timer interrupt (that is, quite a few times per second). It determines what process to run next based on a variety of factors, including priority, time already run, etc.

	Difference between preemption and context switch?
		Preemption: Firing of timer interrupt is preempting the current running process and running the interrupt service routine of timer interrupt.
		Context Switch: what happens when the kernel alters the state of the processor (the registers, mode, and stack) between one process or thread's context and another. 

	context_switch() function is called in the kernel. Under Linux, user-space programs have always been preemptible: the kernel interrupts user-space programs to switch to other threads, using the regular clock tick. So, the kernel doesn't wait for user-space programs to explicitly release the processor. This means that an infinite loop in an user-space program cannot block the system.

	Kernel Space: one can enable or disable it using the CONFIG_PREEMPT option. If CONFIG_PREEMPT is enabled, then kernel code can be preempted everywhere, except when the code has disabled local interrupts. An infinite loop in the code can no longer block the entire system.

	my understanding: so there is no relation between user space and kernel space process. Only kernel scheduler selects those and runs on SMP using different CPUs. So, kernel and user processes are just different in process types, nothing else ?

	Kernel preemption can occur:
		When returning to kernel-space from an interrupt handler
		When kernel code becomes preemptible again
		If a task in the kernel explicitly calls schedule()
		If a task in the kernel blocks (which results in a call to schedule())

	Case1: 
		While process A executes an exception handler (necessarily in Kernel Mode), a higher priority process B becomes runnable. This could happen, for instance, if an IRQ occurs and the corresponding handler awakens process B. As the kernel is preemptive, a forced process switch replaces process A with B. The exception handler is left unfinished and will be resumed only when the scheduler selects again process A for execution.

	Case2:
		consider a process that executes an exception handler and whose time quantum expires. As the kernel is preemptive, the process may be replaced immediately.

	Motivation for making the kernel preemptive: reduce the dispatch latency of the User Mode processes. the delay between the time they become runnable and the time they actually begin running. Processes performing timely scheduled tasks (such as external hardware controllers, environmental monitors, movie players, and so on) really benefit from kernel preemption, because it reduces the risk of being delayed by another process running in Kernel Mode.

	scheduler itself also is a process. It is scheduled by timer. When timer interrupt fires, in interrupt handler, scheduler gets called usually. Otherwise, by yielding also it can run. So, scheduler will run interrupt context/process context based on invokation path. at boot u-boot bootloader ( others also can based on design ) might start kernel. Then check [ cat /proc/interrupts ] for timer interrupt. Bringing Kernel from harddisk to RAM is done by bootloader like U-boot, GRUB ( x86 uses GRUB ). on x86, BIOS also. The moment kernel starts, it configures timer and then frequently gets updated.

	A kernel control path denotes the sequence of instructions executed by the kernel to handle a system call, an exception, or an interrupt. Linux kernel is reentrant. This means that several processes may be executing in Kernel Mode at the same time. On uniprocessor systems, only one process can progress, but many can be blocked in Kernel Mode when waiting for the CPU or the completion of some I/ O operation.

	Example:
		-->	after issuing a read to a disk on behalf of a process, the kernel lets the disk controller handle it and resumes executing other processes.
		-->	An interrupt notifies the kernel when the device has satisfied the read, so the former process can resume the execution.

	Reentrancy in Linux Kernel:
		1. Reentrant functions : They don't use/modify global data structures.
		2. Non reentrant functions: Modify global data structures but use locking mechanism

	( IMP: difference between thread safe v/s reentrant function ) (https://stackoverflow.com/a/33445858, https://uvdn7.github.io/reentrant/ )

	Synchronization and Critical Regions: Implementing a reentrant kernel requires the use of synchronization. If a kernel control path is suspended while acting on a kernel data structure, no other kernel control path should be allowed to act on the same data structure unless it has been reset to a consistent state. Otherwise, the interaction of the two control paths could corrupt the stored information.

	When the outcome of a computation depends on how two or more processes are scheduled, the code is incorrect. We say that there is a race condition. Any section of code that should be finished by each process that begins it before another process can enter it is called a critical region

	Causes of concurrency:
		1. Interrupts: An interrupt can occur asynchronously at almost any time; interrupting the currently executing code.
		2. Softirqs and tasklets: Kernel can raise or schedule a softirq or tasklet at almost any time.
		3. Kernel preemption: Because the kernel is preemptive, one task in the kernel can preempt another
		4. Sleeping and synchronization with user space: Task in the kernel can sleep and thus invoke the scheduler, resulting in running of a new process.
		5. Symmetrical multiprocessor: Two or more processors can execute kernel code at exactly the same time.

	Solutions:
		1. Kernel Preemption Disabling
				disabling kernel preemption
				critical region start 
				......
				.....
				critical region end
				enable kernel preemption
			Problem:
				On Multiprocessor, two kernel paths running on different CPUs can concurrently access the same global data.
		2. Disabling Hardware Interrupts
				Disabling Hardware Interrupts
				critical region start
				......
				......
				critical region end
				enable hardware interrupts
			Problem:
				If the critical region is large, interrupts can remain disabled for a relatively long time, potentially causing all hardware activities to freeze/ might get missed.
				On a multiprocessor system, disabling interrupts on the local CPU is not sufficient, and other synchronization techniques must be used.

	Maximum number of processors that an SMP kernel could support: $ grep NR_CPUS /boot/config-`uname -r`. You can override this with the nr_cpus kernel parameter in the bootloader command line. nr_cpus=12. Use num_online_cpus() function to get the number of cpus online.

	smp_processor_id() gives you the current processor number on which kernel is running. IMP: video 46:00 - 50:00

	Per CPU Variables: The simplest and most efficient synchronization technique consists of declaring kernel variables as per-CPU Variables. Basically a per CPU Variables is an array of data structures, one element  per each CPU in the system. A CPU should not access the elements  of the array corresponding to other CPU. It can freely read and modify its own element without fear of race conditions, because it is the only CPU Entitled to do so. The elements of the per-CPU array are aligned in main memory so that each data structure falls on a different line of the hardware cache.
		get_cpu() on top of returning the current processor number also disables kernel preemption.
		put_cpu() enables kernel preemption.

	Why is disabling kernel preemption needed ( look in program how it is getting called ? ). Just consider, for instance, what would happen 
		if a kernel control path gets the address of its local copy of a per-CPU variable, then it is preempted and moved to another CPU: the address still refers to the element of the previous CPU.

	percpu interface: The 2.6 kernel introduced a new interface, known as percpu, for creating and manipulating per-CPU data. Creation and manipulation of per-CPU data is simplified with this new approach. The previously discussed method of creating and accessing per-CPU data is still valid and accepted. This new interface, however, grew out of the needs for a simpler and more powerful method for manipulating per-CPU data on large symmetrical multiprocessing computers.
		Header File: <linux/percpu.h>. To create a per-CPU variable at compile time, use this macro
		DEFINE_PER_CPU(type, name);
			This creates an instance of a variable of type type, named name, for each processor on the system.

	You can access another processor's copy of the variable with: per_cpu(variable, int cpu_id); If you write code that involves processors reaching into each other's per-CPU variables, you, of course, have to implement a locking scheme that makes that access safe.

	Per-CPU Data at Runtime: Dynamically allocated per-CPU variables are also possible. While per-CPU variables provide protection against concurrent accesses from several CPUs, they do not provide protection against accesses from asynchronous functions (interrupt handlers and deferrable functions). In these cases, additional synchronization primitives are required.

17_1)
	Atomic Operations: Several assembly language instructions are of type “read-modify-write”. they access a memory location twice, the first time to read the old value and  the second time to write a new value.

	Suppose that two kernel control paths running on two CPUs try to “read-modify-write” the same memory location at the same time by executing nonatomic operations. At first, both CPUs try to read the same location, but the memory arbiter (a hardware circuit that serializes accesses to the RAM chips) steps in to grant access to one of them and delay the other. However, when the first read operation has completed, the delayed CPU reads exactly the same (old) value from the memory location. Both CPUs then try to write the same (new) value to the memory location; again, the bus memory access is serialized by the memory arbiter, and eventually both write operations succeed. However, the global result is incorrect because both CPUs write the same (new) value. Thus, the two interleaving “read-modify-write” operations act as a single one.

		Kernel Thread1              Kernel Thread2  
		------------------------------------------------------
		read i (5)
									read i(5)
		increment i(5 -> 6) 
									increment i (5 -> 6)
		write i(6)
									write i(6)

	Atomic Operations: The easiest way to prevent race conditions due to “read-modify-write” instructions is by ensuring that such operations are atomic at the chip level. Every such operation must be executed in a single instruction without being interrupted in the middle and avoiding accesses to the same memory location by other CPUs. Most CPU instruction set architectures define instruction opcodes that can perform atomic read-modify-write operations on a memory location. In general, special lock instructions are used to prevent the other processors in the system from working until the current processor has completed the next action.
		Header File: <asm/atomic.h>
		typedef struct { volatile int counter; } atomic_t;
	Why a new user defined data type atomic_t is needed? Because the atomic data types are ultimately implemented with normal C types, the kernel encapsulates standard variables in a structure that can no longer be processed with normal operators such as ++.

	What happens to atomic variables when the kernel is compiled without SMP Support? it works the same way as for normal variables (only atomic_t encapsulation is observed) because there is no interference from other processors

		atomic_t:
		Initialization: atomic_t i;  //define i
		Increment/Decrement: void atomic_inc(atomic_t *i);  //Add 1 to *i
		Set/Read: void atomic_set(atomic_t *i, int j); //Atomically set counter i to value specified in j
		Add/Sub: void atomic_add(int val, atomic_t *i); //Atomically add val to atomic counter i
		Atomic Operation and test: int atomic_dec_and_test(atomic_t *i); //atomic Subtract 1 from *i and return 1 if the result is zero; 0 otherwise
		Atomic Add/Subtract and return: int atomic_add_return(int val, atomic_t *i);// Atomically add val to *i and return the result.
		//Atomically adds val to i and return pre-addition value at i:  int atomic_fetch_add(int val, atomic_t *i);
		//Atomically subtracts val from i, and return pre-subtract value at i: int atomic_fetch_sub(int val, atomic_t *v);
		//Reads the value at location i, and checks if it is equal to old; if true, swaps value at v with new, and always returns value read at i: int atomic_cmpxchg(atomic_t *i, int old, int new);
		//Swaps the oldvalue stored at location i with new, and returns old value i: int atomic_xchg(atomic_t *i, int new);

	Common use of atomic operations:
		A common use of the atomic integer operations is to implement counters
		Protecting a sole counter with a complex locking scheme is overkill, so instead developers use 
		atomic_inc() and atomic_dec(), which are much lighter in weight.

	64-bit Atomic Operations: Many processor architectures have no 64-bit atomic instructions, but we need atomic64_t in order to support the perf_counter subsystem. This adds an implementation of 64-bit atomic operations using hashed spinlocks to provide atomicity.
		typedef struct {
			long long counter;
		} atomic64_t;

	Atomic Bitwise Operations: In addition to atomic integer operations, the kernel also provides a family of functions that operate at the bit level.
		Header File: <asm/bitops.h>
	These functions operate on generic pointer. There is no equivalent of the atomic integer atomic_t.

17_2)
	Problem with atomic instructions:
			Can only work with CPU word and double word size.
			Cannot work with shared data structures of custom size.

	In real life, critical regions can be more than one line. And these code paths such execute atomically to avoid race condition. To ensure atomicity of such code blocks locks are used.

	Spinlocks: The most common lock in the Linux kernel is the spin lock. Spinlocks are used to protect short code sections that comprise just a few C statements and are therefore quickly executed and exited. A spin lock is a lock that can be held by at most one thread of execution.

	When the thread tries to acquire lock which is already held? The thread busy loops/spins waiting for the lock to become available.
	When the thread tries to acquire lock which is available? The thread acquires the lock and continues.

	Spinlock Methods:
	initially, spinlock is unlocked.
		Header File: <linux/spinlock.h>
		Data Structure: spinlock_t
		Methods: DEFINE_SPINLOCK(my_lock);   == spinlock_t my_lock = __SPIN_LOCK_UNLOCKED(my_lock);

		From <linux/spinlock_types.h>:
			#define DEFINE_SPINLOCK(x)      spinlock_t x = __SPIN_LOCK_UNLOCKED(x)
			//To lock a spin lock: void spin_lock(spinlock_t *lock);
			//To unlock a spin lock: void spin_unlock(spinlock_t *lock);

		To initialize spin lock at run time. void spin_lock_init(spinlock_t *lock);

	on uniprocessor machines, spin lock exist when CONFIG_PREEMPT is not set/kernel preemption disabled. Spinlocks are defined as empty operations because critical sections cannot be entered by several CPUs at the same time. When CONFIG_PREEMPT is set:
		spin_lock  = preempt_disable
		spin_unlock = preempt_enable

	What happens if i acquire a lock which is already held by the same CPU? Spin locks are not recursive. Unlike spin lock implementations in other operating systems and threading libraries, the Linux kernel’s spin locks are not recursive. This means that if you attempt to acquire a lock you already hold, you will spin, waiting for yourself to release the lock. But because you are busy spinning, you will never release the lock and you will deadlock.

	int spin_trylock(spinlock_t *lock); Tries to acquire given lock.
		If not available, returns zero.
		If available, it obtains the lock and returns nonzero

	Can i use spinlock when the resource is shared between kernel control path in process context vs interrupt context?
		1. Your driver is executing and has taken a lock.
		2. Device the driver is handling issues a interrupt.
		3. Interrupt handler also obtains the same lock.
		- Problem: Happens when the interrupt handler runs in the same processor which driver code with lock is running. More profound in single processor system. Interrupt handler will spin forever, as the non interrupt code will not be able to run to release the lock. This results in deadlock.
		- Solution:
			- Disable interrupts before acquiring the spin lock
			- Enable them back after releasing the spin lock.

	The kernel provides an interface that conveniently disables interrupts and acquires the lock.
		DEFINE_SPINLOCK(my_lock);
		unsigned long flags;
			spin_lock_irqsave(&my_lock, flags);
			/* critical region ... */
			spin_unlock_irqrestore(&my_lock, flags);

	Why additional argument of flags is needed? What if the interrupts were disabled before you acquire a spinlock, if we don't have flags, we will enable them after unlocking. spin_lock_irqsave()saves the current state of interrupts, disables them locally, and then obtains the given lock. current stata is flags and those indicate which interrupts are enabled/disabled. Conversely, spin_unlock_irqrestore() unlocks the given lock and returns interrupts to their previous state. If you always know before the fact that interrupts are initially enabled, there is no need to restore their previous state.
		DEFINE_SPINLOCK(mr_lock);
		spin_lock_irq(&mr_lock);
		/* critical section ... */
		spin_unlock_irq(&mr_lock);

	Use of spin_lock_irq() is not recommended, as it is hard to ensure interrupts are always enabled in any kernel code path.

	Is the kernel preemption disabled when the spinlock is acquired? Any time kernel code holds a spinlock, preemption is disabled on the relevant processor. Otherwise any holidng task/process may get preempted and other scheduled process might be always waiting for that spinlock. This scenario is more profound in uniprocssor system where only single process can be scheduled at a time. Lock/unlock methods disable/enable kernel preemption.

	Important Points with Spinlocks:
		1. If a lock is acquired but no longer released, the system is rendered unusable.
			All processors— including the one that acquired the lock — sooner or later arrive at a point where they must enter the critical region.
			They go into the endless loop to wait for lock release, but this never happens and deadlocks.
		2. On no account should spinlocks be acquired for a longer period because all processors waiting for lock release are no longer available for other productive tasks.
		3. Code that is protected by spinlocks must not go to sleep.
			it must also be ensured that none of the functions that are called inside a spinlocked region can go to sleep!
			Ex: kmalloc with GFP_KERNEL.

	Simple Implementation:
		A spinlock is a mutual exclusion device that can have only two values:
			Locked
			Unlocked
		It is usually implemented as a single bit in an integer value. Code wishing to take out a particular lock tests the relevant bit. If the lock is available, the "locked" bit is set and the code continues into the critical section. If, instead, the lock has been taken by somebody else, the code goes into a tight loop where it repeatedly checks the lock until it becomes available. This loop is the "spin" part of a spinlock.

	Real Implementation: The "test and set" operation must be done in an atomic manner so that only one thread can obtain the lock, even if several are spinning at any given time. Spinlocks are built on top of hardware-specific atomic instructions. The actual implementation of spinlock is different for each architecture the linux supports.

18_1)
	Mutexes: Almost all semaphores found in the Linux kernel are used for mutual exclusion by count of 1. Using semaphore for mutual exclusion is overhead, so kernel provides a new interface: mutex. The mutex subsystem checks and enforces the following rules:
		Only one task can hold the mutex at a time.
		Whoever locked a mutex must unlock it.
		That is you cannot lock a mutex in one context and unlock in another.
		Recursive locks and unlocks are not allowed.
		Process cannot exit while holding a mutex.
		Mutex cannot be acquired from an interrupt handler.

	Differences between mutexes and semaphores: What happens when a process tries to acquire a mutex lock? When acquiring a mutex, there are three possible paths that can be taken:
				1. Fast Path
				2. Mid Path
				3. Slow Path
		The path which will be taken depends on the state of the mutex.
		Fast Path:
			Taken when no process has acquired the mutex
		Mid Path:
			When the mutex is not available, it tries to go for mid path. also called as optimistic spinning. This path will be only executed if there are no other processes ready to run having high priority and the owner of mutex is running. In this path, tries to spin using MCS lock hoping the owner will release the lock soon. Avoids expensive context switch
		Slow Path:
			last resort. This path acts as a semaphore lock. If the lock is unable to be acquired by the process, the task is added to wait queue. It sleeps until woken up by the unlock path.

		Documentation: Documentation/locking/mutex-design.txt
		Implementation: kernel/locking/mutex.c
		Header File:  <linux/mutex.h>
		Data structure: struct mutex
		struct mutex {
				atomic_long_t           owner;
				spinlock_t              wait_lock;
				struct list_head        wait_list;
		};
			owner -> used for both holding lock state, and reference to owner(task_struct) who has acquired it
			wait_lock -> used for atomic updating wait_list
		Initialization:
		Static:
			DEFINE_MUTEX(name)
		Dynamic:
			mutex_init(mutex)
		void mutex_lock(struct mutex *lock);
		void mutex_unlock(struct mutex *lock);
		int mutex_trylock(struct mutex *lock);
			Tries to acquire the given mutex
			Return:
				1   --> Successful
				0   --> Otherwise

		int mutex_lock_interruptible(struct mutex *lock);
			places the calling process in the TASK_UNINTERRUPTIBLE state when it sleeps
		Return value:
			0 -> mutex is acquired
			-EINTR  -> If the task receives a signal while waiting for mutex

		int mutex_lock_killable(struct mutex *lock);
			places the calling process in the TASK_KILLABLE state when it sleeps, only fatal signal can interrupt
		Return value:
			0 -> mutex is acquired
			-EINTR  -> If the task receives a fatal signal while waiting for mutex

	Mutex semantics are fully enforced when CONFIG DEBUG_MUTEXES is enabled.

	Test if the mutex is taken:
		int mutex_is_locked(struct mutex *lock);
		Return:
			1 -> Locked
			0 -> Unlocked

	Which one do you choose in between semaphores and mutexes? Start with mutex and move to semaphore only if the strict semantics of mutexes are unsuitable.

	spinlock vs mutexes:
		Requirement                         Recommended Lock
		=========================================================
		Low overhead locking                Spinlock
		Short lock hold time                Spinlock
		Long lock hold time                 Mutex
		Need to lock from interrupt context Spinlock
		Need to sleep while holding lock    Mutex

18_2)
	Semaphores: Semaphores in Linux are sleeping locks. What happens when the semaphore lock is unavailable?
			the semaphore places the task onto a wait queue and puts the task to sleep.
			the processor is then free to execute other code

	What happens after the semaphore becomes available?
			one of the tasks on the wait queue is awakened so that it can then acquire the semaphore.

	Entering critical section: A process wishing to enter a critical section will call on the relevant semaphore. if the semaphore's value is greater than zero, that value is decremented by one and the process continues. If, instead, the semaphore's value is 0 (or less), the process must wait until somebody else releases the semaphore.

	Exiting critical section: this function increments the value of the semaphore and, if necessary, wakes up processes that are waiting

	Types of Semaphore: Spin locks allow only one task to hold the lock at a time. With semaphores,number of tasks to hold the lock at a time can be specified while initializing/declaring semaphore. This value is called as usage count or simply count.
		Count = 1   --> Binary Sempahore. Used for mutual exclusion
		Count > 1   --> Counting Semaphore

	Can i use counting semaphores in critical section ? Counting semaphores are not used to enforce mutual exclusion because they enable multiple threads of execution in the critical region at once. Instead, they are used to enforce limits in certain code. They are not used much in the kernel.
		kernel/locking/semaphore.c
		Data structures:
			Header File: <linux/semaphore.h>
			Data structures: struct semaphore
			struct semaphore {
					raw_spinlock_t          lock;
					unsigned int            count;
					struct list_head        wait_list;
			};
			lock - spinlock for a semaphore data protection;
			count - amount available resources;
			wait_list - list of processes which are waiting to acquire a lock.

	Initialization:
		Dynamic:
			void sema_init(struct semaphore *sem, int val);
					where val is the initial value to assign to a semaphore.
		Static: 
			DEFINE_SEMAPHORE(name)
			#define DEFINE_SEMAPHORE(name)  \
			struct semaphore name = __SEMAPHORE_INITIALIZER(name, 1)
			void down(struct semaphore *sem);
			void up(struct semaphore *sem);

	down():
		decrements the count by one
		If count >= 0 task can enter the critical region
		Else task is placed on the wait queue

	up():
		increments the count by one

	int down_interruptible(struct semaphore *sem);
	down vs down_interruptible:
		down() places the calling process in the TASK_UNINTERRUPTIBLE state when it sleeps.
		down_interruptible() places the calling process to sleep in the TASK_INTERRUPTIBLE state
		If the task receives a signal while waiting for the semaphore, it is awakened and down_interruptible() returns -EINTR.

	int down_trylock(struct semaphore *sem); If the semaphore is not available at the time of the call, down_trylock returns immediately with a nonzero return value.

	int down_timeout(struct semaphore *sem, long jiffies); Attempts to acquire the semaphore. If no more tasks are allowed to acquire the semaphore, calling this function will put the task to sleep. If the semaphore is not released within the specified number of jiffies, this function returns -ETIME. It returns 0 if the semaphore was acquired.

	int down_killable(struct semaphore *sem); The down_killable function does the same as the down_interruptible function. Only the fatal signals can be delivered like kill signal. What are fatal signals? Any signal listed with a default action of “terminate” or “dump core” is fatal, unless it’s ignored or handled explicitly. Eg. SIGCONT, SIGCHLD, SIGSTP ..

	Important points while using semaphore:
		1. Semaphores are well suited to locks that held for a long time. As the tasks trying to acquire the lock sleep if it is not available.
		2. Semaphores are not suited for locks that held for a short time.
			Due to overhead of
				a. sleeping
				b. maintaining the wait queue.
				c. waking back up 
			total time can easily overweigh the total lock hold time.
		3. As we sleep if the lock is not available, cannot be used in interrupt context.
		4. Semaphores do not disable kernel preemption, and consequently code holding a sempahore can be preempted.

	Advantages of semaphore over spinlock:
		better processor utilization as no time is spent busy looping

	Which one to choose for critical region: spin lock vs semaphore?
		1. Sleep: Semaphore is the only option. 
		2. Lock hold time: Sempahores are good for longer lock hold times
				   Spinlocks are useful when the lock hold time is small
		3. Scheduling latency: As semaphores do not disable kernel preemption, scheduling latency is better
					   when compared to spinlocks.

19_1)
	Problem: Readers-writer lock is a special lock mechanism which allows concurrent access for read-only operations. An exclusive lock is needed for writing or modifying data. A writer process can't acquire a lock as long as at least one reader process which acquired a lock holds it. This may lead to a problem called writer starvation, where writer process may sometimes need to wait long time for the lock.

	Lock free and wait free synchronization plays a major role in RTOS, where time guarantees must be given. Two new synchronization mechanisms added in 2.6 Kernel to totally remove locking on the reader side:
		1. Sequence Lock
		2. Read Copy Update (RCU)

	seqlocks/sequence locks:
		Objective: Provide Fast and lock-free access to shared resources.
		Differences between reader-writer locks and sequence locks:
			--> Writer is given a higher priority when compared to reader
			--> Writer is allowed to modify the shared data, even when there are readers in critical section

	How readers handle the data corruption when writer updates it during read ?
		Readers are in charge to check if they read valid data.
		If a write access took place while the data was read, the data is invalid and has to be read again.
		Identification of write accesses is realized with a counter.

	What happens when a writer is already in critical section and another writer arrives? A writer uses a spinlock for mutual exclusion and hence will not interfere the other writer.

	When to use?
		A small amount of data is to be protected
		Your data has a lot of readers/frequently accessed
		Your data has a few writers
		It is important that writers not be starved for access

	How it works? It uses Sequence Counter (Integer) & Spin lock
		Data structure: seqlock_t
		Header File: linux/seqlock.h
		typedef struct seqcount {
				unsigned sequence;
		} seqcount_t;
		typedef struct {
				struct seqcount seqcount;
				spinlock_t lock;
		} seqlock_t;
			seqcount -> sequence counter
			lock     -> lock to atomic update in case of writers
		Initialization:
			Static:         DEFINE_SEQLOCK(x)
			Dynamic:        seqlock_init(x)

	spinlock is used only in write operation. Write operation: Writers must take out exclusive access before making changes to the protected data.
		write_seqlock(&the_lock);
		/* Make changes here */
		write_sequnlock(&the_lock);

		write_seqlock() locks the spinlock and increments the sequence number.
		write_sequnlock() increments the sequence number again, then releases the spinlock.

	Read Operation: No locking is required when you are using trying to read. Each reader must read the sequence number twice:
		before reading the data
		after reading the data
	And verify whether they both are same or not.

	When there was no writer during the read operation? value of the sequence counter will be same.
	When there was writer during the read operation?
		value of the sequence counter will not be same
		The important point here is that while the writer is operating, the sequence number would be odd.

		unsigned int seq;
		do {
			seq = read_seqbegin(&the_lock);
			/* Make a copy of the data of interest */
		} while read_seqretry(&the_lock, seq);
		read_seqbegin   --> Returns the current sequence number.
		read_seqretry	-->	Returns 1 if the value of seq local variable is odd.

	Is Kernel Preemption Disabled?
			Readers: No
			Writers: Yes because it acquires a spinlock
	spinlock disables kernel preemption.

	Limitations: Seqlocks cannot be used for pointers, it can only be used for normal data like integers, booleans. Because, there can be pointer which can be already freed, dereferencing such pointer will cause oops. Also, writer might be freeing without informing to reader.

	Who uses seqlocks in Linux Kernel?
		Jiffies: Variable that stores a Linux machine's uptime.
		kernel/time.c, kernel/time/tick-common.c

			u64 get_jiffies_64(void)
			{
				unsigned int seq;
				u64 ret;

				do {
					seq = read_seqbegin(&jiffies_lock);
					ret = jiffies_64;
				} while (read_seqretry(&jiffies_lock, seq));
				return ret;
			}
			EXPORT_SYMBOL(get_jiffies_64);

	Seqlocks have other variants to use in interrupts.
		write_seqlock_irq(seqlock_t *sl);
		write_sequnlock_irq(seqlock_t *sl);
		write_seqlock_irqsave(seqlock_t *sl);
		write_sequnlock_irqrestore(seqlock_t *sl, unsigned long flags);

19_2)
	The synchronization techniques discussed till now have one drawback. They do not differentiate between situations in which:
			data structures are simply read
			data structures are actively updated
		Read access can be provided to multiple tasks concurrently
		Write access should be provided to one task at a time.

	Kernel provides additional semaphore and spinlock versions for the above requirement, as read operation is performed more often than write operation:
		1. Reader/Writer Spinlocks
		2. Reader/Writer Semaphores

	These are also known as shared/exclusive or concurrent/exclusive locks:
		shared 		--> readers
		exclusive	--> writers

		Header File: <linux/rwlock_types.h>
		Data Structure: struct rwlock_t
		Initialization:
			static: DEFINE_RWLOCK(x)
			Dynamic: rwlock_init(lock);

		Lock/Unlock:
			Readers:
				read_lock(&mr_rwlock);
				/* critical section (read only) ... */
				read_unlock(&mr_rwlock);

			Writers:
				write_lock(&mr_rwlock);
				/* critical section (read and write) ... */
				write_unlock(&mr_lock);

	What happens when we run the below code snippet?
		read_lock(&mylock);
		write_lock(&mylock);
	Executing these two functions will cause deadlock, as write_lock will spin until it all readers have released the lock. Write lock can only be acquired when reader has completed read unlock.

	It is safe for the same thread to recursively obtain the same read lock. What happens when a read lock is held and a writer is waiting for exclusive access and a new reader arrives? Who is given a chance? reader/writer. first in first out happens. Whoever come first, it is given chance.

		Header File: <linux/rwsem.h>
		Data Structure: struct rw_semaphore
		Implementation : kernel/locking/rwsem.c
		Initialization:
			Static: 	DECLARE_RWSEM(name)
			Dynamic:	init_rwsem(struct rw_semaphore *sem)

	All reader-writer semaphores are mutexes—that is, their usage count is one. They enforce mutual exclusion only for writers, not readers.

	Lock/Unlock:
		Readers:
			void down_read(struct rw_semaphore *sem);
				critical section
				....
			void up_read(struct rw_semaphore *sem);
		Writers:
			void down_write(struct rw_semaphore *sem);
				critical section
				....
			void up_write(struct rw_semaphore *sem);
	Note: down_read/down_write may put the calling process into an uninterruptible sleep.

		int down_read_trylock(struct rw_semaphore *sem);
		int down_write_trylock(struct rw_semaphore *sem);

	Note: Both return 1 if the lock is successfully acquired and 0 if it is currently contended. This is the opposite of normal semaphore behavior!

	downgrade_write():

	Reader-writer semaphores have a unique method which is not present in reader-writer spinlocks.
		void downgrade_write(struct rw_semaphore *sem);

	This function atomically converts an acquired write lock to a read lock. Where can i use this? Used in situation where writer lock is needed for a quick change, followed by longer period of read-only access

20)
	Read Copy Update / RCU:
		IMP: 29:00 - 32:00

	RCU supports concurrency between a single updater/writer and multiple readers. Used in same scenario as in seqlock. Often used to update linked lists,which are used all over the kernel. RCU Can be used in the following scenario:
		Lot of Reads
		Rare Writes
		Write should have priority when compared to Read

	Problem with Read/Write Locks:
		Expensive (as they use atomic increment/decrement for reader count)

	Problem with Seq Locks:
		Cannot be used with pointers, only works on basic types like integer etc
		Reader needs to retry the operation

	RCU solves the above problem:
		to have pointer as a shared resource and 
		No locks in the reader ( same as in seqlock )
		Avoid reader to retry the operation

	Constraints of RCU:
		Access to shared resource should be mostly read, and very rare write
		Cannot sleep into region protected by RCU
		Protected resource should only be accessed via pointer

	Read Operation:
		No Locking is required

	Write Operation:
		Locking is required

	RCU allows read access to happen concurrently with write updates 
	Note: RCU Updaters/writers cannot block readers or force them to retry their accesses like seqlocks.

	Linux kernel uses many data structures that are read and updated intensively, especially in
		1. Virtual File System : Directory entry caches (dentry)
		2. Networking	       : Routing Tables. Every outgoing packet requires to check routing table to determine which interface ( ethernet/Wifi etc. ) should be used.

	How it works:
		As readers do not check if the data they read is consistent(like the seqlock), writer have to
		apply all their changes with one atomical operation. RCU keep tracks of all users of the pointers to the shared data structure. When a shared data structure is going to change, it:
			first create a copy of the structure
			perform the change
			After all the readers have finished reading on the old copy, pointer is updated

	Why it is called RCU? When the writing thread needs to be changed, 
		it makes a copy
		changes the copy
		updates the pointer to point to it

	Initial linked list
		   HEAD
			|
			V
		--------------          -----------------               -------------
		|            |          |               |               |           |
		|   A        |--------->|   B           |-------------->|    C      |
		|            |          |               |               |           |
		--------------          ------------------              -------------

	Reader is reading
				 Reader
		   HEAD   /
			|    /
			V   V
		--------------          -----------------               -------------
		|            |          |               |               |           |
		|   A        |--------->|   B           |-------------->|    C      |
		|            |          |               |               |           |
		--------------          ------------------              -------------

	Request to delete node B when there is reader at B
				Updater        Reader
		   HEAD   /              |
			|    /               |
			V   V                v
		--------------          -----------------               -------------
		|            |          |               |               |           |
		|   A        |--------->|   B           |-------------->|    C      |
		|            |          |               |               |           |
		--------------          ------------------              -------------

	First phase of update (Element B unlinked from List)
			 Updater          Reader
		   HEAD   /             |
			|    /              |
			V   V               v
		--------------          -----------------               -------------
		|            |          |               |               |           |
		|   A        |---       |   B           |-------------->|    C      |
		|            |  |       |               |            -->|           |
		--------------  |       ------------------           |  -------------
						|                                    |
						|                                    |
						--------------------------------------

	Second phase of update (Updater deletes the node after grace period)
									Updater                     Reader
		   HEAD                        |                           |
			|                          |                           |
			V                          V                           v
		--------------          -----------------               -------------
		|            |          |               |               |           |
		|   A        |---       |   B           |-------------->|    C      |
		|            |  |       |               |            -->|           |
		--------------  |       ------------------           |  -------------
						|                                    |
						|                                    |
						--------------------------------------

	After node is deleted
		   HEAD
			V
		--------------                                  -----------------
		|            |                                  |               |
		|   A        |--------------------------------->|   C           |
		|            |                                  |               |
		--------------                                  -----------------

	suppose there is a reader at A, at request comes to delete B. If it gets deleted then when reader moves to B, it will dereference NULL pointer and crashes/OOPS. Here we have to point A to node C. So, reader will move directly to A to C. We should not delete node B untill reader moves from there. This is how RCU read copy update works. ) video ( 7 - 13 ).

	RCU Design: Core of RCU is based on two primitives:
		1. RCU Read-side critical sections : rcu_read_lock/rcu_write_lock
		2. RCU Synchronization : synchronize_rcu/call_rcu()

	Developers can use RCU Read-Side Critical sections and RCU Synchronization to build data structures that allow concurrent reading during updates.
		Header File: <linux/rcupdate.h>

	Core RCU API:
		a.	rcu_read_lock()
		b.	rcu_read_unlock()
		c.	synchronize_rcu() / call_rcu()
		d.	rcu_assign_pointer()
		e.	rcu_dereference()

	Write operation:
		Direct assign a new pointer to a pointer is protected by RCU is forbidden. You need to use rcu_assign_pointer() function.
			struct my_data
			{
				int key;
				int val;
			};
			struct my_data *global = NULL;

		Write operation:
			struct my_data *new_ptr;
			new_ptr = kmalloc(sizeof(struct my_data), GFP_KERNEL);
			new_ptr->key = 1;
			new_ptr->val = 1234;
			rcu_assign_pointer(global, new_ptr);

	Why can't i directly write to the pointer/global shared resource? or Why should i use rcu_assign_pointer? Consider the below code fragment:
		struct my_data
		{
			int key;
			int val;
		};
		struct my_data *global = NULL;
		....
		struct my_data *ptr;
		ptr = kmalloc(sizeof(struct my_data), GFP_KERNEL);
		ptr->key = 1;
		ptr->val = 1201;
		global = ptr;

	The problem here is CPU/Compiler can perform optimizations and can execute the above last three lines in any order. If assignment of ptr to global happens before initialization of ptr fields, concurrent readers can could see the unitialized values.
		ptr = kmalloc(sizeof(struct my_data), GFP_KERNEL);
		global = ptr;
		ptr->key = 1;
		ptr->val = 1201;

	We need to keep use memory barriers to keep the things in order. rcu_assign_pointer will internally use memory barriers and make everything happen as per the order.

	Read operation: It is forbidden to simply de-reference the pointer, protected by RCU region. You need to use rcu_dereference() function. Additionally, the code that de-references the pointer and uses the result needs to be embraced by calls to rcu_read_lock() and rcu_read_unlock().
		rcu_read_lock() - mark the beginning of an RCU read-side critical section
		rcu_read_unlock() - marks the end of an RCU read-side critical section.

		struct my_data
		{
			int key;
			int val;
		};
		struct my_data *global = NULL;
		global = kmalloc(sizeof(struct my_data), GFP_KERNEL);

		Read operation:
			struct my_data *tmp;
			rcu_read_lock();
			tmp = rcu_dereference(global);
			pr_info("key:%d\t val:%d\n", tmp->key, tmp->val);
			rcu_read_unlock();

	Why can't i directly dereference to the pointer/global shared resource? or Why should i use rcu_dereference? Consider the below code fragment:
		struct my_data
		{
			int key;
			int val;
		};
		struct my_data *ptr;
		ptr = global;
		add_key_val(ptr->key, ptr->val);

	Due to compiler optimization, value of ptr->key, ptr->val are fetched before the value of ptr. Compiler tries to guess value of ptr.

	retry:
		ptr = guess(global)
		add_key_val(ptr->key, ptr->val);
		if (ptr != global)
			goto retry;

	rcu_dereference() internally uses memory barrier instructions/compiler directives to avoid this.
		rcu_read_lock();
		ptr = rcu_dereference(global);
		if (ptr != NULL) {
			add_key_val(ptr->key, ptr->val);
		}
		rcu_read_unlock();

	What is the problem in the below code?
	Memory Leak
	- at write thread we are allocating memeory but not freeing.

	When should i free memory? RCU should free after waiting For Pre-Existing RCU Readers to Complete. RCU waits on "RCU read-side critical sections".

	RCU read-side critical sections:
		rcu_read_lock();
		.....
		critical section
		.....
		rcu_read_unlock();

	Basic idea behind RCU is to split updates/write into two phases:
			1. Removal
			2. Reclamation

	Removal:
			Replaces references to data items with the latest

	Reclamation:
			Freeing the old reference.
			It should happen only when all the readers completed accessing using old reference

	void synchronize_rcu(void);
	Calling process is blocked until all pre-existing RCU read-side critical sections on all CPUs have completed. After the function returns, it is safe to free the memory associated with the old pointer. Note that synchronize_rcu will not necessarily wait for any subsequent RCU read-side critical sections to complete.

			CPU 0                  CPU 1                 CPU 2
			 ----------------- ------------------------- ---------------
		 1.  rcu_read_lock()
		 2.                    enters synchronize_rcu()
		 3.                                               rcu_read_lock()
		 4.  rcu_read_unlock()
		 5.                     exits synchronize_rcu()
		 6.                                              rcu_read_unlock()

	void call_rcu(struct rcu_head *head, rcu_callback_t func);

	Another way to avoid blocking is to register a callback which will be called when all the read-side critical sections are completed. This requires that an instance of rcu_head is embedded.

	Can the RCU read-side critical sections be nested?
	Yes, as long as that code does not explicitly block or sleep.

	How does RCU/synchronize_cpu() know that all readers have finished reading?
	We know RCU read-side critical sections delimited by rcu_read_lock() and rcu_read_unlock() are not permitted to block or sleep. Therefore, when a given CPU executes a context switch, we are guaranteed that any prior RCU read-side critical sections will have completed. synchronize_cpu() returns as soon as all the CPU's have completed one context switch.

	RCU Terminology:
	- Quiescent state: Any code that is not in an RCU read-side critical section. Readers could see stale data if they enter the read-side critical section before the writer finished updating. Writer has to wait until all the readers drop their references to the stale data or they have entered the quiescent state.
	- Grace Period:   The above time span is called the grace period. Grace period ends after all CPUs execute a context switch.
					------------------  Context Switch
					|   RCU          |          |
					V       Reader   V          V
		CPU0        ----------------------------------------

						------------------  Context Switch
						|   RCU          |          |
						V       Reader   V          V
		CPU1        ---------------------------------------------------

						Synchronize_rcu()
							|
							V
		CPU2        ---------------------------------------------------------
							|   Grace               |
							|   Period              |
							-------------------------

	RCU Variants of Linked List API:
		Header File: <linux/rculist.h>

		void INIT_LIST_HEAD_RCU(struct list_head *list);
		void list_add_rcu(struct list_head *new, struct list_head *head);
		void list_add_tail_rcu(struct list_head *new, struct list_head *head);
		void list_del_rcu(struct list_head *entry);
		list_entry_rcu(ptr, type, member);
		list_for_each_entry_rcu(pos, head, member);

	Advantages of RCU's:
		1. Performance
		2. Deadlock Immunity: As they do not use locks
		3. Realtime Latency: As they do not use locks

	Do readers need to take lock while operating inside the critical section? Locks are not required in case of readers using RCU.

	Do writers need to take lock while operating inside the critical section? Locks are required in case of writers using RCU to avoid another writer concurrently entering critical section.

	What is quiescent state?
	============================
	----
	threads are not in a read side critical section

	What is grace period? from start of synchronize RCU to end of synchronize RCU.

	Do the reader needs to retry the read operation like seqlock when the writer is also in critical section? Not required. Writer needs to handle this and atomically update the shared resource to the latest.

	What is the disadvantage of the RCU when compared to seqlock? As we are performing copy operation to update the data structure, increased memory cost.

	Can I sleep inside a region protected by RCU ? No, you cannot sleep inside a region protected by RCU.

	What is the similarity between read-write locks and RCU's? Both have read-side critical sections that can execute in parallel.

	To read more: https://free5gc.org/blog/20231129/20231129/, http://lastweek.io/notes/linux/linux-rcu/, https://medium.com/@boutnaru/the-linux-process-journey-rcub-read-copy-update-boost-7b0bb62b4454

21_1)
	Schedule() implements the scheduler.
		Implementation: kernel/sched.c
	The most important data structure used by scheduler is run queue. Run Queue: Contains the list of all processes which are in TASK_RUNNING state. Each CPU has its own run queue and each active process will be present on just one run queue.

	How it is invoked?
		1. Direct Way: When the current process do not have the resource it needs, and want to block itself until it acquires the resource, it calls schedule
		2. Lazy Way: When the time quantum/time slice of the current process is completed.

	Sleeping in Linux: At times, processes needs to wait until a certain event occurs, for example
			1. Device to Initialize
			2. I/O completion
			3. Fix Interval of time to elapse
		In such cases, the process is said to sleep on that event. A process can go to sleep by calling schedule(). When a process is put to sleep, it is marked as being in a special state and removed from the scheduler's run queue. Until something comes along to change that state, the process will not be scheduled on any CPU and, therefore, will not run.

	Process States:
		TASK_RUNNING : Running or ready to run
		TASK_ZOMBIE  : Task has terminated, but waiting for parent to call wait
		TASK_STOPPED : Process Execution has stopped; happens when it receives SIGSTOP
		TASK_INTERRUPTIBLE
		TASK_UNINTERRUPTIBLE

	TASK_INTERRUPTIBLE vs TASK_UNINTERRUPTIBLE
	===========================================
		TASK_INTERRUPTIBLE                          TASK_UNINTERRUPTIBLE

		1. Process is sleeping/blocked              1. Process is sleeping/blocked
		   waiting for some condition                  waiting for some condition
		   to exist                                    to exist
		2. When the condition becomes true          2. When the condition becomes true
		   the process is set to TASK_RUNNING          the process is set to TASK_RUNNING
		   by kernel                                   by kernel
		3. When signal is send to this process      3. When signal is send to this process
		   it wakes up and becomes runnable            it doesn't wake up

	TASK_UNINTERRUPTIBLE is  mostly used by device drivers waiting for disk or network I/O. How to find out what wait channels processes are waiting on?
		$ ps -l (to see processes associated with the current shell)
		$ ps -el (to see all processes on the system)

	If a process is in Sleep state, the WCHAN field shows the system call that the process is waiting on.
	WCHAN(Wait Channel) - name of the kernel function in which the process is sleeping. State:
		D    uninterruptible sleep (usually IO)
		S    interruptible sleep   (waiting for an event to complete)

	schedule() function invokes scheduler and it then picks up the next process/task from the run queue. process invoking the schedule() voluntarily yields the processor, as the process is still in run queue, it would be scheduled again. You must call set_current_state() before calling schedule() to move it from the run queue.
		Header File: <linux/sched.h>

	When the schedule() function is called with the state as TASK_INTERRUPTIBLE or TASK_UNINTERRUPTIBLE, an additional step is performed:
		the currently executing process is moved off the run queue before another process is scheduled. 
		The effect of this is the executing process goes to sleep, as it no longer is on the run queue.
		Hence, it never is scheduled by the scheduler. And, that is how a process can sleep.
	There is no one trying to wake up the process, hence the process is sleeping unconditionally.

	Waking up:
		Given a reference to a task structure, the process could be woken up by calling:
			wake_up_process(sleeping_task);
			Implementation: kernel/sched/core.c
				-->	this sets the task state to TASK_RUNNING
				-->	puts the task back on the run queue.
		Note:	the process runs only when the scheduler looks at it the next time around.
		Return: 
			1 if the process was woken up, 
			0 if it was already running.
	example is a device driver showing skeep and wake of process.

	schedule_timeout():
		long schedule_timeout (	signed long  timeout);
		timeout - timeout value in jiffies
	Make the current task sleep until timeout jiffies have elapsed. The routine will return immediately unless the current task state has been set using set_current_state. The current task state is guaranteed to be TASK_RUNNING when this routine returns.
		Return value:
			0	when the timer has expired
			remaining time in jiffies, if the signal is received or process is woken up

	Lost Wake Up Problem:
		processes go to sleep after checking some condition.
		Lost wakeup problem arises out of a race condition that occurs while a process goes to conditional sleep.
		Process A                                   Process B
		====================                        ========================
		if (list_empty(&mylist_head))               list_add_tail_rcu(&mylist_head);
		{                                           wake_up_process(task_a);
			set_current_state(TASK_INTERRUPTIBLE);
			schedule();
		}
		//Rest of the Code which performs operation on list 

	What is the problem in the above code?
		If process A which was executing list_empty  on one processor found that the list is empty and it entered the if loop. At the same time, process B started on another processor starts and executes all its instructions. It calls wake_up_process on process A which has not yet slept. Now process A sets the state to TASK_INTERRUPTIBLE and goes to sleep. Thus, a wake up from process B is lost. This is known as lost-wakeup problem. Process A sleeps, even though there are nodes available on the list.
	Solution: Problem goes if we modify our code

		Process A                                   Process B
		====================                        ========================
		set_current_state(TASK_INTERRUPTIBLE);
		if (list_empty(&mylist_head))               list_add_tail_rcu(&mylist_head);
		{                                            wake_up_process(task_a);
			
			schedule();
		}
		//Rest of the Code which performs operation on list 

	How?
		Whenever wake_up_process() is called on process whose state is TASK_INTERRUPTIBLE/TASK_UNINTERRUPTIBLE, and the process has not yet called schedule(), it changes the state to TASK_RUNNING. Even if the wake_up_process is called after list_empty, as the state is TASK_RUNNING, it will not put the process into sleep. We can't spinlock because schedule will put process into sleep state. But can use semaphore but above solution is better.

	The following is a snippet from kernel/kthread.c:
		set_current_state(TASK_INTERRUPTIBLE);
		if (list_empty(&kthread_create_list))
			schedule();
		__set_current_state(TASK_RUNNING);
	Here in this code, it is checking the condition only after setting the state to TASK_INTERRUPTIBLE. Why do you think last line is needed? It is setting the task state to RUNNING, as there are chances that the list_empty condition may fail() and schedule() will never be called.

21_2)
	Sometimes processes may need to go to Sleep state for a particular amount of time
		void msleep(unsigned int msecs);
		Header File : <linux/delay.h>
	msleep will put the processor into uninterruptible sleep. [ ps ] will show you 'D' as the state.

	unsigned long msleep_interruptible(unsigned int msecs); will put the process into interruptible sleep
		Return value : 
			Normally 0
			If the process is awakened early, then the return value is number of milliseconds remaining in the original requested sleep period.

	void ssleep(unsigned int seconds);
		Header File: <linux/delay.h>
	it is uninterruptible sleep.

22)
	How are semaphores implemented? Look at kernel/locking/semaphore.c
		struct semaphore {
				raw_spinlock_t          lock;
				unsigned int            count;
				struct list_head        wait_list;
		};

	Issue using schedule/wake_up_process:
		1. Need to write code carefully to avoid lost-wakeup problem
		2. Waker process needs to know the task_struct of the sleeping process. 
		   This can become tedious when there are more than one process involved in sleeping.

	Wait queues: Wait queues are a higher-level mechanism which handles
		1. putting processes to sleep and 
		2. waking them up.

	Wait queues are used to enable processes to wait for a particular event to occur without the need for constant polling. A wait queue is a simple list of processes waiting for an event to occur. Processes sleep during wait time and are woken up automatically by the kernel when the event takes place.
		Header File: <linux/wait.h>
		Data Structure: wait_queue_head_t
			struct wait_queue_head {
					spinlock_t              lock;
					struct list_head        head;
			};
		typedef struct wait_queue_head wait_queue_head_t;
			lock -->	used to protect its own resources from being accessed by multiple processes at the same time
			head -->	List of wait_queue_entry

	Types of sleeping processes:
		1. Exclusive Process: Processes are selectively woken up by the kernel when the event happens
		2. Non Exclusive Process: All the processes present in the wait queue are woken up by the kernel on event.

	Static:
		DECLARE_WAIT_QUEUE_HEAD(name);
		#define __WAIT_QUEUE_HEAD_INITIALIZER(name) {                                   \
				.lock           = __SPIN_LOCK_UNLOCKED(name.lock),                      \
				.head           = { &(name).head, &(name).head } }
		#define DECLARE_WAIT_QUEUE_HEAD(name) \
				struct wait_queue_head name = __WAIT_QUEUE_HEAD_INITIALIZER(name)
	Dynamic:
		wait_queue_head_t my_queue;
		init_waitqueue_head(&my_queue);

	API's:
		wait_event(queue, condition);
			queue -->	wait queue head to use.
			condition --> arbitrary boolean expression that is evaluated by the macro before and after sleeping; 
	The process goes to sleep only if the condition evaluates to false. Care is taken to avoid the lost wake-up problem. Some other thread of execution (a different process, or an interrupt handler, perhaps) has to perform the wakeup for you, since your process is, of course, asleep.

	void wake_up(wait_queue_head_t *queue); Note: until condition evaluates to a true value, the process continues to sleep.

	wait_event_interruptible(queue, condition); It can be interrupted by signals. This version returns an integer value that you should check; a nonzero value means your sleep was interrupted by some sort of signal, and your driver should probably return -ERESTARTSYS.

	void wake_up_interruptible(wait_queue_head_t *queue);

	wait_event_timeout(queue, condition, timeout)
		The process is put to sleep (TASK_UNINTERRUPTIBLE) until the condition evaluates to true. 
		The condition is checked each time the waitqueue is woken up.
		Return Value:
			0 if the condition evaluated to false after the timeout elapsed
			1 if the condition evaluated to true after the timeout elapsed
			remaining jiffies (at least 1) if the condition evaluated to true before the timeout elapsed.

	wait_event_interruptible_timeout(queue, condition, timeout)
		process is put to sleep (TASK_INTERRUPTIBLE) until the condition evaluates to true or a signal is received. The condition is checked each time the waitqueue wq is woken up.
		Return value:
			0 if the condition evaluated to false after the timeout elapsed
			1 if the condition evaluated to true after the timeout elapsed
			the remaining jiffies (at least 1) if the condition evaluated to true before the timeout elapsed, 
			or -ERESTARTSYS if it was interrupted by a signal.

23)
	Little issue while waking:
		Processes which are blocked/sleeping using wait_event() are moved to running state using wake_up(). Scheduler will run them in future. There is no guarantee when these waking-up processes will be allocated CPU time nor in what order. The above can happen to multiple processes at the same time, if they are non-exclusive. Once woken up, there is no guarantee that the condition which the process is waiting for using wait_event() is true. That is if the process was waiting for condition = 1 after waking up, this may not be true. Another process in the wait queue can change the condition = 0 after they woke up. So, the waking processes needs to check the state of the condition after waking up and act accordingly.

	Thundering Herd Problem:
		When a process calls wake_up on a wait queue, all processes waiting on the wait queue are made runnable. Consider a scenario in which a set of processes are sleeping on wait queue, wanting to acquire lock.
			--->	The process that has acquired the lock is done with it, releases the lock
			--->	All the processes that are sleeping for it will wake up
			--->	All processes try to grab lock
			--->	Only one of these acquires the lock and the rest goes back to sleep
		If the number of procesess in the wait queue is large, it seriously degrades the performance of system. As, it consumes valuable CPU cycles and incur context-switching overheads.

	To address the thundering herd problem, we need an exclusive sleeping system that only wakes up one task from the wait queue at a time. Exclusive wait can be set up by using this macro:
		wait_event_interruptible_exclusive(wait_queue_head_t wq, int condition);

		void wake_up_all (wait_queue_head_t *wq);
		void wake_up_interruptible_all (wait_queue_head_t *wq);
			The above functions will wake up all threads.

	Why are the wait_event() implemented as macros?
		1. Use of macros will expand the code and removes a function call/return pair.
		2. Using macros avoid the race condition which can happen     
			CPU1            CPU2
			wait_event      wake_up

		   How?
			wait_event(condition) {
				prepare_to_wait();            //add ‘current’ to wait-queue, set state to !runnable
				if (!condition) schedule(); //check condition, possibly give up the CPU
				finish_wait();                    //remove from wait-queue, set state to runnable
			}

			Condition can be:
				1. A variable that evaluates to true/false (eg. x)
				2. Test ( eg x == 1234)
				3. Function (atomic_read(&counter))
			If wait_event() was implemented as a function, condition argument will be passed as a value
			and it would be stale/old when evaluated at if (!condition) schedule();

			It will have the value when wait_event will be called and not the latest value of condition. Using macros, condition argument is always latest value.

	wake_up_interruptible()	-->	Can only wake up Tasks which are sleeping in interruptible state
	wake_up()	-->	Can wake up both tasks which are in interruptible/non interruptible

	waitqueue_active -- locklessly test for waiters on the queue. it checks if waitqueue is empty or not. It checks it by checking if HEAD linked list is empty or not.

	In many situations, wait_event() does not provide enough flexibility. Alternative is to do full manual sleep.
		wait_queue_entry_t:
		Wait queue = Wait Queue Head + Wait Queue Elements
	A wait queue is a doubly linked list of wait_queue_entry_t structures. Each element in the wait queue list represents a sleeping process, which is waiting for some event to occur;
		struct wait_queue_entry {
				unsigned int            flags;
				void                    *private;
				wait_queue_func_t       func;
				struct list_head        entry;
		};
		typedef struct wait_queue_entry wait_queue_entry_t;
			flags = 1 -> Exclusive process
			flags = 0 -> Non Exclusive process
		private -> used to store task_struct
		func -> Function which will wake up the sleeping process
		entry -> used for linked list 

		---------------
		|    lock     |    --------------------------------------------------------------   
		|             |    |                                                            |
		---------------    |                                                            |
		|             |<----            -----------                     ----------      |
		|    head     |<--------------->|entry    |<------------------->|entry   |<------
		---------------                 |---------|                     |--------|
										|func     |                     |func    |
		wait_queue_head_t               |---------|                     |--------|
										|private  |                     |private |
										|---------|                     |--------|
										|flags    |                     |flags   |
										-----------                     ---------
										wait_queue_entry_t      wait_queue_entry_t

	Initialization of wait queue entry:
		Static:
			DEFINE_WAIT(wait);
				Declares a new wait_queue_entry variable and initialize its with the descriptor of the process
				currently executing and function is assigned to autoremove_wake_function()
			#define DEFINE_WAIT(name) DEFINE_WAIT_FUNC(name, autoremove_wake_function)
			#define DEFINE_WAIT_FUNC(name, function)                                        \
					struct wait_queue_entry name = {                                        \
							.private        = current,                                      \
							.func           = function,                                     \
							.entry          = LIST_HEAD_INIT((name).entry),                 \
					}

		Dynamic:
			void init_waitqueue_entry(struct wait_queue_entry *wq_entry, struct task_struct *p);
			static inline void init_waitqueue_entry(struct wait_queue_entry *wq_entry, struct task_struct *p)
			{
					wq_entry->flags         = 0;
					wq_entry->private       = p;
					wq_entry->func          = default_wake_function;
			}
			int wake_up_process(struct task_struct *p)
			{
					return try_to_wake_up(p, TASK_NORMAL, 0);
			}
			int default_wake_function(wait_queue_entry_t *curr, unsigned mode, int wake_flags,
									  void *key)
			{
					return try_to_wake_up(curr->private, mode, wake_flags);
			}
			int autoremove_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *key)
			{
					int ret = default_wake_function(wq_entry, mode, sync, key);

					if (ret)
							list_del_init(&wq_entry->entry);

					return ret;
			}

	Adding an element into wait queue: Once an element is defined, it must be inserted into a wait queue. Two different functions are used to add sleeping processes into a wait queue.
			add_wait_queue()
			add_wait_queue_exclusive()
		add_wait_queue() function inserts a nonexclusive process in the first position of a wait queue list.
		void add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
		add_wait_queue_exclusive() function inserts an exclusive process in the last position of a wait queue list.
		void add_wait_queue_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
		The remove_wait_queue( ) function removes a process from a wait queue list.
		void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);
			Implementation: kernel/sched/wait.c

	Change the state of the process: You don't need to fiddle with current->state. prepare_to_wait() and finish_wait() will do that.
		void prepare_to_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
		void prepare_to_wait_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
	The above functions set the process state to the value passed as the third parameter. Running prepare_to_wait() when you're already on the waitqueue_head is fine. After this, we schedule out the process by invoking the schedule() API.

	Cleaning up: Once schedule returns, it is cleanup time.
		void finish_wait(wait_queue_head_t *queue, wait_queue_t *wait);
			DEFINE_WAIT(wait);
		prepare_to_wait(wq_head, &wait, TASK_UNINTERRUPTIBLE);
		if (!condition)
			schedule();
		finish_wait(wq_head, &wait);

	signal_pending: The above function can be used to check whether the wait was interrupted by signal.
		Returns : 1	-> If the process has pending signals
				0     -> If no signal
		static inline int signal_pending(struct task_struct *p)
		{
				return unlikely(test_tsk_thread_flag(p,TIF_SIGPENDING));
		}
		kernel/signal.c(signal_wake_up/signal_wake_up_state) 	->	Sets the TIF_SIGPENDING whenever a signal is delivered.

	Does this code have lost wake up problem?
		DEFINE_WAIT(wait);
		add_wait_queue(queue, &wait);
		while (!condition) {
			prepare_to_wait(&queue, &wait, TASK_INTERRUPTIBLE);
			if (signal_pending(current))
				/* handle signal */
			schedule();
		}
		finish_wait(&queue, &wait);
	What will happen if a wake_up comes just before prepare_to_wait() and after the while condition? The wakeup will be lost. prepare_to_wait() must be called before the condition is checked.

		DEFINE_WAIT(wait); // defining wait queue entry
		add_wait_queue(queue, &wait); // adding wait queue entry
		while (!condition) { // checking condition if list is empty or not, if list is not empty, come inside
			prepare_to_wait(&queue, &wait, TASK_INTERRUPTIBLE); // set state to interruptible
			if (signal_pending(current)) //
				/* handle signal */
			schedule();
		}
		finish_wait(&queue, &wait);
	at line no.11 signal may get lost if process is preempted
	( video : 35:00 - 40:00 )

24_1)
	Completions: Completions is a code synchronization mechanism which is preferable to any misuse of locks/semaphores and busy loops.

	When to use them ? If you have one or more threads that must wait for some kernel activity to have reached a point or state. Completions can provide a race-free solution to this problem. Completions are built on top of the waitqueue and wakeup infrastructure of the Linux scheduler. The event the threads on the waitqueue are waiting for is reduced to a simple flag in 'struct completion', appropriately called "done".
		Implementation: kernel/sched/completion.c

	Without completions:
		int condition = 0;
		DECLARE_WAIT_QUEUE_HEAD(queue);

		Thread 1;                                       Thread 2
		============                                    =============
		.....                                           ......
		wait_event_interruptible(queue, condition);     condition = 1;
		....                                            wake_up_interruptible(queue);
		....                                            ......

	With Completions:
		DECLARE_COMPLETION(my_comp);

		Thread 1;                       Thread 2
		============                        =============
		.....                           ......
		wait_for_completion(&my_comp);              complete(&my_comp);

	Can't i use this semaphore for this purpose or What is the difference between semaphore and completion? Yes, you can use semaphore for the above scenario. You have a semaphore initially in the locked state. Waiting process will call down() and gets blocked. The one who is waking up will call up().

	Advantages of Completions over Semaphores:
		1. the semaphores are optimized (on purpose) for the non-contention case. Means initially it will not be in locked state. It will be in unlocked state initially. completion usage has the opposite default case.
		2. Multiple threads can wait for a completion, and they can be released with one call. It's more complex to have a semaphore wake up an unknown number of threads.
		3. Semaphores usage is for mutual exclusion. Completion usages is typically for synchronization

	Header File: <linux/completion.h>
	Data Structure: struct completion
	struct completion {
			unsigned int done;
			wait_queue_head_t wait;
	};
	wait --> wait queue to place tasks on for waiting
	done --> indicating whether it is completed or not

	Usage:
	There are three main parts to using completions:
		1. the initialization of the 'struct completion' synchronization object
		2. the waiting part through a call to one of the variants of wait_for_completion(),
		3. the signaling side through a call to complete() or complete_all().

	Initialization:
		Static:		DECLARE_COMPLETION(my_comp);
		Dynamic:	init_completion(&my_comp);

	In initialization:
		1. we initialize the waitqueue
		2. set done to 0, i.e. "not completed" or "not done".

	Waiting for Completion: For a thread to wait for some concurrent activity to finish, it calls wait_for_completion() on the initialized completion structure.
		void wait_for_completion(struct completion *done);

	When some other part of your code has decided that the completion has happened, it can wake up anybody
		void complete(struct completion *comp);

	A typical usage scenario is:
		CPU#1                                   CPU#2
		struct completion setup_done;
		init_completion(&setup_done);
		initialize_work(...,&setup_done,...);
		/* run non-dependent code */            /* do setup */
		wait_for_completion(&setup_done);       complete(setup_done);

	What happens when a call to complete happens before wait_for_completion? the waiting side simply will continue immediately as all dependencies are satisfied. If not, it will block until completion is signalled by complete().

	wait_for_completion will places the task in 'TASK_UNINTERRUPTIBLE' state, if you want the process to be placed in 'TASK_INTERRUPTIBLE' state.
		int wait_for_completion_interruptible(struct completion *done)

	Other Variants:
		unsigned long wait_for_completion_timeout(struct completion *done, unsigned long timeout)
			The task is marked as TASK_UNINTERRUPTIBLE and will wait at most 'timeout' jiffies. 
			Return Value: 0 on Timeout, else the remaining time in jiffies

		long wait_for_completion_interruptible_timeout(struct completion *done, unsigned long timeout)
			This function passes a timeout in jiffies and marks the task as TASK_INTERRUPTIBLE. 
			Return value: 0 on Timeout
					  Remaining time in jiffies if complete() was called
					   -ERESTARTSYS on receiving a signal

		long wait_for_completion_killable(struct completion *done)
		long wait_for_completion_killable_timeout(struct completion *done, unsigned long timeout)
			Uses state as TASK_KILLABLE

		bool try_wait_for_completion(struct completion *done);
			Returns 
				false: if the thread not to be blocked and will not put into the wait queue
				true: if the thread consumes one posted completion.

		bool completion_done(struct completion *done)
			Returns:
				False: If there are waiters
				True: otherwise

	complete_all: void complete_all(struct completion *); complete_all, wakes up all processing waiting for the completion.

	what is the meaning of done in struct completion? Each time complete is called, the counter is incremented by 1, The wait_for functions only puts the caller to sleep if done is not equal to 0. complete_all works similarly, but sets the counter to the largest possible value (UINT_MAX);
		void complete_all(struct completion *x)
		{
				unsigned long flags;

				spin_lock_irqsave(&x->wait.lock, flags);
				x->done = UINT_MAX;
				__wake_up_locked(&x->wait, TASK_NORMAL, 0);
				spin_unlock_irqrestore(&x->wait.lock, flags);
		}
		EXPORT_SYMBOL(complete_all);

	Can wait_for_completion() and its variants are safe to use in atomic/interrupt contexts? No, as they sleep.

	If complete() is called multiple times then this will allow for that number of waiters to continue - each call to complete() will simply increment the done field.

	Can i call complete() or complete_all() from interrupt/atomic context? Signaling completion from IRQ context is fine as it will appropriately lock with spin_lock_irqsave()/spin_unlock_irqrestore() and it will never sleep.

	static inline void reinit_completion(struct completion *x)
	{
			x->done = 0;
	}
	This inline function should be used to reinitialize a completion structure so it can be reused. This is especially important after complete_all() is used. Calling init_completion() on the same completion object twice is most likely a bug.

24_2)
	Each instruction in C is translated into machine instruction. To complete each machine instruction, the processor goes through these (and more) stages:
		1. Fetch: Read the next instruction
		2. Decode: Determine the meaning of the instruction
		3. Execute: Perform the 'real work' of the instruction
		4. Store: Store results into memory

			Instruction1        Fetch   ->  Decode  ->  Execute ->  Store
			Instruction2                    Fetch   ->  Decode  ->  Execute ->  Store
			Instruction3                                Fetch   ->  Decode  ->  Execute  -> Store

	Each instruction in the above takes four clock cycles to complete execution. With pipeline, you will have the total execution of 1 clock cycle/instruction. Modern processors have pipelines with 10-31 stages. For optimum performance, it is very important to keep all the stages as busy as possible.

	Branch Prediction: Branches are instructions that can change the flow of a program's execution.
		if (i < 0)
			i = 0;
		else
			i = 1;
	Branches (i.e., conditional jumps) present a difficulty for the processor pipeline. After fetching a branch instruction, the processor needs to fetch the next instruction. With 'if' we will be having two possibilities of the next instruction. Instead of stalling the pipeline until the branch instruction is fully executed, modern processors attempt to predict/guess the branch.

	Branch Predictor: Digital Circuit that tries to guess which way a branch will go before this is known definitively. Branch predictor plays a critical role in achieving high effective performance in many modern pipelined microprocessor architecture such as x86. If the guess/prediction found to be wrong, then the processor will simply discard the partially executed instructions that are in pipeline and starts over with the correct branch, incurring a delay.

	Command: $ perf stat <command>. for example, [ perf stat ls ] it will show page fault, context switches, branch misses etc. Run on Direct Machine without any virtualization.

	likely/unlikely: The gcc has __builtin_expect function using which you can provide the compiler/CPU with branch prediction information.
		long __builtin_expect (long exp, long c)
	This construct tells the compiler that the expression 'exp' most likely will have the value 'c'.
		Return value: return value of exp.

	How it optimizes? It optimizes things by ordering the generated assembly code correctly, to optimize the usage of the processor pipeline. Arranges the code so that the likeliest branch is executed without performing any jmp instruction. Kernel has two macros which internally uses builtin_expect to provide branch prediction information.
		#define likely(x)       __builtin_expect(!!(x), 1)
		#define unlikely(x)     __builtin_expect(!!(x), 0)

	!! converts it to boolean. Just think

		Header File: <linux/compiler.h>
		Examples:  if (likely(sem->count > 0))


	CONFIG_PROFILE_ANNOTATED_BRANCHES: By enabling CONFIG_PROFILE_ANNOTATED_BRANCHES in the kernel build config file, all the likely() and unlikely() macros will be recorded to see how many times they were correct or not.

	$ cat /sys/kernel/debug/tracing/trace_stat/branch_annotated

	This will show what branches are correct or not. for higher performance, we use likely/unlikely. watch video [ 22 - 24 ]

25)
	What is the default operation in Linux when you call read() and there is no data: block/nonblock ? Default: Blocking
		Read:
			No data is available, the process must block. Data available, process is awakened, even if available data < requested data.
		Write:
			No space is available in write buffer, process must block. Space available, process is awakened, even if available space < requested write data

	Do we need a separate buffer in the kernel for write operation? No. The data can remain in the user space buffer. Benefit of a separate buffer for write: Reduced number of context switches and user-level/kernel-level transitions.

	Consider a slow device where the hardware can only accepts data transfer in few bytes. Kernel Driver without output buffer.
		1. User Process tries to write more than 100 bytes, as there is no output buffer, process writes few bytes:write()
		2. Kernel driver tries to write few bytes to the hardware and puts the process to sleep until write completes
		3. During this time, the context switch can happen, another process is given a chance
		4. Once the write on the hardware completes, the process is resumed (context switch)
		5. write() returns (kernel level to user level transition)
		6. User process loops until it performs the same operation.
	With an output buffer in the kernel.
		1. Write call succeed with a single system call 
		2. Data is copied into the kernel output buffer
		3. Buffered data will be pushed later to device.
	So, as no going back to user space for second or third write and increased performance. 

	How do i specify a non blocking I/O in linux through my user application? Explicitly nonblocking I/O is indicated by the O_NONBLOCK flag in filp->f_flags.
		Header File in user space : <fcntl.h>
			Read:
					No data is available, return -EAGAIN
					Data available, it is returned even if available data < requested data
			Write:
					No space is available in write buffer, return -EAGAIN
					Space available, it is written even if available space < requested write data

	Problem with blocking/non-blocking I/O: If we want to read from multiple devices, read system call with blocking is not a good solution. If one device has no data, the process will be blocked even though there is data available from the other device.
			Application                     Kernel
	   ---- read    ------------------->    no data available --------
	   |                                                              |
	   |                                                              | Wait for data
	   | process                                                      |
	   | blocks             data ready     ----------------------------
	   |  in                copy data      ----------------------------
	   |  read                |                                       |  Copy data from
	   |                      v                                       |  kernel to user
	   ---- process <-------------------    copy complete   -----------
		data

	Another option is open the device in nonblocking mode, and continuously check whether there is data available, if there are more devices, it will consume lot of CPU. So, this is waste of time.
			Application                     Kernel
			read    ------------------->    no data available ------------
	   |            <------------------                                   |
	   |    read    ------------------->    no data available             | Wait for data
	   |            <------------------                                   |
	   |    read    ------------------->    data ready     ---------------
	   |-----                               copy data      ---------------
	   |    process                           |                           | Copy data from
	   |    blocks                            v                           | kernel to user
	   ---- process <-------------------    copy complete   --------------
			data

	I/O Multiplexing:
		poll and select allow a process to determine whether it can read from or write to one or more open files without blocking. They are often used in applications that use multiple input or output streams without getting struck on any one of them.
					 Application                     Kernel
				---- select  ------------------->    no data available --------
	process    |                                                               |
	blocks     |                                                               | Wait for data
	waiting    |                                                               |
	one of many|                                                               |
	fds        |                                                               |
			   -----        <------------------      data available -----------
			   |    read    ------------------->     data ready     ------------
			   |-----                                copy data      ------------
			   |   process                            |                        |  Copy data from
			   |    blocks                            v                        |  kernel to user
			   ---- process <-------------------    copy complete   -----------
			   ---  read

	What are the advantages of multithreading over I/O Multiplexing: I/O Multiplexing is better over purely multithreaded/multiprocess approaches in which a thread/process is launched to handle each file descriptor, since each thread/process requires additional memory, context switching overhead, etc. which may not scale well in handling large numbers of concurrent connections.

	process gives all file descriptor it wants to read/write. Then select system call comes from userspace to kernel space and checks if any file decsriptors are available. If no, then wait for data. If one the file descriptor is available to read, then it will return a file decscriptor available to read in select system call. Then user can now give read system call.

	select system call:
		int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
	Select system call is used to instruct kernel:
		1. what file descriptors we are interested in (for reading, writing or an exception)
		2. How long to wait.
		Arguments:
			timeout: tells the kernel how long to wait for one of the specified descriptors to become ready
		Header file: <sys/time.h>
		struct timeval {
				   long    tv_sec;         /* seconds */
				   long    tv_usec;        /* microseconds */
			   };
		Three possiblities with timeout:
				1. Wait forever (timeout is specified as a null pointer): Return only when one of the specified descriptors is ready for I/O.
				2. Wait up to a fixed amount of time (timeout points to a timeval structure). Return when one of the specified descriptors is ready for I/O but do not wait beyond the number of seconds and microseconds specified in the timeval structure.
				3. Do not wait at all (seconds = 0, microseconds = 0) Return immediately after checking the descriptors. This is called polling.
			Note: The wait in the first two scenarios is normally interrupted if the process catches a signal
		Descriptor Sets: (readfds,writefds, exceptfds). Descriptor sets are arrays of integers, each bit in each integer corresponding to a descriptor.
			readfds	 	--> Notify when data is available to read
			writefds	--> Notify when write buffer is having space to write
			exceptfds	--> Used in sockets (out-of-band data)
		nfds:
			It should be set to the highest numbered file descriptor in any of the three sets, plus 1. The indicated file descriptors in each set are checked up to this limit. ex: if we have 5 file descriptors but the highest number is 100, the select will check any bit from 0 to 100. Reason for this argument exists is for efficiency. Although each fd_set has room for many descriptors, typically 1024, this is much more than the number used by a typical process. The kernel gains efficiency by not copying unneeded portions of the descriptor set between the process and the kernel, and by not testing bits that are always 0.
		Macros for fd_set datatype:
			– FD_ZERO(fd_set *fdset);  // clear all bits in fdset
			– FD_SET(int fd, fd_set *fdset);  // turn on the bit for fd in fdset
			– FD_CLR(int fd, fd_set *fdset);   // turn off the bit for fd in fdset 
			– int FD_ISSET(int fd, fd_set *fdset);  // is the bit for fd on in fdset? 
		Return:
			select modifies the descriptor sets pointed to by the readset, writeset, and exceptset pointers. When we call the function, we specify the values of the descriptors that we are interested in, and on return, the result indicates which descriptors are ready. We use the FD_ISSET macro on return to test a specific descriptor in an fd_set structure. Any descriptor that is not ready on return will have its corresponding bit cleared in the descriptor set. The return value from this function indicates the total number of bits that are ready across all the descriptor sets. If the timer value expires before any of the descriptors are ready, a value of 0 is returned. A return value of –1 indicates an error (which can happen, for example, if the function is interrupted by a caught signal).

	Support for select/poll system call requires support from the device driver: poll method.
		unsigned int (*poll) (struct file *, poll_table *);
		Header file for poll_table structure : <linux/poll.h>

	Driver Poll Implementation:
	It needs to perform the following two operations:
		1. Call kernel's poll_wait() function on one or more wait queues
		2. Return a bitmask describing operations that could be immediately performed without blocking.
		 void poll_wait (struct file *, wait_queue_head_t *, poll_table *);

	Bitmask:
		POLLIN  -->  This bit must be set if the device can be read without blocking.
		POLLRDNORM  -->  This bit must be set if "normal'' data is available for reading.
							A readable device returns (POLLIN | POLLRDNORM).
		POLLOUT  --> This bit is set in the return value if the device can be written to without blocking.
		POLLWRNORM  -->   This bit has the same meaning as POLLOUT, and sometimes it actually is the same number. 
							A writable device returns (POLLOUT | POLLWRNORM).
	Device Drivers need not worry about poll_wait internals. They must use it as an opaque object.

	Problem with select:
		- What happens when i have file descriptors:1005, 1006 which i want to verify whether they are ready to read from. I will call select with nfds of 1007 and the appropriate value of readfds. Kernel gets a request from a user space program to monitor some file descriptors for reading. It knows that the file descriptors are smaller than 1007, but that's all it knows. To figure out which file descriptors the program is interested, the kernel needs to check all 1007 file descriptors, safely one by one. Checking 1007 file descriptors when the program really only cares about two is quite inefficient. What happens when the file descriptors were 10010 and 100019. select() performs very poorly once the file descriptors get large. maximum limit of file descriptor is [ uname -r ].
		- Second Problem with select: How many file descriptors should fd_set be able to hold? Ideally, it should be able to hold as many file descriptors as a process can have open. $ ulimit -a. Traditionally, Linux allowed only 1,024 file descriptors per process, so this was reasonable. From man page of select: select() can monitor only file descriptors numbers that are less than FD_SETSIZE. Executing FD_CLR() or FD_SET() with a value of fd that is negative or is equal to or larger than FD_SETSIZE will result in undefined behavior. See Bugs section of select man page.
		- Third problem with select: select modifies the readfds/writefds/exceptfds passed as input, you should either
			1. Reinitialize them for the next call
			2. Backup your readfds/writefds/exceptfds

	overcomes previous problems. poll function: poll() performs a similar task to select(2): it waits for one of a set of file descriptors to become ready to perform I/O.
		Header File: #include <poll.h>
		int poll(struct pollfd *fds, nfds_t nfds, int timeout);
			Arguments:
				fds: must point to an array of struct pollfd. Each element in the array specifies a file descriptor that the program is interested in monitoring, and what events on that file descriptor the program would like to know about.
			struct pollfd {
				int     fd;       /* descriptor to check */
				short   events;   /* events of interest on fd */
				short   revents;  /* events that occurred on fd */
			};
			nfds: Number of items which are present in the fds argument.
			timeout: the number of milliseconds that poll() should block waiting for a file descriptor to become ready
			Returns:
				count of ready descriptors on success
				0 on timeout
				-1 on error

	events/revents:
		events: input parameter, a bit mask specifying the events the application is  interested in for the file descriptor fd
		revents: output parameter, filled by the kernel with the events that actually  occurred.

	Input to Events:
		POLLIN          There is data to read.
		POLLOUT         Writing is now possible

	Error value in revents:
		POLLERR:        This is set if an error condition has occurred on the file descriptor.
		POLLHUP:        This is set when the file descriptor refers to a terminal that has been hung upon.
		POLLNVAL:       Invalid request: fd not open

26)
	Developers, Maintainers in Linux Kernel: Most parts of the kernel have an associated maintainer. The maintainer is the individual (or individuals) who is in charge of specific parts of the kernel. Example:
		1. Each individual driver has an associated maintainer
		2. Each Kernel subsystem for example networking subsystem also has an associated maintainer. Subsystems may have multiple maintainers. Examples of subsystems:
			a) Memory Management
			b) Networking
			c) scheduling
			d) USB
			e) PCI
		These maintainers decide which patch goes to the mainline kernel. The maintainer for a specific driver or subsystem is usually listed in the file MAINTAINERS, which is also located in the root of the kernel source tree. There is a special type of maintainer known as the kernel maintainer. This individual actually maintains the kernel tree. [ vi MAINTAINERS ] has list of maintainers in Linux.

	What is Linux Kernel Tree? The Linux Kernel source-tree is a directory which contains all of the kernel source. You could build a new kernel, install that, and reboot your machine to use the rebuilt kernel. There are several main and susbsystem git repositories of Linux Trees.

	Mainline Kernel Tree: Maintained by Linus Torvalds. This is the tree where Linux releases mainline kernels and RC releases.

	Stable Tree: Maintained by Greg Kroah-Hartman. This tree consists of stable release branches. Stable releases are based on this tree.

	linux-next Tree: Maintained by Stephen Rothwell. Before updates from subsystem trees are merged into the mainline tree, they need to be integration-tested. This tree is used for integration testing. The linux-next tree contains the latest version of the staging tree.

	Staging Tree: Used to hold stand-alone drivers and filesystems that are not ready to be merged into main portion of
	Linux Kernel tree at this point due to coding standards or quality issues. Resolves the "hundreds of different download sites" problem that most out-of-tree drivers had in past. Location: drivers/staging folder.

	Submitting Patches: The development process itself happens entirely over emails.  Every kernel subsystem has a mailing list. Patches touching a specific driver/subsystem are sent to the maintainer listed in MAINTAINER. The MAINTAINER file consists of subsystem git information and mailing lists for each of the subsystem. Contributors send patches to mailing lists through email. While sending the patch, carbon copy (cc) to  linux-kernel@vger.kernel.org (Linux Kernel Mailing List):
		Subject of the mail: "[PATCH] brief description"
		Body of the mail: Technical details of your changes patch makes and reasons behind those changes
		Add Kernel version to the email.
		Attach the patch as plain text.
		Note: If your patch is large or contains several logical changes, you should break the patch into chunks with each chunk representing a logical change.
		Each Email should send one patch.

	Linux Kernel Release Cycle:
		1. Linus Torvalds releases a new kernel and opens a 2-week merge window.
		2. Subsystem maintainers collects patches ahead of time and send them to Linus during this merge window.
		3. Nearly 10,000 patches get pulled into linus's tree during these 2 weeks.
		4. At the end of two weeks Linus declares the merge window has closed ande releases the first release candidate known as rc1.
		5. At this point, the release cycle moves into a bug fixes-only mode, with a series of release candidate(rc) from Linus.
		6. Every week a new rc is released with the name 5.12.rc1, 5.12.rc2, and so on.
		7. Finally after the end of these rc weeks the kernel is stable and ready for release as version 5.12.
		8. The whole development is a matter of 10-12 weeks and we get a new version in every three months. References: https://www.kernel.org/doc/html/latest/process/2.Process.html

	Types of Releases:
		1. Prepatch/RC:
			Mainline kernel pre-releases
			Contains new features which must be tested before they can put into a stable release
			Maintained and released by Linus Torvalds
			https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/refs/tags?h=v5.4-rc6
		2. Mainline:
			Maintained by Linus Torvalds
			Tree where all the new features are introduced.
			New mainline kernels are released every 2-3 months
		3. Stable:
			After each mainline kernel is released, it is considered "stable."
			Any bug fixes for a stable kernel are backported from the mainline tree and applied by a designated stable kernel maintainer.
			Stable kernel updates are released on as-needed basis, usually once a week.
			There are usually only a few bugfix kernel releases until next mainline kernel becomes available
		4. LongTerm:
			Stable releases are selected for long term maintenance to provide critical bug fixes for older kernel trees
			https://www.kernel.org/category/releases.html

	Linux Versioning:
	Mainline Kernels: x.y
	Stable Kernels: x.y.z

	How to find out whether my kernel is a distribution kernel or not ? Unless you downloaded, compiled and installed your own version of kernel from kernel.org, you are running a distribution kernel.
		# uname -r
		5.0.0-32-generic
	If you see anything at all after the dash, you are running a distribution kernel.

27)
	Building Kernel: The process of building a kernel has two parts
		1. Configuring the kernel options
		2. Building the source with those options

	Configuring Kernel: The kernel configuration is kept in a file called .config in the top directory of the kernel source tree. After downloading the sources, there will be no .config file, it needs to be created. It can be created from
		1. Scratch
		2. Default configuration from a running kernel version ( it is present in /boot/config-`uname -r` )

	Copying the configuration file of your distribution is the safest approach for the very first kernel install on any system. Run the following command to generate a kernel configuration file based on the current configuration.
		$ make oldconfig
		[ make oldconfig V=1 ]
	The above command reads the existing .config file and prompts the user for options in the current kernel source that are not found in this file.

	To build the kernel in a multithreaded way, use the -j option to the make program. It is best to give a number to the -j option that corresponds to twice the number of processors in the system. Example with four processors.
	$ make -j8

	Installing the new kernel: Once the kernel compilation is complete, install the new kernel with:
		$ sudo make modules_install

	This will install all the modules that you have built and place them in the proper location in the filesystemfor the new kernel to properly find. Modules are placed in the /lib/modules/kernel_version directory.

	kernel_version is the kernel version of the new kernel you have just built. After the modules have been successfully installed, the main kernel image must be installed.
	$ sudo make install

	The above command will perform the below steps:
		1. Kernel build system will verify that the kernel has been successfully built properly
		2. Kernel build system will install the static kernel into the /boot directory and name it based on the kernel version
		3. Any needed initial ramdisks images will be automatically created, using the modules that have been just installed during the modules_install phase
		4. The bootloader program will be properly notified that a new kernel is present, and it will be added to the appropriate menu so the user can select it next time the machine is booted. ( for example, GRUB is updated ).
		5. After this is finished, the kernel is successfully installed, and you can safely reboot and try out your new kernel image.

	IMP Note: Installation does not overwrite older kernel images. Very IMP: watch linux boot process at ( video 47 - 50 )

	Different Architecture: The kernel build system allows you to specify a different architecture from the current system with the ARCH= argument.

	There are many methods available for configuring the kernel.
		$ make defconfig
	Creates a ".config" file with default options from the ARCH supplied defconfig. Default Configurations are generally stored in the directory: arch/$(ARCH)/configs. When you run "make defconfig" on "x86" machine, it copies the configuration options from arch/x86/configs/i386_defconfig.

	If you diff the defconfig and .config, you will find they are not same why? .config vs defconfig:
	The .config file is a full config file: it contains the value for all options. A defconfig stores only the values for options for which the non-default value is chosen. When .config file is being generated, kernel build system goes through all Kconfig files (from all subdirs), checking all options in those Kconfig files:
		if option is mentioned in defconfig, build system puts that option into .config with value chosen in defconfig.
		if option isn't mentioned in defconfig, build system puts that option into .config using its default value, specified in corresponding Kconfig.

	make config:
		Text-based Configuration. 
		Options are prompted one after another.
		All options need to be answered
		Access to former options is not possible

	make menuconfig:
		Menu-driven user interface
		Allows to navigate forwards and backward directly between features
		Allows to load and save files with filenames different from ".config"
		Provides search feature
		It uses ncurses library for GUI. 
		If the ncurses library is not installed, make menuconfig option fails. 
		To install ncurses library on Ubuntu: sudo apt-get install libncurses5-dev
		[ ] --> Yes/No
			[ ]  excluded
			[*]  built-in
		< > -> built-in/module/excluded
			<M>  Module
			<*>  Built-In
			< >  Left out altogether

	$ make clean
		Remove most generated files, keeps the config, enough build support to build external modules.

	$ make mrproper
		Remove all generated files, Removes config, Removes various backup files (include/config, include/generated, scripts/basic, scripts/fixdep).

	$ make distclean
		Performs all operations of make mrproper, Deletes temporary code navigation files:tags, cscope*, Deletes files generated as a side-effect of working with patches: *.orig *.rej *.bak, Deletes core dump files.

	Building Only a Portion of the Kernel: Kernel build system allows you to easily build a portion of the kernel. For example, if you want to build the files in drivers/pci.
		$ make drivers/pci
	The above command will not build the modules in that directory. To build modules
		$ make M=drivers/pci
	Finally execute 
		$ make
	to have the build system check all changed object files and do the final kernel image link properly. To build only a particular module
		$ make drivers/usb/serial/usb-serial.ko
	The build system will build all needed files for the usb-serial.ko kernel module, and do the final link to create the module.

31)
	I/O Memory: The most widely supported form of IO is memory mapped IO. A part of the CPU’s address space is interpreted not as accesses to memory, but as accesses to a device. Some architectures define devices to be at a fixed address, but most have some method of discovering devices. Advantage of memory mapped I/O is that it keeps the instruction set small. Logic of creating separate I/O address space initially because the memory address space of processors was quite limited. When x86 moved to 32-bit, the address space was still same 64KB, even after it moved to 64-bit. Examples of I/O Memory:
		a) Holding Video Data
		b) Ethernet Packets
		c) Device Registers

	Requesting I/O Memory: Functions equivalent to request_region() and release_region(), but for I/O memory
		struct resource *request_mem_region(
				unsigned long start,
				unsigned long len,
				char *name);
		void release_mem_region(
				unsigned long start,
				unsigned long len);
		request_mem_region:
			---> Informs kernel that your driver is going to use this range of I/O addresses
			---> This prevents other drivers from using it through request_mem_region
		cat /proc/iomem lists all the kernel drivers requested 'request_mem_region'

	Can we access(read/write) MMIO memory directly? No, we can't . Kernel is running in virtual address space. Like user space, the kernel accesses memory through page tables. So, when kernel code needs to access memory-mapped I/O devices, it must first set up an appropriate kernel page-table mapping.
		void *ioremap(unsigned long phys_addr, unsigned long size);
		void iounmap(void * addr);
	A successful call to ioremap() returns a kernel virtual address corresponding to start of the requested physical address range. Return address of ioremap is not normally meant to be dereferenced directly, though, for a number of (often architecture-specific) reasons.

	Functions to read and write data using memory mapped by ioremap()
		Read:
			unsigned int ioread8(void *addr); unsigned int ioread16(void *addr); unsigned int ioread32(void *addr);
		Write:
			void iowrite8(u8 value, void *addr); void iowrite16(u16 value, void *addr); void iowrite32(u32 value, void *addr);

	Why do we need to call ioread instructions why can't i directly access by dereferencing? Compiler can perform optimizations. For example, the below logic:
		*reg  = 1; *reg = 2;
			will be converted to 
				*reg = 2;
	MMIO registers will have side effects, so you must force the compiler to avoid optimizations by using volatile and avoid hardware caching using barriers. ioread functions internally perform these operations.

	Ports as I/O Memory: Linux kernel provides a function ioport_map which maps I/O ports and make them appear as I/O Memory.
		void *ioport_map(unsigned long port, unsigned int count);
	To unmap:
		void ioport_unmap(void *addr);
	Note: I/O Ports must still be allocated with request_region before they can be remapped in this way.

	Accessing mmio from user space: /dev/mem is a character device file that is an image of the main memory of the computer. ( main memory is not just RAM but includes all other devices also ). Byte addresses in /dev/mem are interpreted as physical memory addresses. [ man 4 mem ] for more information Implemented by drivers/char/mem.c. Accessing /dev/mem from command line:
		$ hexdump -C /dev/mem
		$ cat /dev/mem | strings
		$ cat /dev/mem | strings -n 20

	CONFIG_STRICT_DEVMEM kernel configuration option limits the areas which can be accessed through /dev/mem
		# cat /boot/config-`uname -r` | grep CONFIG_STRICT_DEVMEM

	It is enabled by default x86/x86_64 and ARM platforms. Enabling CONFIG_STRICT_DEVMEM implements strict access to /dev/mem so that it only allows user-space access to memory mapped peripherals. With this option disabled, the root user from user-space can access all kernel and user-space memory through /dev/mem. Try with qemu-system-arm. The QEMU emulator supports the VersatilePB platform, that contains an ARM926EJ-S core. Memory map can be read : cat /proc/iomem

	devmem present in busybox: devmem is a small program that reads and writes from physical memory using /dev/mem
		Usage: devmem ADDRESS [WIDTH [VALUE]]
		Read/write from physical address
			ADDRESS Address to act upon
			WIDTH   Width (8/16/...)
			VALUE   Data to be written
		$ devmem 0x00000000 8
		$ devmem 0x00000000 16
		$ devmem 0x00000000 32

	UART0 is mapped: 0x101f1000. The code that emulates the serial port inside QEMU implements a subset of the functionalities of the PL011 Prime Cell UART from ARM. UARTDR register that is used to transmit (when writing in the register) and receive (when reading) bytes; this register is placed at offset 0x0.
		$ devmem 0x101f1000 8 0x61

	On Ubuntu: $ sudo apt install devmem2

	How to dump BIOS data on to a file?
		$ grep ROM /proc/iomem
			which results in:
			000c0000-000c7fff : Video ROM
			000e2000-000e2fff : Adapter ROM
			000f0000-000fffff : System ROM
		Starting Address = 0xf0000 = 960KB
		Ending Address = 0xfffff = 1024KB
		$ sudo dd if=/dev/mem of=pcbios.bin bs=1k skip=960 count=64
		$ cat pcbios.bin | strings -n 20

	If i say echo "linux is the future" and strings /dev/mem | grep "linux is the future"? will it be present in RAM? Yes

32)
	System Management BIOS is a standard developed by DMTF (Distributed Management Task Force). The purpose of this standard is to allow the operating system to retrieve information about the PC. The specification addresses how motherboard and system vendors present management information about their products in a standard format by extending the BIOS interface on Intel Architecture systems. https://www.dmtf.org/sites/default/files/standards/documents/DSP0134_3.2.0.pdf

	It provides information such as:
		a) Make, Model
		b) Serial Number
		c) BIOS Version
		d) Processor
		e) Memory Configuration
		f) .....

	Locating SMBIOS Entry Point Table: On boot, the SMBIOS will put a table somewhere in memory. The SMBIOS Entry Point Table is located somewhere between the addresses 0xF0000 and 0xFFFFF, and must be on a 16-byte boundary. To find the specific location of the start of the table it is necessary to search that region of memory for the string "_SM_".

	Parsing the Entry Point Table: The entry point table has the following structure for SMBIOS 2 and below (the structure is different for SMBIOS 3):( ignore )
		struct SMBIOSEntryPoint {
			char EntryPointString[4];    //This is _SM_
			uchar Checksum;              //This value summed with all the values of the table, should be 0 (overflow)
			uchar Length;                //Length of the Entry Point Table. Since version 2.1 of SMBIOS, this is 0x1F
			uchar MajorVersion;          //Major Version of SMBIOS
			uchar MinorVersion;          //Minor Version of SMBIOS
			ushort MaxStructureSize;     //Maximum size of a SMBIOS Structure (we will se later)
			uchar EntryPointRevision;    //...
			char FormattedArea[5];       //...
			char EntryPointString2[5];   //This is _DMI_
			uchar Checksum2;             //Checksum for values from EntryPointString2 to the end of table
			ushort TableLength;          //Length of the Table containing all the structures
			uint TableAddress;	     //Address of the Table
			ushort NumberOfStructures;   //Number of structures in the table
			uchar BCDRevision;           //Unused
		 };

	TableAddress contains the address of the table that contains all the structures with information about the PC. All of the structures are located from [TableAddress] to [TableAddress + TableLength]. The structures are located directly adjacent to each other in memory, with a new structure beginning as soon as another one ends. Each structure is composed of a header, a structure specific table, and a string table. The format of the header is as follows.
		 struct SMBIOSHeader {
			uchar Type;
			uchar Length;
			ushort Handle;
		 };
	Located at TableAddress is a SMBIOS header. The value of Type indicates what element the structure contains information about. Length indicates the size of header + data table. The strings are not included in the length. Immediately after the end of the header is the data. At the end of the data table (Address + Length), the strings section starts. Each string is NULL terminated and is limited to 64 characters. Strings are referenced within tables by using an index into the string table. The first string begins immediately after the data, and the second string begins immediately after that, etc. The string section itself is terminated by two consecutive zero bytes. The next table begins immediately after the end of the string section.
		Code	Description
		0	BIOS Information
		1	System Information
		2	Mainboard Information
		3	Enclosure/Chasis Information
		4	Processor Information
		7	Cache Information
		9	System Slots Information
		16	Physical Memory Array
		17	Memory Device Information
		19	Memory Array Mapped Address
		20	Memory Device Mapped Address (optional as of SMBIOS 2.5)
		32	System Boot Information

	dmidecode: dmidecode is a tool for dumping a computer's SMBIOS/DMI table contents in a human-readable format. $dmidecode. When you run dmidecode, it will try to locate the DMI table. It will first try to read the DMI table from sysfs, if failed try to read from memory directly /dev/mem. If dmidecode  succeeds  in locating a valid DMI table, it will then parse this table and display it.

	biosdecode: biosdecode parses the BIOS memory and prints information about all structures (or entry points) it knows of. Currently known entry point types are:
		SMBIOS/DMI
		SYSID
		PNP
		ACPI
		BIOS32
		...

33)
	Early PC's: Peripheral devices in the early PCs used fixed i/o-ports and fixed memory-addresses. Intel introduced a new bus standard PCI (Peripheral Component InterConnect) in the early 1990'S. To avoid contention among equipment vendors for fixed I/O Addresses (0x0000 - 0xFFFF), one of the goals of PCI wasto create a flexible scheme for allocating addresses that future peripherals could use.

	Address Space: A PCI device can have up to three address spaces:
		a) Configuration Space: i/o-ports 0x0CF8-0x0CFF dedicated to accessing PCI Configuration Space (Required)
		b) I/O Space (Optional)
		c) Memory Space (Optional)
	Note: Every PCI device must implement the PCI configuration register dictated by the PCI specification. Otherwise, the device will not be regarded as valid PCI device. Each PCI device is identified by a
		a) Bus Number
		b) Device Number
		c) Function Number
	The PCI Specification permits a single system to host up to 256 buses. Each bus hosts up to 32 Devices. Each Device can have multi functionality. There are 8 possible funtions per device.

	PCI Configuration Space: Each PCI Device has a set of registers referred to as configuration space. Size of the Configuration space is 256 bytes.
		First 64 bytes (0x00 - 0x3f) are standardized.
		Next 192 bytes (0x40 - 0xff) are vendor specific.
			Registers 0x00, 0x01 are defined by PCI spec as vendor ID (16-Bit)
			Registers 0x02, 0x03 are defined by PCI spec as product ID (16-Bit)
		Vendor ID identifies the manufacturer of the device. Allocated by the PCI SIG to ensure each is unique .
		Device ID identifies the particular device, set by the vendor 

	How do you access all registers present in the Configuration Space? Accessing these registers is like accessing RTC(CMOS) Memory.
		PCI Index Port  0xCF8h
		PCI Data Port   0xCFCh

		PCI Index Port (0xCF8)
		============================
			31                                   0
			---------------------------------------------------------------------------
			| |Reserved |Bus Number |Device Number|Function Number|Register Number|0|0|
			---------------------------------------------------------------------------
								  B      D         F                Offset
			Bit 31 when set, all reads and writes to CONFIG_DATA are PCI Configuration transactions
			Bits 30:24 are read-only and must return 0 when read
			Bits 23:16 select a specific Bus in the system (up to 256 buses)
			Bits 15:11 specify a Device on the given Bus (up to 32 devices)
			Bits 10:8 Specify the function of a device (up to 8 devices)
			Bits 7:0 Select an offset within the Configuration Space (256 bytes)
		Addresses are often given in B/D/F, Offset notation (also written as B:D:F, Offset) 

	PCI Data Port (0xCFCh): Read and Write to 0xCFCh with Bit 31 enabled in 0xCF8 results in PCI configuration transaction. If the Bit 31 is not enabled, according to PCI Spec, transaction is forwarded out as Port I/O.

	How do you find out Bus, Device and Function of a PCI Device?
	$ lspci
	Each line starts with the PCI bus address formatted as bus:slot.function

	What happens if we try to read a PCI device(B/D/F) which doesn't exist? When a configuration access attempts to select a device that does not exist, the host bridge will complete the access without error, dropping all data on writes and returning all ones on reads.

	Base Address Registers (BAR): Base Address Registers holds the memory addresses used by the device. PCI Configuration Registers provides space for up to 6 BARs. Each BAR is 32-bits wide to support 32-bit address space locations. Concatenating two 32-bit BARs provides 64-bit addressing capability. Each region consists of either memory or I/O locations. So, RC can access exposed devicxe area using BAR configurations and not all from device memory. Device can access all RC memeory area, but those can be protected by SMMU/IOMMU to allow only certain region. RC can indicate area using doorbell. Doorbell : RC to device. MSI/MSI-X: device to RC. RC has ECAM region to map.

	How do you determine the amount of address space needed by a PCI device? A Base Address is half the information that’s needed. We need to get the size of the device.
		1. you must save the original value of the BAR
		2. write a value of all 1's to the register
		3. then read it back
		4. restore the original value.
	The amount of memory can then be determined by masking the information bits, performing a bitwise NOT ('~' in C), and incrementing the value by 1

	PCI Express: The PCI Express bus extends the Configuration Space from 256 bytes to 4096 bytes. This extended configuration space *cannot* be accessed using the legacy PCI method (through ports 0xCF8 and 0xCFC). The enhanced configuration mechanism makes use of memory mapped address space range/s to access PCI configuration space. On x86 and x64 platforms, the address of each memory area is determined by the ACPI 'MCFG' table
	[ ls /sys/firmware/acpi/tables/ ]
	[ hexdump -C /sys/firmware/acpi/tables/MCFG ]

	More reading: https://www.programmersought.com/article/78017399476/, https://ctf.re/windows/kernel/pcie/tutorial/2023/02/14/pcie-part-1/, https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/virtualization_deployment_and_administration_guide/sect-pci_devices-pci_passthrough etc.

34)
	sysfs: sysfs is a virtual file system. It provides information about
		a) various kernel subsystems
		b) hardware devices
		c) and associated device drivers
	from the kernel's device model to user space through virtual files.

	CONFIG_SYSFS: By default syfs is compiled in the Linux Kernel. It depends on CONFIG_SYSFS being enabled in the Linux kernel configuration. $ cat /boot/config-`uname -r` | grep CONFIG_SYSFS

	Mounting Sysfs: $ mount | grep sysfs. If sysfs is not already mounted, you can mount it with the below command $ mount -t sysfs sysfs /sys 

	Source Code: Present in fs/sysfs directory
		Documentation/filesystems/sysfs.txt

	sysfs: The root of the sysfs contains at least 10 directories
		- block: Contains one directory for each of the registered block devices on the system. Each of those directories, in turn, contains any partitions on the block device. Connect a USB drive and you should see, directory should be created in /sys/block. Disconnect USB drive, and directory should be removed.
		- bus: provides a view of the system buses. Inside each of these directories are two subdirectories
			a) devices:
				Correspond to devices discovered on this bus.
			b) drivers:
				Device drivers loaded for this bus.
			Connect a USB drive, and you should see directory in /sys/bus/usb/devices. Disconnect USB drive, and directory should be removed.
		- class: contains a view of the devices on the system organized by high-level function. Examples: input, network, backlight, sound etc.
		- dev: Contains two sub directories:
				- block
				- char
			Inside each of the sub directories are symbolic links of the form major-id:minor-id. Load a character driver and see the behavior is /sys/dev/char. try adding and removing char driver and check that entry is coming and getting deleted after unloading.
		- devices: Contains information about all devices represented in the device model. Most of the data present in other directories is symlink to this directory.
		- firmware: contains interfaces for viewing and manipulating firmware-specific objects and attributes. Eg. ACPI, EDD, EFI. If you booted with UEFI enabled, you will be seeing a /sys/firmware/efi folder. check by running ls into it. We will see efi, dmi, acpi etc.
		- fs: contains a view of registered filesystems.
		- kernel: contains various files and subdirectories that provide information about the running kernel
		- module: contains one subdirectory for each module that is loaded into the kernel. name of each directory is the name of the module. /sys/module/<modulename>/parameters: each file containing the value of the corresponding parameter.
		- power: Contains information about power management sleep states
		- hypervisor:

	Linux Device Model: Purpose: To provide information like:
		1. what devices are in the system
		2. how they are in terms of power management
		3. what bus they are attached to
		4. what drivers they have
	The device model provides a single mechanism for representing devices and describing their topology in the system.

	Benefits:
		--> The capability to enumerate all the devices in the system, view their status, and see to what bus they attach
		--> The capability to generate a complete and valid tree of the entire device structure of the system, including all buses and interconnections
		--> The capability to link devices to their drivers and vice versa
		--> The capability to categorize devices by their class, such as input device, without the need to understand the physical device topology
		--> The capability to walk the tree of devices from the leaves up to the root, powering down devices in the correct order

	kobject (Kernel Object): Linux Device Model provides a number of structures to ensure the interaction between a hardware device and a device driver. kobject is the heart of the device model. kobject provides various functionalities:
		---> Reference Counting
		---> Parent Pointer which enables creation of hierarchy of objects
		struct kobject {
				const char              *name;
				struct list_head        entry;
				struct kobject          *parent;
				struct kset             *kset;
				struct kobj_type        *ktype;
				struct kernfs_node      *sd; /* sysfs directory entry */
				struct kref             kref;
		#ifdef CONFIG_DEBUG_KOBJECT_RELEASE
				struct delayed_work     release;
		#endif
				unsigned int state_initialized:1;
				unsigned int state_in_sysfs:1;
				unsigned int state_add_uevent_sent:1;
				unsigned int state_remove_uevent_sent:1;
				unsigned int uevent_suppress:1;
		};
			name --> Points to the name of this kobject, will show in sysfs
			parent --> Points to this kobject's parent, this makes object hierarchical structure
			kref --> Provides reference counting
			ktype,kset --> Used to group kobjects
	Kobjects are usually embedded in other structures and are generally not interesting on their own. For example, the cdev structure has the following definition <linux/cdev.h>
		/* cdev structure - object representing a character device */
		struct cdev {
			struct kobject kobj;
			struct module *owner;
			const struct file_operations *ops;
			struct list_head list;
			dev_t dev;
			unsigned int count;
		};

	kobject Operations. kobject_init:
		void kobject_init(struct kobject *kobj, struct kobj_type *ktype);

	Initialize a kobject structure.
		kobj --> kobject to initialize. Before calling this function, the kobject must be zeroed.
			struct kobject *kobj;
			kobj = kmalloc(sizeof (*kobj), GFP_KERNEL);
			if (!kobj)
				return -ENOMEM;
			memset(kobj, 0, sizeof (*kobj));
			kobj->kset = my_kset;
			kobject_init(kobj, my_ktype);

	kobject_create: The above multistep effort is handled by kobject_create().
		struct kobject * kobject_create(void);
		struct kobject *kobj;
		kobj = kobject_create();
		if (!kobj)
			return –ENOMEM;

	Adding and Removing kobjects from sysfs: Initialized kobjects are not automatically exported to sysfs. To represent a kobject to sysfs,you use kobject_add():
		int kobject_add(struct kobject *kobj, struct kobject *parent, const char *fmt, ...);

	A given kobject’s location in sysfs depends on the kobject’s location in the object hierarchy. If the kobject’s parent pointer is set, the kobject maps to a subdirectory in sysfs inside its parent. If the parent pointer is not set, the kobject maps to a subdirectory inside kset->kobj. If neither the parent nor the kset fields are set in the given kobject, the kobject is assumed to have no parent and maps to a root-level directory in sysfs. Regardless, the name of the directory representing the kobject in sysfs is given by fmt, which accepts a printf()-style format string.

	kobject_create_and_add(): combines the work of kobject_create() and kobject_add() into one function.
		struct kobject * kobject_create_and_add(const char *name, struct kobject *parent);

	kobject_del(): Removing a kobject’s sysfs representation is done via kobject_del():
		void kobject_del(struct kobject *kobj);

	Implementation: lib/kobject.c
	using [ grep ] for kobject_create_and_add will tell which file is creating particular sysfs entry.

	Adding Files to sysfs: kobjects map to directories, what about files? Attributes map kernel data to files in sysfs.
		Header File: <linux/sysfs.h>
		struct attribute {
				const char              *name;
				umode_t                 mode;
		};
		name --> will be the file name of the resulting file in sysfs
		mode --> permissions of the file in sysfs
	A bare attribute contains no means to read or write the value of the attribute. 
		struct kobj_attribute {
				struct attribute attr;
				ssize_t (*show)(struct kobject *kobj, struct kobj_attribute *attr,
								char *buf);
				ssize_t (*store)(struct kobject *kobj, struct kobj_attribute *attr,
								 const char *buf, size_t count);
		};
	When an attribute is opened, a PAGE_SIZE buffer is allocated for transferring the data between the kernel and userspace.
		show(): Invoked when the sysfs entry is read from user space. It should copy the value of attribute given by attr into buffer(third argument). size of buffer is PAGE_SIZE
			Return Value:
					Success, Number of bytes written
					Negative error code on Failure
		store(): Read the size bytes from the buffer into the variable represented by attribute attr. size of buffer is PAGE_SIZE or less
			Return Value:
					Success, Number of bytes read
					Negative error code on Failure

	Creating New Attributes:
		int sysfs_create_file(struct kobject *kobj, const struct attribute *attr);
		This function associates the attribute structure pointed at by attr with the kobject pointed at by kobj. Before it is invoked, the given attribute should be filled out.
		Return Value: 
			Success - 0
			Failure - Negative error code

		void sysfs_remove_file(struct kobject *kobj, const struct attribute *attr);

	Attribute Groups: The attribute group interface is a simplified interface for easily adding and removing a set of attributes with a single call.
		struct attribute_group {
				const char              *name;
				umode_t                 (*is_visible)(struct kobject *,
													  struct attribute *, int);
				umode_t                 (*is_bin_visible)(struct kobject *,
														  struct bin_attribute *, int);
				struct attribute        **attrs;
				struct bin_attribute    **bin_attrs;
		};

	An attribute group is simply an array of attributes to be added to an object, as represented by the attrs field. Why they were created?
			- To make it easier to keep track of errors when registering multiple attributes at one time, and 
			- To make it more compelling to clean up all attributes that a piece of code may create for an object
		static int sysfs_create_group(struct kobject *kobj, const struct attribute_group *grp)

	Object Relationships: Objects throughout the kernel are referenced by multiple subsystems. When a block device is registered, a symbolic link is created to the device’s directory in the physical hierarchy. A symbolic link is also created in the device’s directory that points to the corresponding directory under the block directory. go in /sys/block and execute [ ls -la ] and check all are symbolic links.
			int sysfs_create_link(struct kobject *kobj, struct kobject *target, char *name);
	This function creates a link named name in the directory mapped from kobj to the directory mapped from target
		Return Value:
				Success - 0
				Failure - Negative Error Code

	void sysfs_remove_link(struct kobject *kobj, char *name);

	Binary Attributes: Convention of sysfs is to have a single value in human readable text format for each attribute. Other kind of attributes is binary attributes for handling larger chunks of binary data. Examples: Passing Firmware from user space program
		  PCI Configuration Space Registers
				struct bin_attribute {
						struct attribute        attr;
						size_t                  size;
						void                    *private;
						ssize_t (*read)(struct file *, struct kobject *, struct bin_attribute *,
										char *, loff_t, size_t);
						ssize_t (*write)(struct file *, struct kobject *, struct bin_attribute *,
										 char *, loff_t, size_t);
						int (*mmap)(struct file *, struct kobject *, struct bin_attribute *attr,
									struct vm_area_struct *vma);
				};
				attr -> name and permissions
				size -> Maximum size of the binary attribute
				read,write,mmap -> Work similar to char driver

	Creating a binary attribute:
		int sysfs_create_bin_file(struct kobject *kobj, struct bin_attribute *attr);

	Removing a binary attribute:
		int sysfs_remove_bin_file(struct kobject *kobj, struct bin_attribute *attr);

35)
	debugfs: debugfs helps kernel developers export large amounts of debug data into user-space.
		procfs  - Used for information about process
		sysfs   - Has strict one-value-per-file rule
		debugfs - no rules, any information can be placed by developers

	CONFIG_DEBUG_FS: To compile a Linux kernel with the debugfs facility, the CONFIG_DEBUG_FS option must be set to yes. $ cat /boot/config-`uname -r` | grep CONFIG_DEBUG_FS

	Mounting debugfs: $ mount | grep debugfs. If debugfs is not already mounted, you can mount it with the below command, $ mount -t debugfs none /sys/kernel/debug

	Note:
		1. Debugfs directory is accessible to only root user by default, can be changed with uid/gid/mode options while mounting.
		2. Can be used by only GPL Modules

	Why can't i use printk instead of putting data into debugfs ? Sometimes putting in a few printk() calls is sufficient, but, often, that is not the best way to go. The debugging information may only be useful occasionally, but the printed output clogs up the logs all the time. Using printk() also does not help if the developer wishes to be able to change values from user space.

	Creating a directory in debugfs:
		Header File: <linux/debugfs.h>
		struct dentry *debugfs_create_dir(const char *name, struct dentry *parent);
			If parent is NULL, the directory will be created in the debugfs root.
		Return Value:
			Success - struct dentry * which can be used to create files in the directory
			Failure - ERR_PTR(-ERROR)
				ERR_PTR(-ENODEV) is returned, when kernel has been built without debugfs

	To remove directory:
		void debugfs_remove(struct dentry *dentry);

	Create a file within debugfs:
		struct dentry *debugfs_create_file(const char *name, umode_t mode,
							   struct dentry *parent, void *data,
							   const struct file_operations *fops);
		name -> Name of the file to create
		mode -> access permissions the file should have
		parent -> the directory which should hold the file
		data -> will be stored in the i_private field of the resulting inode structure
		fops -> set of file operations which implement the file's behavior
	At a minimum, the read() and/or write() operations should be provided; others can be included as needed.
		Return Value:
			Success: dentry pointer to the created file
			Failure: ERR_PTR(-ERROR)

	What happens if i forget to delete call debugfs_remove? There is no automatic cleanup of any directories created in debugfs. If a module is unloaded without explicitly removing debugfs entries, the result will be a lot of stale pointers.

	debugfs_remove_recursive:
	   void debugfs_remove_recursive(struct dentry *dentry);

	If you pass a pointer for the dentry corresponding to the top-level directory, the entire hierarchy below that directory will be removed.

	Debugfs code provides a number of helper functions for simple situations. If you need to write to and read from a single value, you can use this to create an unsigned 8-bit value:
		struct dentry *debugfs_create_u8(const char *name, mode_t mode, struct dentry *parent, u8 *value);
			name - a pointer to a string containing the name of the file to create.
			mode - the permission that the file should have
			parent - a pointer to the parent dentry for this file
			value  - a pointer to a variable that needs to be read and written to.

	A few other helper functions to create files with single integer values are:
		struct dentry *debugfs_create_u16(const char *name, umode_t mode,
						  struct dentry *parent, u16 *value);
		struct dentry *debugfs_create_u32(const char *name, umode_t mode,
						  struct dentry *parent, u32 *value);
		struct dentry *debugfs_create_u64(const char *name, umode_t mode,
						  struct dentry *parent, u64 *value);
	Implementation: fs/debugfs/file.c

	How to provide a read only file? By appropriately setting the mode bits.

	The values in the previous files are in decimal; if hexadecimal is more appropriate, the following functions can be used instead:
		struct dentry *debugfs_create_x8(const char *name, umode_t mode,
						 struct dentry *parent, u8 *value);
		struct dentry *debugfs_create_x16(const char *name, umode_t mode,
						  struct dentry *parent, u16 *value);
		struct dentry *debugfs_create_x32(const char *name, umode_t mode,
						  struct dentry *parent, u32 *value);
		struct dentry *debugfs_create_x64(const char *name, umode_t mode,
						  struct dentry *parent, u64 *value);

	Boolean Values: Boolean values can be placed in debugfs with:
		struct dentry *debugfs_create_bool(const char *name, umode_t mode,
							   struct dentry *parent, bool *value);
			Read: Y (for non-zero values) or N, followed by a newline
			Write: Upper or lower case values, or 1 or 0

	Pointers and Error Values: Many internal kernel functions return a pointer value to the caller. Many of those functions can also fail. In most cases, failure is indicated by returning a NULL pointer value. This technique works, but it is unable to communicate the exact nature of the problem. Some interfaces really need to return an actual error code so that the caller can make the right decision based on what actually went wrong. A number of kernel interfaces return this information by encoding the error code in a pointer value. A function returning a pointer type can return an error value with:
		void *ERR_PTR(long error);
			where error is the usual negative error code.
		Header File: <linux/err.h>
		The caller can use IS_ERR to test whether a returned pointer is an error code or not:

36)
	Minimal Linux with QEMU/Busybox: QEMU (short for Quick Emulator) is a free and open-source  hypervisor that performs hardware virtualization.

	Busybox : combines tiny versions of many common UNIX utilities into a single small executable. BusyBox provides a fairly complete environment for any small or embedded system. Note: The utilities in BusyBox generally have fewer options than their full-featured GNU cousins. How it is useful? Building a minimal Linux kernel and booting it on an emulator allows developers to quickly build additional Linux kernel features.

	initrd vs initramfs: initrd (initial ramdisk) is a scheme for loading a temporary root file system into memory, which may be used as part of the Linux startup process. initrd and initramfs refer to two different methods of achieving this. Both are commonly used to make preparations before the real root file system can be mounted. An image of this initial root file system (along with the kernel image) must be stored somewhere accessible by the Linux bootloader or the boot firmware of the computer. The bootloader will 
		load the kernel,
		initial root file system image into memory and 
		then start the kernel
	At the end of its boot sequence, the kernel tries to determine the format of the image from its first few blocks of data, which can lead either to the initrd or initramfs scheme. In the initramfs scheme (available since the Linux kernel 2.6.13), the image is a cpio archive (optionally compressed).

	cpio - copy in and out

	The archive is unpacked by the kernel into a special instance of a tmpfs that becomes the initial root file system the kernel executes /init as its first process that is not expected to exit.

	Create Initramfs:
		Step1 : Create initramfs directory
			$ mkdir initramfs; $ cd initramfs
		Step2: Create directory structure
			$ mkdir -pv {bin,sbin,etc,proc,sys,usr/{bin,sbin}}
		Step3: Copy busbox install directory
			$ cp -av busybox-1.31.0/build/_install/* initramfs/
			-av: a means -dR --preserve=all, v means explain what is being done
			-dR --preserve=all:
			d means --no-dereference --preserve=links
			R means copy directories recursively
		Step4: Create init and make it executable 
			$ vi initramfs/init
			#!/bin/sh 
			mount -t proc none /proc
			mount -t sysfs none /sys
			mount -t debugfs none /sys/kernel/debug
			echo -e "\nBoot took $(cut -d' ' -f1 /proc/uptime) seconds\n"
			exec /bin/sh
			$ chmod +x initramfs/init
		Step5: Create initramfs
			$ cd initramfs
			$ find . -print0 | cpio --null -ov --format=newc | gzip -9 > ../initramfs.cpio.gz

	Boot the kernel/initramfs with QEMU:
		$ qemu-system-x86_64 -kernel linux_build/arch/x86/boot/bzImage -initrd initramfs.cpio.gz -m 512
			kernel option specifies the kernel image
			initrd option specifies the initramfs
			m option to specify the memory size (optional)

	check boot time. It is very less. also check /proc/meminfo and find that it is using very less memory.

37)
	Flashing Raspbian Image on Raspberry Pi3:
		- Copy the kernel and Device Tree blobs onto the SD card
		- Copy the modules into a folder
			$ sudo mount /dev/sdb2 /mnt /* mount root partition */ /* check using [ ls /mnt ] */
			$ sudo make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- INSTALL_MOD_PATH=/mnt modules_install
		- Finally Plug the Card and boot it

	Cross Compiling Linux Kernel Module:
		$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- -C ~/raspberrypi/linux/ M=${PWD} modules
		$ make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- -C ~/raspberrypi/linux/ M=${PWD} clean
	then copy generated .ko using ssh and then install it using [ sudo insmod ]

38)
	GPIO Registers on Raspberry Pi3: $ sudo cat /proc/iomem | grep gpio

39)
	What is Interrupt? Interrupt is an input signal to the processor, sent by the hardware peripherals when they need processor attention.

	What is the purpose of Interrupts? we want to perform an action with an incoming packet from the network card as soon as the packet arrives. If you don't want to continuously ask the network card «Has my packet arrived?» and waste your processor time, you can use external hardware interrupt IRQ. The interrupt line from a device should be connected to the INTR line of the CPU, and after each packet is received, the network card will make a signal over this line. The CPU will sense this signal and know that the network card has information for it. Only after that the CPU will read the incoming packet.

	Types of Interrupt:
		1. Hardware/Asynchronous:
			--> Generated by hardware devices 
			--> Occurs at arbitrary times(asynchronously) with respect to clock signals
			--> Examples: Pressing a key on the keyboard, Mouse Movement, Timer fired,
					  Network cards report the arrival of packet with interrupt.
		2. Software/Synchronous: 
			--> Generated by executing instructions
			--> Occurs synchronously with respect to processor clock
			--> Also called as exceptions/traps
			--> Examples: Divide-By-Zero, system call, page fault

	Exceptions: Exceptions are classified as faults, traps and abort, depending on the way they are reported and whether the instruction that caused the exception can be restarted without loss of program. traps increment the instruction pointer, faults do not, and aborts 'explode'.
		- Faults: These can be corrected and the program may continue as if nothing happened. Eg. page fault
		- Traps: Traps are reported immediately after the execution of the trapping instruction. Eg. int instruction, updating instruction pointer
		- Aborts: Some severe unrecoverable error. Eg. hardware failure

	General Protection Fault: A General Protection Fault may occur for various reasons. The most common are:
		Segment error (privilege, type, limit, read/write rights).
		Executing a privileged instruction while CPL != 0.
		Writing a 1 in a reserved register field.
		Referencing or accessing a null-descriptor.
		Trying to access an unimplemented register (like: mov cr6, eax)
		The saved instruction pointer points to the instruction which caused the exception.

	How debuggers work?
	To implement breakpoints on the x86 architecture, software interrupts (also known as "traps") are used. Breakpoints are implemented on the CPU by a special trap called int 3. int is x86 jargon for "trap instruction" - a call to a predefined interrupt handler. x86 supports the int instruction with a 8-bit operand specifying the number of the interrupt that occurred. Run the program in gdb, compile with debugging information.

	Triggering Methods: Each interrupt signal input is designed to be triggered by either a logical signal level or a particular signal edge (level transition).
		- Level Triggered:
			Interrupt is requested by holding the interrupt signal at its particular (high or low) active logic level. Level triggered interrupts happen as long as the interrupt line is held at active level. As long as the line is active, you get interrupt, when you serve the interrupt and return, if the interrupt line is still active, you get the interrupt again immediately. Level-triggered inputs allow multiple devices to share a common interrupt signal via wired-OR connections. 
		- Edge Triggered:
			Interrupt is requested by a level transition on the interrupt line.
				Falling Edge (high to low)
				Rising Edge  (Low to High) 
	These interrupts are issued per transition and not repeated. e.g. in networking when the packet queue goes from empty to non-empty. This makes it critical to never miss an edge triggered interrupt, because failure to handle one interrupt may result in no further interrupts from happening.

	Masking: Processors typically have an internal interrupt mask register. This allows selective enabling and disabling of hardware interrupts. Each interrupt signal is associated with a bit in the mask register.

	When the interrupt is disabled, the associated interrupt signal will be ignored by the processor.
		- Maskable Interrupts: Interrupts which can be enabled/disabled
		- NonMaskable Interrupts: Interrupts which cannot be disabled. Example: NMI, timeout signal from watchdog timer

	The 8086 processor has two hardware interrupt signals
		– NMI non-maskable interrupt
		– INTR Interrupt request (maskable interrupt)

	How to support more than two interrupts? It would be very unproductive to make a ton of INTR pins on the CPU for all of them. To solve this problem a special chip was invented — an interrupt controller. System software, such as the BIOS or operating system, is responsible for programming the interrupt router. 

	Get info about NVIC & GIC. Arm specific.

	APIC (Advanced PIC): The PIC method only works for a single processor systems. PIC can only send interrupts to one CPU, and in a multiprocessor system it is desired to load CPUs in a balanced way. The solution to this problem was the new APIC interface (Advanced PIC). Comprises of two components:
		1. IO-APIC - Interfaces with Devices
		2. LAPIC   - Interfaces with CPU

	LAPIC:
		Each processor in a multiprocessor system consists of a one LAPIC. Responsible for:
			- receiving various interrupt requests and delivering them to the processor
			- handling prioritization of interrupts
			- sending interrupts to other processors (known as inter processor interrupts or IPIs)
		LAPIC can be connected directly to I/O devices via local interrupt inputs (timer, thermal sensor) or through IOAPIC via external interrupt inputs. LAPIC can generate interrupts due to interrupt requests received from various sources.
	I/O APIC:
		connects to the devices to allow device interrupt requests to be routed to LAPIC(s). There can be one or more IOAPIC in the system. IOAPIC receives interrupt requests from the devices and sends them to LAPIC(s) based upon the redirection table entries (RTE) programmed in the IOAPIC.

	Most of the information in cpuid is reported by the kernel in cooked form either in /proc/cpuinfo. $ cat /proc/cpuinfo | grep -i apicid.  apicid: A unique ID given to each logical processor upon startup

	What happens when there is an interrupt:
		Device Asserts IRQ of I/O APIC, I/O APIC transfer interrupt to LAPIC, LAPIC asserts CPU interrupts, after current instruction completes CPU senses interrupt line and obtains IRQ number from LAPIC, jumps to interrupt handler.

	How does the hardware finds the interrupt handler? Interrupt Vector: On x86 Each interrupt or exception is identified by a number between 0 and 255. Intel calls this number a vector. The interrupt vector is used by the interrupt-handling mechanism to locate the system-software service routine assigned to the exception or interrupt. Up to 256 unique interrupt vectors are available in x86. The number of interrupt vectors or entry points supported by a CPU differs based on the CPU architecture. The first 32 vectors are reserved for predefined exception and interrupt conditions. Look into arch/x86/include/asm/traps.h.

	Interrupt Descriptor Table: The IDT is a linear table of 256 entries which associates an interrupt handler with each interrupt vector. When an interrupt is fired, the CPU looks at the IDT table, and finds what method needs to be called. Each descriptor is of size 8 bytes (on x86) and 16 bytes (on x86_64). During early boot, the architecture-specific branch of the kernel code sets up the IDT in memory and programs the IDTR register (special x86 register)of the processor with the physical start address and length of the IDT.

	Interrupt Handling in Linux Kernel:
		1. Whenever an interrupt occurs, assembly instructions in linux kernel are executed, which
			locates relevant vector descriptor by multiplying reported vector number by size of vector number(8/16)
			and adding the result to the base address of IDT.
		2. common_interrupt: arch/x86/entry/entry_64.S:
			a. saves the context of the running process
			b. This includes instruction pointer (IP), stack pointer and other registers needed to resume the process again
			c. This context is usually saved on the stack.
			d. Then the context is changed to interrupt stack. 
		3. Finally it arrives at do_IRQ(). do_IRQ() is the common function for all hardware interrupts
			arch/x86/kernel/irq.c
		4. Finds IRQ number in saved %EAX register
		5. Calls handle_irq which will finally call our registered interrupt handler.

	/proc/interrupts: Contains statistics related to interrupts on the system
			   CPU0       CPU1       CPU2       CPU3       CPU4       CPU5       
	   0:          2          0          0          0          0          0   IO-APIC    2-edge      timer
	   1:        458          0          0          0       6154          0   IO-APIC    1-edge      i8042
	   8:          0          0          0          0          0          1   IO-APIC    8-edge      rtc0
	   9:          0          0          0          0          0          0   IO-APIC    9-fasteoi   acpi
	  12:          0          0          0      22185          0          0   IO-APIC   12-edge      i8042
	  14:          0          0          0          0          0          0   IO-APIC   14-edge      ata_piix
	  15:          0          0          0          0          0          0   IO-APIC   15-edge      ata_piix
	  16:          0      19541          0          0          0          0   IO-APIC   16-fasteoi   vmwgfx, snd_ens1371
	  17:       9825          0      47519          0          0          0   IO-APIC   17-fasteoi   ehci_hcd:usb1, i

		Column 1:  IRQ number
					the file shows only interrupts corresponding to installed handlers
		Column 2:  counter of the number of interrupts received.
				   A column is present for each processor on the system
		Column 3/4: Type of the interrupt and device that handles the interrupt.
					For x86.
					XT-PIC — This is the old AT computer interrupts. 8259
					IO-APIC 
		Column 5:  device associated with this interrupt
					This name is supplied by the devname parameter to request_irq(),

	Difference between  IO-APIC-fasteoi and IO-APIC-edge? The difference lies in the way the interrupts are triggered. The -edge interrupt are edge triggered. The -fasteoi interrupts are level interrupts that are triggered until the interrupt event is acknowledged in the programmable interrupt controller (PIC). The EOI stands for End Of Interrupt.

	Watch Interrupts: To see the interrupts occurring on your system, run the command:
		# watch -n1 "cat /proc/interrupts"
	The watch command executes another command periodically, in this case "cat /proc/interrupts". The -n1 option tells watch to execute the command every second. -d option of watch highlight  the  differences  between successive updates

	# watch -n 0.1 -d 'cat /proc/interrupts'. --no-title / -t option of watch Turn off the header showing the interval, command, and current time at the top of the display, as well as the following blank line.

	# watch -n 0.1 -d --no-title 'cat /proc/interrupts'

	Interrupt Handlers: Interrupt handlers are the responsibility of the driver managing the hardware. If the device uses interrupts, then driver must register one interrupt handler. Registering an interrupt handler:
		Header File: <linux/interrupt.h>

		int request_irq(unsigned int irq,
				irq_handler_t handler,
				unsigned long flags,
				const char *name,
				void *dev);
		Parameters:
			irq     --> The interrupt number being requested
						For some devices,for example legacy PC devices such as the system timer or keyboard, this value is typically hard-coded.
						For most other devices, it is probed or otherwise determined programmatically and dynamically.
			handler   --> function pointer to the actual interrupt handler that services this interrupt.
						  invoked whenever the operating system receives the interrupt
						  typedef irqreturn_t (*irq_handler_t)(int, void *);
			flags     --> bitmask of options related to interrupt management.
			name      --> Name to be displayed in /proc/interrupts
			dev       --> Used for shared Interrupt Lines
		Return Value:
			Success  -->    Returns Zero
			Failure  -->    Non-Zero Value

		void free_irq(unsigned int irq_no, void *dev);
			When the interrupt is released, using the free_irq() function, you must send the same pointer value (dev) along with the same interrupt number (irq_no).

		Kernel registers all interrupt handlers with interrupt and one by one calls all and then finds if anyone returns done.

40)
	Return Value of Interrupt Handlers: Interrupt handlers return an irqreturn_t value.
		IRQ_NONE            interrupt was not from this device or was not handled
		IRQ_HANDLED         interrupt was handled by this device

	Interrupt Flags: The third parameter, flags of request_irq can be either zero or a bit mask of one or more flags defined in <linux/interrupt.h>.

	IRQF_SHARED informs the kernel that the interrupt can be shared with other devices. If this flag is not set, then if there is already a handler associated with the requested interrupt, the request for interrupt will fail.

	On success it returns 0

	Interrupt Flags:
		IRQF_TIMER			This flag specifies that this handler processes interrupts for the system timer.
		IRQF_PERCPU 		Interrupt is per cpu
		IRQF_PROBE_SHARED	set by callers when they expect sharing mismatches to occur

	Interrupt Flags:
		IRQF NOBALANCING: Flag to exclude this interrupt from IRQ balancing. The purpose of IRQ balancing is to distribute hardware interrupts across processors on a multiprocessor system in order to increase performance. Setting this flag forbids to set any CPU affinity for the requested interrupt handler.

	/proc/irq: Linux has gained the ability to assign certain IRQs to specific processors (or groups of processors). This is known as SMP IRQ affinity. The interrupt affinity value for a particular IRQ number is stored in the associated /proc/irq/IRQ_NUMBER/smp_affinity file, which can be viewed and modified by the root user. The value stored in this file is a hexadecimal bit-mask representing all CPU cores in the system /proc/irq/irq_number/smp_affinity_list contains cpu list. Example:
		$ cat /proc/irq/1/smp_affinity

	00000000,00000000,00000000,00000038
	This mean keyboard interrupt can occur in CPU 3, 4, 5. Setting this value to 1, as follows, means that only CPU 0 can service this interrupt:

	# echo 1 >/proc/irq/1/smp_affinity
	# cat /proc/irq/1/smp_affinity
	1

	Commas can be used to delimit smp_affinity values for discrete 32-bit groups. This is required on systems with more than 32 cores. /proc/irq/default_smp_affinity specifies default affinity mask that applies to all non-active IRQs. Once IRQ is allocated/activated its affinity bitmask will be set to the default mask

	How can a device driver know if the interrupt handler was activated by an interrupt generated by the device it manages? All devices that offer interrupt support have a status register that can be read in the handling routine to see if the interrupt was or was not generated by the device. Example: For 8250 serial port, this status register is IIR - Interrupt Information Register.

	we should not pass null as device id. this, example will fail to reserve device.

41)
	Why do we need to disable interrupts? Disabling interrupts, you can guarantee that an interrupt handler will not preempt your current code. Disabling interrupts also disables kernel preemption.

	Note: Disabling kernel preemption doesnot provide protection from concurrent access from another processor. Use locks to prevent another processor from accessing shared data simultaneously.

	Enable/Disable Interrupt:
		Header File: <linux/irqflags.h>
			local_irq_disable(); //disable all interrupts on the current processor
			local_irq_enable(); //Enables all interrupts on the current processor
		On x86, local_irq_disable() is a simple cli, and local_irq_enable() is a simple sti instruction. cli and sti are the assembly calls to clear and set the allow interrupts flag, respectively.

	Enabling/Disabling Interrupts:
		local_irq_disable() routine is dangerous if some of interrupts were already disabled prior to its invocation. The corresponding call to local_irq_enable() unconditionally enables interrupts, despite the fact that they were off to begin with.

		local_irq_save(flags); saves the interrupt state ( which interrupts were already disabled/enabled ) on flags and disables interrupt on that processor.
			local_irq_restore(flags); restores the previous interrupt state and enables interrupt on that processor. 

	Disabling a specific interrupt line: Disabling a specific interrupt line is also called as masking out an interrupt line. Example: you might want to disable delivery of a device’s interrupts before manipulating its state.
		- void disable_irq(unsigned int irq); //Disables a given interrupt line in interrupt controller. // this disables delivery of the given interrupt to all processors in system
		- void enable_irq(unsigned int irq); // this enables delivery of the given interrupt to all processors in system

	Note: disable_irq does not return until any executing handler completes.
		callers are assured that
			a) new interrupts will not be delivered on the given line,
			b) any already executing handlers have exited

	there is no API in Linux, to disable all interrupt on all processors in SMP. Only specific interrupt line on specific processor can be disabled.

	void disable_irq_nosync(unsigned int irq); The function disable_irq_nosync() does not wait for current handlers to complete.

	void synchronize_irq(unsigned int irq); The function synchronize_irq() waits for a specific interrupt handler to exit, if it is executing, before returning.

	synchronize_irq() spins until no interrupt handler is running for the given IRQ.

	What happens if i call disable_irq twice and enable_irq once? Calls to these functions nest.

	For each call to disable_irq() or disable_irq_nosync() on a given interrupt line, a corresponding call to enable_irq() is required. Only on the last call to enable_irq() is the interrupt line actually enabled. For example, if disable_irq() is called twice, the interrupt line is not actually reenabled until the second call to enable_irq().

	What happens if I disable interrupt line shared among multiple interrupt handlers? Disabling the line disables interrupt delivery for all devices on the line. Therefore, drivers for newer devices tend not to use these interfaces.

	Because PCI devices have to support interrupt line sharing by specification, they should not use these interfaces at all. Thus, disable_irq() and friends are found more often in drivers for older legacy devices, such as the PC parallel port.

	irqs_disabled(): The macro irqs_disabled(), returns nonzero if the interrupt system on the local processor is disabled.
		Header File: <linux/irqflags.h>

	Interrupt Context: When executing a interrupt handler, the kernel is in interrupt context. We know process context is the mode of operation the kernel is in while it is executing on behalf of a process. Eg. Executing a system call.

	As interrupt context is not backed with process, you cannot sleep in interrupt context. If a function sleeps, you cannot use it from your interrupt handler. Examples: kmalloc with GFP_KERNEL, ssleep.

	in_interrupt():
		Header File: <linux/preempt.h>
	To find out whether you are running in interrupt context or process context:
		- in_interrupt() returns non zero if the kernel is performing any type of interrupt handling.
		- in_interrupt() returns zero if the kernel is in process context

	Can we use current macro inside interrupt handler? It points to the interrupted process.

	/* if we add delay in interrupt context, it will have to wait. We should not have delay in interrupt */
	/* we shoudl not sleep in interrupt context */

43)
	Top Half and Bottom Half: Two important goals of interrupt handler are:
		- Execution Time: Handler of an interrupt must execute quickly. long running handlers can slow down the system and may also lead to losing interrupts. The faster the handler returns, the lower the interrupt latencies in the kernel, which is especially important for real-time systems.
		- Execution Context: Interrupt handlers are executed in hard-interrupt context – CPU-local interrupts remain disabled. locking is undesirable and sleeping must be avoided. large amount of work cannot be performed in interrupt handler.
	Both limitations lead to the fact that most interrupt handlers execute only a small amount of code and defer the rest of the work to a later point in time

	Handling of interrupts is divided into two parts:
		1. Top Half (Hard IRQ)
			Acknowledge the interrupt
			Copy the necessary stuff from the device
			schedule the bottom half
		2. Bottom Half (Soft IRQ)
			Remaining pending work

	Top and bottom halves with an example: Network Card on reception of packet from the network, issues an interrupt, kernel responds it by executing the handler.
		Top Half(Interrupt Handler): 
			Acknowledges the interrupt, 
			copies the new networking packets into main memory,
			pushes it up to the protocol layer
			readies the network card for more packets.
			schedule the bottom half
		Bottom Half: 
			Rest of the processing and handling of the packets

	Various Mechanisms available for Bottom Half:
		1. Soft IRQ
		2. Tasklets
		3. Workqueue

	Threaded IRQs: An alternative to using formal bottom-half mechanisms is threaded interrupt handlers. Threaded interrupt handlers seeks to reduce the time spent with interrupts disabled to bare minimum, pushing the rest of the processing out into kernel threads. With threaded IRQs, the way you register an interrupt handler is a bit simplified. You do not even have to schedule the bottom half yourself. The core does that for us. The bottom half is then executed in a dedicated kernel thread. 
		int request_threaded_irq (unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char * devname, void * dev_id);

	Difference between request_irq and request_threaded_irq:
		irq_handler_t thread_fn
	request_threaded_irq() breaks handler code in two parts, 
		handler and 
		thread function
	Now main functionality of handler is to intimate hardware that it has received the interrupt and wake up thread function. As soon as handler finishes, processor is in process context. 
		kernel/irq/manage.c --- setup_irq_thread
	priority of the thread is set to MAX_USER_RT_PRIO/2 which is higher than regular processes

	Why is the threaded handler not being executed even after thread is created? When the hard-IRQ handler (handler function) function returns IRQ_WAKE_THREAD,  the kthread associated with this bottom half will be scheduled, invoking the thread_fn. The thread_fn function must return IRQ_HANDLED when complete.

	After being executed, the kthread will not be rescheduled again until the IRQ is triggered again and the hard-IRQ returns IRQ_WAKE_THREAD.

	IRQF_ONESHOT: The interrupt is not reenabled after the IRQ handler finishes. This flag is required for threaded interrupts which need to keep the interrupt line disabled until the threaded handler has run Specifying this flag is mandatory if the primary handler is set to NULL. The default primary handler does nothing more than to return IRQ WAKE THREAD to wake up a kernel thread to execute the thread fn IRQ handler.
		kernel/irq/manage.c 	-->	irq_default_primary_handler

	ret_from_fork - a newly-created thread of execution is first switched to, it starts out executing at this function

44)
	Softirqs: Softirqs are bottom halves that run at a high priority but with hardware interrupts enabled
		Implementation: kernel/softirq.c
		Header File: <linux/softirq.h>
		Data structures: Softirqs are represented by the softirq_action structure.
			struct softirq_action
			{
					void    (*action)(struct softirq_action *);
			};

	A 10 entry array of this structure is declared in kernel/softirq.c
		static struct softirq_action softirq_vec[NR_SOFTIRQS];
			two for tasklet processing (HI_SOFTIRQ and TASKLET_SOFTIRQ),
			two for send and receive operations in networking (NET_TX_SOFTIRQ and NET_RX_SOFTIRQ),
			two for the block layer (asynchronous request completions),
			two for timers, and 
			one each for the scheduler and 
			read-copy-update processing

	From include/linux/interrupt.h
		enum
		{
				HI_SOFTIRQ=0,
				TIMER_SOFTIRQ,
				NET_TX_SOFTIRQ,
				NET_RX_SOFTIRQ,
				BLOCK_SOFTIRQ,
				IRQ_POLL_SOFTIRQ,
				TASKLET_SOFTIRQ,
				SCHED_SOFTIRQ,
				HRTIMER_SOFTIRQ, /* Unused, but kept as tools rely on the
									numbering. Sigh! */
				RCU_SOFTIRQ,    /* Preferable RCU should always be the last softirq */
				NR_SOFTIRQS
		};

	The number of registered softirqs is statically determined and cannot be changed dynamically.

	Preeemption: A softirq never preempts another softirq . The only event that can preempt a softirq is interrupt handler. Another softirq even the same one can run on another processor.

	/proc/softirqs: Shows Per CPU statistics
		Implementation: fs/proc/softirqs.c
	to watch all softirq handling, run [ $ watch -n1 grep RX /proc/softirqs ]

	softirq methods:
		Registering softirq handlers: Software interrupts must be registered before the kernel can execute them. open_softirq is used for associating the softirq instance with the corresponding bottom halve routine.
			void open_softirq(int nr, void (*action)(struct softirq_action *))
			{
					softirq_vec[nr].action = action;
			}
			It is being called for example from networking subsystem.
			net/core/dev.c:
				open_softirq(NET_TX_SOFTIRQ, net_tx_action);
				open_softirq(NET_RX_SOFTIRQ, net_rx_action);

	Execution of softirq: The kernel maintains a per-CPU bitmask indicating which softirqs need processing at any given time: irq_stat[smp_processor_id].__softirq_pending.

	Drivers can signal the execution of soft irq handlers using a function raise_softirq(). This function takes the index of the softirq as argument.
		void raise_softirq(unsigned int nr)
		{
				unsigned long flags;

				local_irq_save(flags);
				raise_softirq_irqoff(nr);
				local_irq_restore(flags);
		}
		local_irq_save 		--> Disables interrupts on the current processor where code is running
		raise_softirq_irqoff 	--> sets the corresponding bit in the local CPUs softirq bitmask to mark the specified softirq as pending
		local_irq_restore	--> Enables the interrupts
	raise_softirq_irqoff if executed in non-interrupt context, will invoke wakeup_softirqd(), to wake up, if necessary the ksoftirqd kernel thread of that local CPU

	What is the benefit of per-CPU Bitmask? By using a processors specific bitmap, the kernel ensures that several softIRQs — even identical ones — can be executed on different CPUs at the same time.

	Executing Softirqs: The actual execution of softirqs is managed by do_softirq().
		Implementation : kernel/softirq.c
	do_softirq() will call __do_softirq(), if any bit in the local softirq bit mask is set. __do_softirq() then iterates over the softirq bit mask (least signicant bit) and invokes scheduled softirq handlers.

	Creating a new softirq: You declare softirqs statically at compile time via an enum in <linux/interrupt.h>. Creating a new softirq includes adding a new entry to this enum. The index is used by the kernel as priority. Softirqs with the lowest numerical priority execute before those with a higher numerical priority. Insert the new entry depending on the priority you want to give it.

	generally, tasklet should be used instead of creating new softirq. softirq are used only for driver is very high priority and needs to execute botom half on priority. softirq aren't recommended to be created.

	Registering your handler: Soft irq is registered at runtime via open_softirq(). It takes two parameters:
		a) Index
		b) Handler Function.

	Raising your softirq: To mark it pending, so it is run at the next invocation of do_softirq(), call raise_softirq(). Softirqs are most often raised from within interrupt handlers.

	Other Details: The softirq handlers run with interrupts enabled and cannot sleep. While a handler runs, softirqs on the current processor are disabled. Another processor, can however execute another softirq. If the same softirq is raised again while it is executing, another processor can run in it simultaneously. This means that any shared data even global data used only within the soft irq handler needs proper locking.

	most softirq handlers resort to per-processor data (data unique to each processor and thus not requiring locking) and other tricks to avoid explicit locking and provide excellent scalability.

	hard irq run with interrupts disabled, whereas softirqs run with interrupts enabled

45)
